{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46c0702ae15944c9a1b434761dbfd883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75ca7a0bb6744df6b5630b8d37c95939",
              "IPY_MODEL_0eb7d94740e74cf7874bb542c26af4c2",
              "IPY_MODEL_11f43d70c0fa4ec88426206a44d6ef97"
            ],
            "layout": "IPY_MODEL_385db37ecba541c58f97cd88d8c2ee3a"
          }
        },
        "75ca7a0bb6744df6b5630b8d37c95939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427552cb69974a65a69fbda252c54c4e",
            "placeholder": "​",
            "style": "IPY_MODEL_8afd67e4347c4893ab3ef68e04777a04",
            "value": "dic.tar.gz: 100%"
          }
        },
        "0eb7d94740e74cf7874bb542c26af4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972d5022af3a4bcc82c52cc33c51a5d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6af452c410a4cc4a3a2bfcf539cf2bd",
            "value": 1
          }
        },
        "11f43d70c0fa4ec88426206a44d6ef97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba958f395314bf1b5a723d9a2ee5a9e",
            "placeholder": "​",
            "style": "IPY_MODEL_9f4f5d61eab54bc18be584f47e42b6d5",
            "value": " 22.6M/22.6M [00:00&lt;00:00, 40.3MB/s]"
          }
        },
        "385db37ecba541c58f97cd88d8c2ee3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427552cb69974a65a69fbda252c54c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8afd67e4347c4893ab3ef68e04777a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "972d5022af3a4bcc82c52cc33c51a5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d6af452c410a4cc4a3a2bfcf539cf2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ba958f395314bf1b5a723d9a2ee5a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4f5d61eab54bc18be584f47e42b6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whitebearOuO/psychic-fortnight/blob/main/%E3%80%8CVITS_fast_finetuning_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看GPU配置\n",
        "# Check GPU configuration\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "03vVx0mDtuwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7bbc31-1d99-4241-f6cf-33eaa0fab4d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan  8 02:22:51 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(2023/07/23) 这个笔记本参考[HWcomss](https://github.com/HWcomss)的版本修改而成，现已可以正常工作。\n",
        "##(23/07/2023) This notebook is a slightly modified version of [HWcomss](https://github.com/HWcomss)'s notebook, it's working fine now. Many thanks!\n"
      ],
      "metadata": {
        "id": "fwJ-lNbOtp-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title STEP 1 复制代码库并安装运行环境\n",
        "#@markdown #STEP 1 (6 min)\n",
        "#@markdown ##复制代码库并安装运行环境\n",
        "#@markdown ##Clone repository & Build environment\n",
        "\n",
        "!git clone https://github.com/Plachtaa/VITS-fast-fine-tuning.git\n",
        "!python -m pip install --upgrade --force-reinstall regex\n",
        "!python -m pip install --force-reinstall soundfile\n",
        "!python -m pip install --force-reinstall gradio\n",
        "!python -m pip install imageio==2.4.1\n",
        "!python -m pip install --upgrade youtube-dl\n",
        "!python -m pip install moviepy\n",
        "%cd VITS-fast-fine-tuning\n",
        "\n",
        "!python -m pip install --no-build-isolation -r requirements.txt\n",
        "!python -m pip install --upgrade numpy\n",
        "!python -m pip install --upgrade --force-reinstall numba\n",
        "!python -m pip install --upgrade Cython\n",
        "\n",
        "!python -m pip install --upgrade pyzmq\n",
        "!python -m pip install pydantic==1.10.4\n",
        "!python -m pip install ruamel.yaml\n",
        "!python -m pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# build monotonic align\n",
        "%cd monotonic_align/\n",
        "!mkdir monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "%cd ..\n",
        "!mkdir pretrained_models\n",
        "# download data for fine-tuning\n",
        "!wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/sampled_audio4ft_v2.zip\n",
        "!unzip sampled_audio4ft_v2.zip\n",
        "# create necessary directories\n",
        "!mkdir video_data\n",
        "!mkdir raw_audio\n",
        "!mkdir denoised_audio\n",
        "!mkdir custom_character_voice\n",
        "!mkdir segmented_character_voice"
      ],
      "metadata": {
        "id": "-XEdEXyTHVfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ba88d8-ac92-49bb-c01f-2e7945108752"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VITS-fast-fine-tuning'...\n",
            "remote: Enumerating objects: 883, done.\u001b[K\n",
            "remote: Counting objects: 100% (540/540), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 883 (delta 444), reused 398 (delta 398), pack-reused 343 (from 1)\u001b[K\n",
            "Receiving objects: 100% (883/883), 643.54 KiB | 11.70 MiB/s, done.\n",
            "Resolving deltas: 100% (509/509), done.\n",
            "Collecting regex\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: regex\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "Successfully installed regex-2024.11.6\n",
            "Collecting soundfile\n",
            "  Downloading soundfile-0.13.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting cffi>=1.0 (from soundfile)\n",
            "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting numpy (from soundfile)\n",
            "  Downloading numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser (from cffi>=1.0->soundfile)\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading soundfile-0.13.0-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.2/446.2 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycparser, numpy, cffi, soundfile\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.22\n",
            "    Uninstalling pycparser-2.22:\n",
            "      Successfully uninstalled pycparser-2.22\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.17.1\n",
            "    Uninstalling cffi-1.17.1:\n",
            "      Successfully uninstalled cffi-1.17.1\n",
            "  Attempting uninstall: soundfile\n",
            "    Found existing installation: soundfile 0.12.1\n",
            "    Uninstalling soundfile-0.12.1:\n",
            "      Successfully uninstalled soundfile-0.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.2.1 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.1 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.1 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.2.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.1 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.1 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cffi-1.17.1 numpy-2.2.1 pycparser-2.22 soundfile-0.13.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.10.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting anyio<5.0,>=3.0 (from gradio)\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.3 (from gradio)\n",
            "  Downloading gradio_client-1.5.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jinja2<4.0 (from gradio)\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting numpy<3.0,>=1.0 (from gradio)\n",
            "  Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging (from gradio)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas<3.0,>=1.0 (from gradio)\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow<12.0,>=8.0 (from gradio)\n",
            "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fsspec (from gradio-client==1.5.3->gradio)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.3->gradio)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio<5.0,>=3.0->gradio)\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting idna>=2.8 (from anyio<5.0,>=3.0->gradio)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting certifi (from httpx>=0.24.1->gradio)\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.25.1->gradio)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting requests (from huggingface-hub>=0.25.1->gradio)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.25.1->gradio)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas<3.0,>=1.0->gradio)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.25.1->gradio)\n",
            "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.25.1->gradio)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading gradio-5.10.0-py3-none-any.whl (57.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Downloading orjson-3.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.8/431.8 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.1/146.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pytz, pydub, websockets, urllib3, tzdata, typing-extensions, tqdm, tomlkit, sniffio, six, shellingham, semantic-version, ruff, pyyaml, python-multipart, pygments, pillow, packaging, orjson, numpy, mdurl, markupsafe, idna, h11, fsspec, filelock, ffmpy, exceptiongroup, click, charset-normalizer, certifi, annotated-types, aiofiles, uvicorn, requests, python-dateutil, pydantic-core, markdown-it-py, jinja2, httpcore, anyio, starlette, rich, pydantic, pandas, huggingface-hub, httpx, typer, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.2\n",
            "    Uninstalling pytz-2024.2:\n",
            "      Successfully uninstalled pytz-2024.2\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.1\n",
            "    Uninstalling websockets-14.1:\n",
            "      Successfully uninstalled websockets-14.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2024.2\n",
            "    Uninstalling tzdata-2024.2:\n",
            "      Successfully uninstalled tzdata-2024.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.10.12\n",
            "    Uninstalling orjson-3.10.12:\n",
            "      Successfully uninstalled orjson-3.10.12\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.1\n",
            "    Uninstalling numpy-2.2.1:\n",
            "      Successfully uninstalled numpy-2.2.1\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: exceptiongroup\n",
            "    Found existing installation: exceptiongroup 1.2.2\n",
            "    Uninstalling exceptiongroup-1.2.2:\n",
            "      Successfully uninstalled exceptiongroup-1.2.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.0\n",
            "    Uninstalling charset-normalizer-3.4.0:\n",
            "      Successfully uninstalled charset-normalizer-3.4.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.12.14\n",
            "    Uninstalling certifi-2024.12.14:\n",
            "      Successfully uninstalled certifi-2024.12.14\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.1\n",
            "    Uninstalling pydantic_core-2.27.1:\n",
            "      Successfully uninstalled pydantic_core-2.27.1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.3\n",
            "    Uninstalling pydantic-2.10.3:\n",
            "      Successfully uninstalled pydantic-2.10.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.0\n",
            "    Uninstalling huggingface-hub-0.27.0:\n",
            "      Successfully uninstalled huggingface-hub-0.27.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.1\n",
            "    Uninstalling typer-0.15.1:\n",
            "      Successfully uninstalled typer-0.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.2.1 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.1 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.2.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.1 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.1 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.8.0 certifi-2024.12.14 charset-normalizer-3.4.1 click-8.1.8 exceptiongroup-1.2.2 fastapi-0.115.6 ffmpy-0.5.0 filelock-3.16.1 fsspec-2024.12.0 gradio-5.10.0 gradio-client-1.5.3 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.27.1 idna-3.10 jinja2-3.1.5 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 numpy-2.2.1 orjson-3.10.13 packaging-24.2 pandas-2.2.3 pillow-11.1.0 pydantic-2.10.4 pydantic-core-2.27.2 pydub-0.25.1 pygments-2.19.1 python-dateutil-2.9.0.post0 python-multipart-0.0.20 pytz-2024.2 pyyaml-6.0.2 requests-2.32.3 rich-13.9.4 ruff-0.8.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 starlette-0.41.3 tomlkit-0.13.2 tqdm-4.67.1 typer-0.15.1 typing-extensions-4.12.2 tzdata-2024.2 urllib3-2.3.0 uvicorn-0.34.0 websockets-14.1\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (2.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (11.1.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303884 sha256=31bf12a64bc75a54bfa00a77198d52f6c1782316bfd48a7845078cb799a73af8\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/5d/ce/bdbdb04744dac03906336eb0d01ff1e222061d3419c55c55f9\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.36.1\n",
            "    Uninstalling imageio-2.36.1:\n",
            "      Successfully uninstalled imageio-2.36.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\n",
            "scikit-image 0.25.0 requires imageio!=2.35.0,>=2.33, but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.12.17\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
            "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.2.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.12.14)\n",
            "Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.36.1\n",
            "/content/VITS-fast-fine-tuning\n",
            "Collecting git+https://github.com/openai/whisper.git (from -r requirements.txt (line 25))\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-nwl3c056\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-nwl3c056\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Cython==0.29.21 (from -r requirements.txt (line 1))\n",
            "  Downloading Cython-0.29.21-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting librosa==0.9.2 (from -r requirements.txt (line 2))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting matplotlib==3.3.1 (from -r requirements.txt (line 3))\n",
            "  Downloading matplotlib-3.3.1.tar.gz (38.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.0.2 (from -r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.13.1)\n",
            "Collecting numpy==1.21.6 (from -r requirements.txt (line 6))\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.17.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.5.1+cu121)\n",
            "Collecting unidecode (from -r requirements.txt (line 11))\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pyopenjtalk-prebuilt (from -r requirements.txt (line 12))\n",
            "  Downloading pyopenjtalk_prebuilt-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting jamo (from -r requirements.txt (line 13))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pypinyin (from -r requirements.txt (line 14))\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.42.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (4.25.5)\n",
            "Collecting cn2an (from -r requirements.txt (line 17))\n",
            "  Downloading cn2an-0.5.23-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (7.4.0)\n",
            "Collecting eng_to_ipa (from -r requirements.txt (line 19))\n",
            "  Downloading eng_to_ipa-0.0.2.tar.gz (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ko_pron (from -r requirements.txt (line 20))\n",
            "  Downloading ko_pron-1.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting indic_transliteration==2.3.37 (from -r requirements.txt (line 21))\n",
            "  Downloading indic_transliteration-2.3.37-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting num_thai==0.0.5 (from -r requirements.txt (line 22))\n",
            "  Downloading num_thai-0.0.5-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opencc==1.1.1 (from -r requirements.txt (line 23))\n",
            "  Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting demucs (from -r requirements.txt (line 24))\n",
            "  Downloading demucs-4.0.1.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (5.10.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.2->-r requirements.txt (line 2))\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (0.13.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (2024.12.14)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (3.5.0)\n",
            "Collecting backports.functools-lru-cache (from indic_transliteration==2.3.37->-r requirements.txt (line 21))\n",
            "  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic_transliteration==2.3.37->-r requirements.txt (line 21)) (2024.11.6)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic_transliteration==2.3.37->-r requirements.txt (line 21)) (0.15.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic_transliteration==2.3.37->-r requirements.txt (line 21)) (0.10.2)\n",
            "Collecting roman (from indic_transliteration==2.3.37->-r requirements.txt (line 21))\n",
            "  Downloading roman-4.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy (from -r requirements.txt (line 5))\n",
            "  Downloading scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyopenjtalk-prebuilt->-r requirements.txt (line 12)) (4.67.1)\n",
            "Collecting proces>=0.1.7 (from cn2an->-r requirements.txt (line 17))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 18)) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 18)) (4.4.1)\n",
            "Collecting dora-search (from demucs->-r requirements.txt (line 24))\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from demucs->-r requirements.txt (line 24)) (0.8.0)\n",
            "Collecting julius>=0.2.3 (from demucs->-r requirements.txt (line 24))\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lameenc>=1.2 (from demucs->-r requirements.txt (line 24))\n",
            "  Downloading lameenc-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting openunmix (from demucs->-r requirements.txt (line 24))\n",
            "  Downloading openunmix-1.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from demucs->-r requirements.txt (line 24)) (6.0.2)\n",
            "Collecting tiktoken (from openai-whisper==20240930->-r requirements.txt (line 25))\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2 (from openai-whisper==20240930->-r requirements.txt (line 25))\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (4.8.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (1.5.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.27.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (3.10.13)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (2.2.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (2.10.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.8.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 26)) (0.34.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio->-r requirements.txt (line 26)) (14.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 26)) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 26)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 26)) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 26)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 26)) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio->-r requirements.txt (line 26)) (2.32.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.2->-r requirements.txt (line 2)) (0.43.0)\n",
            "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numba>=0.45.1 (from librosa==0.9.2->-r requirements.txt (line 2))\n",
            "  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.45.1->librosa==0.9.2->-r requirements.txt (line 2))\n",
            "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numba>=0.45.1 (from librosa==0.9.2->-r requirements.txt (line 2))\n",
            "  Downloading numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.45.1->librosa==0.9.2->-r requirements.txt (line 2))\n",
            "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numba>=0.45.1 (from librosa==0.9.2->-r requirements.txt (line 2))\n",
            "  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pandas<3.0,>=1.0 (from gradio->-r requirements.txt (line 26))\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "INFO: pip is still looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pandas-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 26)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 26)) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.2->-r requirements.txt (line 2)) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 26)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 26)) (2.27.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic_transliteration==2.3.37->-r requirements.txt (line 21)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic_transliteration==2.3.37->-r requirements.txt (line 21)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic_transliteration==2.3.37->-r requirements.txt (line 21)) (13.9.4)\n",
            "Collecting omegaconf (from dora-search->demucs->-r requirements.txt (line 24))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting retrying (from dora-search->demucs->-r requirements.txt (line 24))\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting submitit (from dora-search->demucs->-r requirements.txt (line 24))\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting treetable (from dora-search->demucs->-r requirements.txt (line 24))\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 2)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio->-r requirements.txt (line 26)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio->-r requirements.txt (line 26)) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic_transliteration==2.3.37->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic_transliteration==2.3.37->-r requirements.txt (line 21)) (2.19.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->dora-search->demucs->-r requirements.txt (line 24))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->dora-search->demucs->-r requirements.txt (line 24)) (3.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic_transliteration==2.3.37->-r requirements.txt (line 21)) (0.1.2)\n",
            "Downloading Cython-0.29.21-py2.py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.2/974.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading indic_transliteration-2.3.37-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num_thai-0.0.5-py3-none-any.whl (4.8 kB)\n",
            "Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyopenjtalk_prebuilt-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cn2an-0.5.23-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ko_pron-1.3-py3-none-any.whl (12 kB)\n",
            "Downloading lameenc-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.9/248.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\n",
            "Downloading openunmix-1.3.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roman-4.2-py3-none-any.whl (5.5 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: matplotlib, eng_to_ipa, demucs, openai-whisper, julius, dora-search, antlr4-python3-runtime, treetable\n",
            "  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for matplotlib: filename=matplotlib-3.3.1-cp310-cp310-linux_x86_64.whl size=11711037 sha256=61ae15ea7e6a6513bd73193c7f41d700fbbd16dd656d7f054500a210537cae01\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/31/bd/cac116cfbdb888062d5f204ba245a2877cd025f5d33f03ae23\n",
            "  Building wheel for eng_to_ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eng_to_ipa: filename=eng_to_ipa-0.0.2-py3-none-any.whl size=2822601 sha256=4916bbbe5e7e2240cd7ae73bced994deda143f5d5292ee6e0f0ae7061084844a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ab/07/fe6722f710d8ef8bd0ccb4eb689ef96f5552f3fc0c80c1aa9c\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.0.1-py3-none-any.whl size=78388 sha256=6a90d8955da44c7036ede4e86f5c79d13b13b03d1fc6918d5e0d9b2d18775108\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/65/a1/6cc0e525a84375af3b09823b3326b0ece53c4e68302c054548\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=f9b970a0e3013bf94c40a9a502e4774d1ace4e382bc51d19d277f3c6f586ee89\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u5ipyojq/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=547f9983a866b23d25a31fe8d665356c97b5d4b4c47649cc702ea2fc542a9757\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75091 sha256=e710d2c7bc2bb640b3c1002012f3d4d3f36080408379d8306983d651bede52e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=b76f8da380bed61c71ed25a3fecbb8569cca78ce309e3a87d28e0abcc87672dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7334 sha256=203a0f3e74360c2665d9ffcf503e8db3807475f0a59efc00aa601a3cd4e53c1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/55/0e/91c3655bdb162446f8a7cd477579397544454a63ae7c599c0c\n",
            "Successfully built matplotlib eng_to_ipa demucs openai-whisper julius dora-search antlr4-python3-runtime treetable\n",
            "Installing collected packages: opencc, lameenc, ko_pron, jamo, eng_to_ipa, antlr4-python3-runtime, unidecode, triton, treetable, submitit, roman, retrying, pypinyin, proces, omegaconf, numpy, num_thai, llvmlite, Cython, backports.functools-lru-cache, tiktoken, scipy, pyopenjtalk-prebuilt, pandas, numba, matplotlib, cn2an, scikit-learn, resampy, openai-whisper, julius, dora-search, openunmix, librosa, indic_transliteration, demucs\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.1\n",
            "    Uninstalling numpy-2.2.1:\n",
            "      Successfully uninstalled numpy-2.2.1\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.11\n",
            "    Uninstalling Cython-3.0.11:\n",
            "      Successfully uninstalled Cython-3.0.11\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.0\n",
            "    Uninstalling matplotlib-3.8.0:\n",
            "      Successfully uninstalled matplotlib-3.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.21.6 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.21.6 which is incompatible.\n",
            "arviz 0.20.0 requires matplotlib>=3.5, but you have matplotlib 3.3.1 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.21.6 which is incompatible.\n",
            "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.21.6 which is incompatible.\n",
            "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "flax 0.8.5 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "geopandas 1.0.1 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.21.6 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 1.21.6 which is incompatible.\n",
            "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "nibabel 5.3.2 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.3.1 which is incompatible.\n",
            "plotnine 0.14.4 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.21.6 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "seaborn 0.13.2 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.3.1 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.21.6 which is incompatible.\n",
            "tensorstore 0.1.71 requires numpy>=1.22.0, but you have numpy 1.21.6 which is incompatible.\n",
            "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-0.29.21 antlr4-python3-runtime-4.9.3 backports.functools-lru-cache-2.0.0 cn2an-0.5.23 demucs-4.0.1 dora-search-0.1.12 eng_to_ipa-0.0.2 indic_transliteration-2.3.37 jamo-0.4.1 julius-0.2.7 ko_pron-1.3 lameenc-1.8.1 librosa-0.9.2 llvmlite-0.41.1 matplotlib-3.3.1 num_thai-0.0.5 numba-0.58.0 numpy-1.21.6 omegaconf-2.3.0 openai-whisper-20240930 opencc-1.1.1 openunmix-1.3.0 pandas-2.0.3 proces-0.1.7 pyopenjtalk-prebuilt-0.3.0 pypinyin-0.53.0 resampy-0.4.3 retrying-1.3.4 roman-4.2 scikit-learn-1.0.2 scipy-1.11.4 submitit-1.5.2 tiktoken-0.8.0 treetable-0.2.5 triton-3.1.0 unidecode-1.3.8\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.21.6)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.20.0 requires matplotlib>=3.5, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.2.1 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.1 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.1 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "numba 0.58.0 requires numpy<1.26,>=1.21, but you have numpy 2.2.1 which is incompatible.\n",
            "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.3.1 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.1 which is incompatible.\n",
            "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.2.1 which is incompatible.\n",
            "seaborn 0.13.2 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.3.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.1 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.1 which is incompatible.\n",
            "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.1\n",
            "Collecting numba\n",
            "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba)\n",
            "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<2.1,>=1.22 (from numba)\n",
            "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, llvmlite, numba\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.1\n",
            "    Uninstalling numpy-2.2.1:\n",
            "      Successfully uninstalled numpy-2.2.1\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.41.1\n",
            "    Uninstalling llvmlite-0.41.1:\n",
            "      Successfully uninstalled llvmlite-0.41.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.58.0\n",
            "    Uninstalling numba-0.58.0:\n",
            "      Successfully uninstalled numba-0.58.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.20.0 requires matplotlib>=3.5, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.3.1 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.0.2 which is incompatible.\n",
            "seaborn 0.13.2 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.3.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\n",
            "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llvmlite-0.43.0 numba-0.60.0 numpy-2.0.2\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (0.29.21)\n",
            "Collecting Cython\n",
            "  Downloading Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Downloading Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.21\n",
            "    Uninstalling Cython-0.29.21:\n",
            "      Successfully uninstalled Cython-0.29.21\n",
            "Successfully installed Cython-3.0.11\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (24.0.1)\n",
            "Collecting pyzmq\n",
            "  Downloading pyzmq-26.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Downloading pyzmq-26.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (868 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyzmq\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\n",
            "notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 26.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyzmq-26.2.0\n",
            "Collecting pydantic==1.10.4\n",
            "  Downloading pydantic-1.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.3/142.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.4) (4.12.2)\n",
            "Downloading pydantic-1.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.4\n",
            "    Uninstalling pydantic-2.10.4:\n",
            "      Successfully uninstalled pydantic-2.10.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.4 which is incompatible.\n",
            "google-genai 0.3.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.4 which is incompatible.\n",
            "gradio 5.10.0 requires pydantic>=2.0, but you have pydantic 1.10.4 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "langchain 0.3.12 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.4 which is incompatible.\n",
            "langchain-core 0.3.25 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.4 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\n",
            "wandb 0.19.1 requires pydantic<3,>=2.6, but you have pydantic 1.10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-1.10.4\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n",
            "Successfully installed ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-p1wzc267\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-p1wzc267\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (2.1.5)\n",
            "/content/VITS-fast-fine-tuning/monotonic_align\n",
            "Compiling core.pyx because it changed.\n",
            "[1/1] Cythonizing core.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /content/VITS-fast-fine-tuning/monotonic_align/core.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "performance hint: core.pyx:7:5: Exception check on 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n",
            "performance hint: core.pyx:38:6: Exception check on 'maximum_path_c' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_c' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_c' to allow an error code to be returned.\n",
            "performance hint: core.pyx:42:21: Exception check after calling 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n",
            "/content/VITS-fast-fine-tuning\n",
            "--2025-01-08 02:20:21--  https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/sampled_audio4ft_v2.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.12, 3.165.160.59, 3.165.160.11, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/ac/b5/acb5f3bba0c513bfed7e77047c9bd2d980658e84d452613fcd1c54d10dbd418f/f9ddea2304dab927ace31fbc4f42b6afb93aa551ba80300072485a038d438c22?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sampled_audio4ft_v2.zip%3B+filename%3D%22sampled_audio4ft_v2.zip%22%3B&response-content-type=application%2Fzip&Expires=1736562021&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNjU2MjAyMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYy9iNS9hY2I1ZjNiYmEwYzUxM2JmZWQ3ZTc3MDQ3YzliZDJkOTgwNjU4ZTg0ZDQ1MjYxM2ZjZDFjNTRkMTBkYmQ0MThmL2Y5ZGRlYTIzMDRkYWI5MjdhY2UzMWZiYzRmNDJiNmFmYjkzYWE1NTFiYTgwMzAwMDcyNDg1YTAzOGQ0MzhjMjI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=W4D-THw-ay0WW39J2YLhcO9%7Edhx7hYPF7Q-2iSxKuz53wOL7NjFTMJJbPWmGVAbQoDoj3qT5qcYKpV3axkscbO-A-K%7E5HOVb1%7E8TomDbQ9BkDT1VJBU1%7EIqOQRNHD8NmzM6PSh4WFRRqLdhrbtXLJUmbY4hOW7259vGPgfaAOAQWvBCDQBBjSPOkiVFvd1Jn5FTRRPQI-iV93VTPV5E0nz52UfD8WvqGMzo-PsGvKNFyi0FuxU9O%7EjAcgrjsvNrvHQFhtM2PeHoI25lnSuQARKY-6AxWbOwd5oxT6W7vRtwShb9JmQUt-BbtAfNLypG1uTa6TAV0FQcsJhKIwpCsXg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-01-08 02:20:21--  https://cdn-lfs.hf.co/repos/ac/b5/acb5f3bba0c513bfed7e77047c9bd2d980658e84d452613fcd1c54d10dbd418f/f9ddea2304dab927ace31fbc4f42b6afb93aa551ba80300072485a038d438c22?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sampled_audio4ft_v2.zip%3B+filename%3D%22sampled_audio4ft_v2.zip%22%3B&response-content-type=application%2Fzip&Expires=1736562021&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNjU2MjAyMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYy9iNS9hY2I1ZjNiYmEwYzUxM2JmZWQ3ZTc3MDQ3YzliZDJkOTgwNjU4ZTg0ZDQ1MjYxM2ZjZDFjNTRkMTBkYmQ0MThmL2Y5ZGRlYTIzMDRkYWI5MjdhY2UzMWZiYzRmNDJiNmFmYjkzYWE1NTFiYTgwMzAwMDcyNDg1YTAzOGQ0MzhjMjI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=W4D-THw-ay0WW39J2YLhcO9%7Edhx7hYPF7Q-2iSxKuz53wOL7NjFTMJJbPWmGVAbQoDoj3qT5qcYKpV3axkscbO-A-K%7E5HOVb1%7E8TomDbQ9BkDT1VJBU1%7EIqOQRNHD8NmzM6PSh4WFRRqLdhrbtXLJUmbY4hOW7259vGPgfaAOAQWvBCDQBBjSPOkiVFvd1Jn5FTRRPQI-iV93VTPV5E0nz52UfD8WvqGMzo-PsGvKNFyi0FuxU9O%7EjAcgrjsvNrvHQFhtM2PeHoI25lnSuQARKY-6AxWbOwd5oxT6W7vRtwShb9JmQUt-BbtAfNLypG1uTa6TAV0FQcsJhKIwpCsXg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.163.158.27, 3.163.158.75, 3.163.158.61, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.163.158.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 336555261 (321M) [application/zip]\n",
            "Saving to: ‘sampled_audio4ft_v2.zip’\n",
            "\n",
            "sampled_audio4ft_v2 100%[===================>] 320.96M   204MB/s    in 1.6s    \n",
            "\n",
            "2025-01-08 02:20:22 (204 MB/s) - ‘sampled_audio4ft_v2.zip’ saved [336555261/336555261]\n",
            "\n",
            "Archive:  sampled_audio4ft_v2.zip\n",
            "   creating: sampled_audio4ft/\n",
            "  inflating: sampled_audio4ft/0.wav  \n",
            "  inflating: sampled_audio4ft/1.wav  \n",
            "  inflating: sampled_audio4ft/10.wav  \n",
            "  inflating: sampled_audio4ft/100.wav  \n",
            "  inflating: sampled_audio4ft/1000.wav  \n",
            "  inflating: sampled_audio4ft/1001.wav  \n",
            "  inflating: sampled_audio4ft/1002.wav  \n",
            "  inflating: sampled_audio4ft/1003.wav  \n",
            "  inflating: sampled_audio4ft/1004.wav  \n",
            "  inflating: sampled_audio4ft/1005.wav  \n",
            "  inflating: sampled_audio4ft/1006.wav  \n",
            "  inflating: sampled_audio4ft/1007.wav  \n",
            "  inflating: sampled_audio4ft/1008.wav  \n",
            "  inflating: sampled_audio4ft/1009.wav  \n",
            "  inflating: sampled_audio4ft/101.wav  \n",
            "  inflating: sampled_audio4ft/1010.wav  \n",
            "  inflating: sampled_audio4ft/1011.wav  \n",
            "  inflating: sampled_audio4ft/1012.wav  \n",
            "  inflating: sampled_audio4ft/1013.wav  \n",
            "  inflating: sampled_audio4ft/1014.wav  \n",
            "  inflating: sampled_audio4ft/1015.wav  \n",
            "  inflating: sampled_audio4ft/1016.wav  \n",
            "  inflating: sampled_audio4ft/1017.wav  \n",
            "  inflating: sampled_audio4ft/1018.wav  \n",
            "  inflating: sampled_audio4ft/1019.wav  \n",
            "  inflating: sampled_audio4ft/102.wav  \n",
            "  inflating: sampled_audio4ft/1020.wav  \n",
            "  inflating: sampled_audio4ft/1021.wav  \n",
            "  inflating: sampled_audio4ft/1022.wav  \n",
            "  inflating: sampled_audio4ft/1023.wav  \n",
            "  inflating: sampled_audio4ft/1024.wav  \n",
            "  inflating: sampled_audio4ft/1025.wav  \n",
            "  inflating: sampled_audio4ft/1026.wav  \n",
            "  inflating: sampled_audio4ft/1027.wav  \n",
            "  inflating: sampled_audio4ft/1028.wav  \n",
            "  inflating: sampled_audio4ft/1029.wav  \n",
            "  inflating: sampled_audio4ft/103.wav  \n",
            "  inflating: sampled_audio4ft/1030.wav  \n",
            "  inflating: sampled_audio4ft/1031.wav  \n",
            "  inflating: sampled_audio4ft/1032.wav  \n",
            "  inflating: sampled_audio4ft/1033.wav  \n",
            "  inflating: sampled_audio4ft/1034.wav  \n",
            "  inflating: sampled_audio4ft/1035.wav  \n",
            "  inflating: sampled_audio4ft/1036.wav  \n",
            "  inflating: sampled_audio4ft/1037.wav  \n",
            "  inflating: sampled_audio4ft/1038.wav  \n",
            "  inflating: sampled_audio4ft/1039.wav  \n",
            "  inflating: sampled_audio4ft/104.wav  \n",
            "  inflating: sampled_audio4ft/1040.wav  \n",
            "  inflating: sampled_audio4ft/1041.wav  \n",
            "  inflating: sampled_audio4ft/1042.wav  \n",
            "  inflating: sampled_audio4ft/1043.wav  \n",
            "  inflating: sampled_audio4ft/1044.wav  \n",
            "  inflating: sampled_audio4ft/1045.wav  \n",
            "  inflating: sampled_audio4ft/1046.wav  \n",
            "  inflating: sampled_audio4ft/1047.wav  \n",
            "  inflating: sampled_audio4ft/1048.wav  \n",
            "  inflating: sampled_audio4ft/1049.wav  \n",
            "  inflating: sampled_audio4ft/105.wav  \n",
            "  inflating: sampled_audio4ft/1050.wav  \n",
            "  inflating: sampled_audio4ft/1051.wav  \n",
            "  inflating: sampled_audio4ft/1052.wav  \n",
            "  inflating: sampled_audio4ft/1053.wav  \n",
            "  inflating: sampled_audio4ft/1054.wav  \n",
            "  inflating: sampled_audio4ft/1055.wav  \n",
            "  inflating: sampled_audio4ft/1056.wav  \n",
            "  inflating: sampled_audio4ft/1057.wav  \n",
            "  inflating: sampled_audio4ft/1058.wav  \n",
            "  inflating: sampled_audio4ft/1059.wav  \n",
            "  inflating: sampled_audio4ft/106.wav  \n",
            "  inflating: sampled_audio4ft/1060.wav  \n",
            "  inflating: sampled_audio4ft/1061.wav  \n",
            "  inflating: sampled_audio4ft/1062.wav  \n",
            "  inflating: sampled_audio4ft/1063.wav  \n",
            "  inflating: sampled_audio4ft/1064.wav  \n",
            "  inflating: sampled_audio4ft/1065.wav  \n",
            "  inflating: sampled_audio4ft/1066.wav  \n",
            "  inflating: sampled_audio4ft/1067.wav  \n",
            "  inflating: sampled_audio4ft/1068.wav  \n",
            "  inflating: sampled_audio4ft/1069.wav  \n",
            "  inflating: sampled_audio4ft/107.wav  \n",
            "  inflating: sampled_audio4ft/1070.wav  \n",
            "  inflating: sampled_audio4ft/1071.wav  \n",
            "  inflating: sampled_audio4ft/1072.wav  \n",
            "  inflating: sampled_audio4ft/1073.wav  \n",
            "  inflating: sampled_audio4ft/1074.wav  \n",
            "  inflating: sampled_audio4ft/1075.wav  \n",
            "  inflating: sampled_audio4ft/1076.wav  \n",
            "  inflating: sampled_audio4ft/1077.wav  \n",
            "  inflating: sampled_audio4ft/1078.wav  \n",
            "  inflating: sampled_audio4ft/1079.wav  \n",
            "  inflating: sampled_audio4ft/108.wav  \n",
            "  inflating: sampled_audio4ft/1080.wav  \n",
            "  inflating: sampled_audio4ft/1081.wav  \n",
            "  inflating: sampled_audio4ft/1082.wav  \n",
            "  inflating: sampled_audio4ft/1083.wav  \n",
            "  inflating: sampled_audio4ft/1084.wav  \n",
            "  inflating: sampled_audio4ft/1085.wav  \n",
            "  inflating: sampled_audio4ft/1086.wav  \n",
            "  inflating: sampled_audio4ft/1087.wav  \n",
            "  inflating: sampled_audio4ft/1088.wav  \n",
            "  inflating: sampled_audio4ft/1089.wav  \n",
            "  inflating: sampled_audio4ft/109.wav  \n",
            "  inflating: sampled_audio4ft/1090.wav  \n",
            "  inflating: sampled_audio4ft/1091.wav  \n",
            "  inflating: sampled_audio4ft/11.wav  \n",
            "  inflating: sampled_audio4ft/110.wav  \n",
            "  inflating: sampled_audio4ft/111.wav  \n",
            "  inflating: sampled_audio4ft/112.wav  \n",
            "  inflating: sampled_audio4ft/113.wav  \n",
            "  inflating: sampled_audio4ft/114.wav  \n",
            "  inflating: sampled_audio4ft/115.wav  \n",
            "  inflating: sampled_audio4ft/116.wav  \n",
            "  inflating: sampled_audio4ft/117.wav  \n",
            "  inflating: sampled_audio4ft/118.wav  \n",
            "  inflating: sampled_audio4ft/119.wav  \n",
            "  inflating: sampled_audio4ft/12.wav  \n",
            "  inflating: sampled_audio4ft/120.wav  \n",
            "  inflating: sampled_audio4ft/121.wav  \n",
            "  inflating: sampled_audio4ft/122.wav  \n",
            "  inflating: sampled_audio4ft/123.wav  \n",
            "  inflating: sampled_audio4ft/124.wav  \n",
            "  inflating: sampled_audio4ft/125.wav  \n",
            "  inflating: sampled_audio4ft/126.wav  \n",
            "  inflating: sampled_audio4ft/127.wav  \n",
            "  inflating: sampled_audio4ft/128.wav  \n",
            "  inflating: sampled_audio4ft/129.wav  \n",
            "  inflating: sampled_audio4ft/13.wav  \n",
            "  inflating: sampled_audio4ft/130.wav  \n",
            "  inflating: sampled_audio4ft/131.wav  \n",
            "  inflating: sampled_audio4ft/132.wav  \n",
            "  inflating: sampled_audio4ft/133.wav  \n",
            "  inflating: sampled_audio4ft/134.wav  \n",
            "  inflating: sampled_audio4ft/135.wav  \n",
            "  inflating: sampled_audio4ft/136.wav  \n",
            "  inflating: sampled_audio4ft/137.wav  \n",
            "  inflating: sampled_audio4ft/138.wav  \n",
            "  inflating: sampled_audio4ft/139.wav  \n",
            "  inflating: sampled_audio4ft/14.wav  \n",
            "  inflating: sampled_audio4ft/140.wav  \n",
            "  inflating: sampled_audio4ft/141.wav  \n",
            "  inflating: sampled_audio4ft/142.wav  \n",
            "  inflating: sampled_audio4ft/143.wav  \n",
            "  inflating: sampled_audio4ft/144.wav  \n",
            "  inflating: sampled_audio4ft/145.wav  \n",
            "  inflating: sampled_audio4ft/146.wav  \n",
            "  inflating: sampled_audio4ft/147.wav  \n",
            "  inflating: sampled_audio4ft/148.wav  \n",
            "  inflating: sampled_audio4ft/149.wav  \n",
            "  inflating: sampled_audio4ft/15.wav  \n",
            "  inflating: sampled_audio4ft/150.wav  \n",
            "  inflating: sampled_audio4ft/151.wav  \n",
            "  inflating: sampled_audio4ft/152.wav  \n",
            "  inflating: sampled_audio4ft/153.wav  \n",
            "  inflating: sampled_audio4ft/154.wav  \n",
            "  inflating: sampled_audio4ft/155.wav  \n",
            "  inflating: sampled_audio4ft/156.wav  \n",
            "  inflating: sampled_audio4ft/157.wav  \n",
            "  inflating: sampled_audio4ft/158.wav  \n",
            "  inflating: sampled_audio4ft/159.wav  \n",
            "  inflating: sampled_audio4ft/16.wav  \n",
            "  inflating: sampled_audio4ft/160.wav  \n",
            "  inflating: sampled_audio4ft/161.wav  \n",
            "  inflating: sampled_audio4ft/162.wav  \n",
            "  inflating: sampled_audio4ft/163.wav  \n",
            "  inflating: sampled_audio4ft/164.wav  \n",
            "  inflating: sampled_audio4ft/165.wav  \n",
            "  inflating: sampled_audio4ft/166.wav  \n",
            "  inflating: sampled_audio4ft/167.wav  \n",
            "  inflating: sampled_audio4ft/168.wav  \n",
            "  inflating: sampled_audio4ft/169.wav  \n",
            "  inflating: sampled_audio4ft/17.wav  \n",
            "  inflating: sampled_audio4ft/170.wav  \n",
            "  inflating: sampled_audio4ft/171.wav  \n",
            "  inflating: sampled_audio4ft/172.wav  \n",
            "  inflating: sampled_audio4ft/173.wav  \n",
            "  inflating: sampled_audio4ft/174.wav  \n",
            "  inflating: sampled_audio4ft/175.wav  \n",
            "  inflating: sampled_audio4ft/176.wav  \n",
            "  inflating: sampled_audio4ft/177.wav  \n",
            "  inflating: sampled_audio4ft/178.wav  \n",
            "  inflating: sampled_audio4ft/179.wav  \n",
            "  inflating: sampled_audio4ft/18.wav  \n",
            "  inflating: sampled_audio4ft/180.wav  \n",
            "  inflating: sampled_audio4ft/181.wav  \n",
            "  inflating: sampled_audio4ft/182.wav  \n",
            "  inflating: sampled_audio4ft/183.wav  \n",
            "  inflating: sampled_audio4ft/184.wav  \n",
            "  inflating: sampled_audio4ft/185.wav  \n",
            "  inflating: sampled_audio4ft/186.wav  \n",
            "  inflating: sampled_audio4ft/187.wav  \n",
            "  inflating: sampled_audio4ft/188.wav  \n",
            "  inflating: sampled_audio4ft/189.wav  \n",
            "  inflating: sampled_audio4ft/19.wav  \n",
            "  inflating: sampled_audio4ft/190.wav  \n",
            "  inflating: sampled_audio4ft/191.wav  \n",
            "  inflating: sampled_audio4ft/192.wav  \n",
            "  inflating: sampled_audio4ft/193.wav  \n",
            "  inflating: sampled_audio4ft/194.wav  \n",
            "  inflating: sampled_audio4ft/195.wav  \n",
            "  inflating: sampled_audio4ft/196.wav  \n",
            "  inflating: sampled_audio4ft/197.wav  \n",
            "  inflating: sampled_audio4ft/198.wav  \n",
            "  inflating: sampled_audio4ft/199.wav  \n",
            "  inflating: sampled_audio4ft/2.wav  \n",
            "  inflating: sampled_audio4ft/20.wav  \n",
            "  inflating: sampled_audio4ft/200.wav  \n",
            "  inflating: sampled_audio4ft/201.wav  \n",
            "  inflating: sampled_audio4ft/202.wav  \n",
            "  inflating: sampled_audio4ft/203.wav  \n",
            "  inflating: sampled_audio4ft/204.wav  \n",
            "  inflating: sampled_audio4ft/205.wav  \n",
            "  inflating: sampled_audio4ft/206.wav  \n",
            "  inflating: sampled_audio4ft/207.wav  \n",
            "  inflating: sampled_audio4ft/208.wav  \n",
            "  inflating: sampled_audio4ft/209.wav  \n",
            "  inflating: sampled_audio4ft/21.wav  \n",
            "  inflating: sampled_audio4ft/210.wav  \n",
            "  inflating: sampled_audio4ft/211.wav  \n",
            "  inflating: sampled_audio4ft/212.wav  \n",
            "  inflating: sampled_audio4ft/213.wav  \n",
            "  inflating: sampled_audio4ft/214.wav  \n",
            "  inflating: sampled_audio4ft/215.wav  \n",
            "  inflating: sampled_audio4ft/216.wav  \n",
            "  inflating: sampled_audio4ft/217.wav  \n",
            "  inflating: sampled_audio4ft/218.wav  \n",
            "  inflating: sampled_audio4ft/219.wav  \n",
            "  inflating: sampled_audio4ft/22.wav  \n",
            "  inflating: sampled_audio4ft/220.wav  \n",
            "  inflating: sampled_audio4ft/221.wav  \n",
            "  inflating: sampled_audio4ft/222.wav  \n",
            "  inflating: sampled_audio4ft/223.wav  \n",
            "  inflating: sampled_audio4ft/224.wav  \n",
            "  inflating: sampled_audio4ft/225.wav  \n",
            "  inflating: sampled_audio4ft/226.wav  \n",
            "  inflating: sampled_audio4ft/227.wav  \n",
            "  inflating: sampled_audio4ft/228.wav  \n",
            "  inflating: sampled_audio4ft/229.wav  \n",
            "  inflating: sampled_audio4ft/23.wav  \n",
            "  inflating: sampled_audio4ft/230.wav  \n",
            "  inflating: sampled_audio4ft/231.wav  \n",
            "  inflating: sampled_audio4ft/232.wav  \n",
            "  inflating: sampled_audio4ft/233.wav  \n",
            "  inflating: sampled_audio4ft/234.wav  \n",
            "  inflating: sampled_audio4ft/235.wav  \n",
            "  inflating: sampled_audio4ft/236.wav  \n",
            "  inflating: sampled_audio4ft/237.wav  \n",
            "  inflating: sampled_audio4ft/238.wav  \n",
            "  inflating: sampled_audio4ft/239.wav  \n",
            "  inflating: sampled_audio4ft/24.wav  \n",
            "  inflating: sampled_audio4ft/240.wav  \n",
            "  inflating: sampled_audio4ft/241.wav  \n",
            "  inflating: sampled_audio4ft/242.wav  \n",
            "  inflating: sampled_audio4ft/243.wav  \n",
            "  inflating: sampled_audio4ft/244.wav  \n",
            "  inflating: sampled_audio4ft/245.wav  \n",
            "  inflating: sampled_audio4ft/246.wav  \n",
            "  inflating: sampled_audio4ft/247.wav  \n",
            "  inflating: sampled_audio4ft/248.wav  \n",
            "  inflating: sampled_audio4ft/249.wav  \n",
            "  inflating: sampled_audio4ft/25.wav  \n",
            "  inflating: sampled_audio4ft/250.wav  \n",
            "  inflating: sampled_audio4ft/251.wav  \n",
            "  inflating: sampled_audio4ft/252.wav  \n",
            "  inflating: sampled_audio4ft/253.wav  \n",
            "  inflating: sampled_audio4ft/254.wav  \n",
            "  inflating: sampled_audio4ft/255.wav  \n",
            "  inflating: sampled_audio4ft/256.wav  \n",
            "  inflating: sampled_audio4ft/257.wav  \n",
            "  inflating: sampled_audio4ft/258.wav  \n",
            "  inflating: sampled_audio4ft/259.wav  \n",
            "  inflating: sampled_audio4ft/26.wav  \n",
            "  inflating: sampled_audio4ft/260.wav  \n",
            "  inflating: sampled_audio4ft/261.wav  \n",
            "  inflating: sampled_audio4ft/262.wav  \n",
            "  inflating: sampled_audio4ft/263.wav  \n",
            "  inflating: sampled_audio4ft/264.wav  \n",
            "  inflating: sampled_audio4ft/265.wav  \n",
            "  inflating: sampled_audio4ft/266.wav  \n",
            "  inflating: sampled_audio4ft/267.wav  \n",
            "  inflating: sampled_audio4ft/268.wav  \n",
            "  inflating: sampled_audio4ft/269.wav  \n",
            "  inflating: sampled_audio4ft/27.wav  \n",
            "  inflating: sampled_audio4ft/270.wav  \n",
            "  inflating: sampled_audio4ft/271.wav  \n",
            "  inflating: sampled_audio4ft/272.wav  \n",
            "  inflating: sampled_audio4ft/273.wav  \n",
            "  inflating: sampled_audio4ft/274.wav  \n",
            "  inflating: sampled_audio4ft/275.wav  \n",
            "  inflating: sampled_audio4ft/276.wav  \n",
            "  inflating: sampled_audio4ft/277.wav  \n",
            "  inflating: sampled_audio4ft/278.wav  \n",
            "  inflating: sampled_audio4ft/279.wav  \n",
            "  inflating: sampled_audio4ft/28.wav  \n",
            "  inflating: sampled_audio4ft/280.wav  \n",
            "  inflating: sampled_audio4ft/281.wav  \n",
            "  inflating: sampled_audio4ft/282.wav  \n",
            "  inflating: sampled_audio4ft/283.wav  \n",
            "  inflating: sampled_audio4ft/284.wav  \n",
            "  inflating: sampled_audio4ft/285.wav  \n",
            "  inflating: sampled_audio4ft/286.wav  \n",
            "  inflating: sampled_audio4ft/287.wav  \n",
            "  inflating: sampled_audio4ft/288.wav  \n",
            "  inflating: sampled_audio4ft/289.wav  \n",
            "  inflating: sampled_audio4ft/29.wav  \n",
            "  inflating: sampled_audio4ft/290.wav  \n",
            "  inflating: sampled_audio4ft/291.wav  \n",
            "  inflating: sampled_audio4ft/292.wav  \n",
            "  inflating: sampled_audio4ft/293.wav  \n",
            "  inflating: sampled_audio4ft/294.wav  \n",
            "  inflating: sampled_audio4ft/295.wav  \n",
            "  inflating: sampled_audio4ft/296.wav  \n",
            "  inflating: sampled_audio4ft/297.wav  \n",
            "  inflating: sampled_audio4ft/298.wav  \n",
            "  inflating: sampled_audio4ft/299.wav  \n",
            "  inflating: sampled_audio4ft/3.wav  \n",
            "  inflating: sampled_audio4ft/30.wav  \n",
            "  inflating: sampled_audio4ft/300.wav  \n",
            "  inflating: sampled_audio4ft/301.wav  \n",
            "  inflating: sampled_audio4ft/302.wav  \n",
            "  inflating: sampled_audio4ft/303.wav  \n",
            "  inflating: sampled_audio4ft/304.wav  \n",
            "  inflating: sampled_audio4ft/305.wav  \n",
            "  inflating: sampled_audio4ft/306.wav  \n",
            "  inflating: sampled_audio4ft/307.wav  \n",
            "  inflating: sampled_audio4ft/308.wav  \n",
            "  inflating: sampled_audio4ft/309.wav  \n",
            "  inflating: sampled_audio4ft/31.wav  \n",
            "  inflating: sampled_audio4ft/310.wav  \n",
            "  inflating: sampled_audio4ft/311.wav  \n",
            "  inflating: sampled_audio4ft/312.wav  \n",
            "  inflating: sampled_audio4ft/313.wav  \n",
            "  inflating: sampled_audio4ft/314.wav  \n",
            "  inflating: sampled_audio4ft/315.wav  \n",
            "  inflating: sampled_audio4ft/316.wav  \n",
            "  inflating: sampled_audio4ft/317.wav  \n",
            "  inflating: sampled_audio4ft/318.wav  \n",
            "  inflating: sampled_audio4ft/319.wav  \n",
            "  inflating: sampled_audio4ft/32.wav  \n",
            "  inflating: sampled_audio4ft/320.wav  \n",
            "  inflating: sampled_audio4ft/321.wav  \n",
            "  inflating: sampled_audio4ft/322.wav  \n",
            "  inflating: sampled_audio4ft/323.wav  \n",
            "  inflating: sampled_audio4ft/324.wav  \n",
            "  inflating: sampled_audio4ft/325.wav  \n",
            "  inflating: sampled_audio4ft/326.wav  \n",
            "  inflating: sampled_audio4ft/327.wav  \n",
            "  inflating: sampled_audio4ft/328.wav  \n",
            "  inflating: sampled_audio4ft/329.wav  \n",
            "  inflating: sampled_audio4ft/33.wav  \n",
            "  inflating: sampled_audio4ft/330.wav  \n",
            "  inflating: sampled_audio4ft/331.wav  \n",
            "  inflating: sampled_audio4ft/332.wav  \n",
            "  inflating: sampled_audio4ft/333.wav  \n",
            "  inflating: sampled_audio4ft/334.wav  \n",
            "  inflating: sampled_audio4ft/335.wav  \n",
            "  inflating: sampled_audio4ft/336.wav  \n",
            "  inflating: sampled_audio4ft/337.wav  \n",
            "  inflating: sampled_audio4ft/338.wav  \n",
            "  inflating: sampled_audio4ft/339.wav  \n",
            "  inflating: sampled_audio4ft/34.wav  \n",
            "  inflating: sampled_audio4ft/340.wav  \n",
            "  inflating: sampled_audio4ft/341.wav  \n",
            "  inflating: sampled_audio4ft/342.wav  \n",
            "  inflating: sampled_audio4ft/343.wav  \n",
            "  inflating: sampled_audio4ft/344.wav  \n",
            "  inflating: sampled_audio4ft/345.wav  \n",
            "  inflating: sampled_audio4ft/346.wav  \n",
            "  inflating: sampled_audio4ft/347.wav  \n",
            "  inflating: sampled_audio4ft/348.wav  \n",
            "  inflating: sampled_audio4ft/349.wav  \n",
            "  inflating: sampled_audio4ft/35.wav  \n",
            "  inflating: sampled_audio4ft/350.wav  \n",
            "  inflating: sampled_audio4ft/351.wav  \n",
            "  inflating: sampled_audio4ft/352.wav  \n",
            "  inflating: sampled_audio4ft/353.wav  \n",
            "  inflating: sampled_audio4ft/354.wav  \n",
            "  inflating: sampled_audio4ft/355.wav  \n",
            "  inflating: sampled_audio4ft/356.wav  \n",
            "  inflating: sampled_audio4ft/357.wav  \n",
            "  inflating: sampled_audio4ft/358.wav  \n",
            "  inflating: sampled_audio4ft/359.wav  \n",
            "  inflating: sampled_audio4ft/36.wav  \n",
            "  inflating: sampled_audio4ft/360.wav  \n",
            "  inflating: sampled_audio4ft/361.wav  \n",
            "  inflating: sampled_audio4ft/362.wav  \n",
            "  inflating: sampled_audio4ft/363.wav  \n",
            "  inflating: sampled_audio4ft/364.wav  \n",
            "  inflating: sampled_audio4ft/365.wav  \n",
            "  inflating: sampled_audio4ft/366.wav  \n",
            "  inflating: sampled_audio4ft/367.wav  \n",
            "  inflating: sampled_audio4ft/368.wav  \n",
            "  inflating: sampled_audio4ft/369.wav  \n",
            "  inflating: sampled_audio4ft/37.wav  \n",
            "  inflating: sampled_audio4ft/370.wav  \n",
            "  inflating: sampled_audio4ft/371.wav  \n",
            "  inflating: sampled_audio4ft/372.wav  \n",
            "  inflating: sampled_audio4ft/373.wav  \n",
            "  inflating: sampled_audio4ft/374.wav  \n",
            "  inflating: sampled_audio4ft/375.wav  \n",
            "  inflating: sampled_audio4ft/376.wav  \n",
            "  inflating: sampled_audio4ft/377.wav  \n",
            "  inflating: sampled_audio4ft/378.wav  \n",
            "  inflating: sampled_audio4ft/379.wav  \n",
            "  inflating: sampled_audio4ft/38.wav  \n",
            "  inflating: sampled_audio4ft/380.wav  \n",
            "  inflating: sampled_audio4ft/381.wav  \n",
            "  inflating: sampled_audio4ft/382.wav  \n",
            "  inflating: sampled_audio4ft/383.wav  \n",
            "  inflating: sampled_audio4ft/384.wav  \n",
            "  inflating: sampled_audio4ft/385.wav  \n",
            "  inflating: sampled_audio4ft/386.wav  \n",
            "  inflating: sampled_audio4ft/387.wav  \n",
            "  inflating: sampled_audio4ft/388.wav  \n",
            "  inflating: sampled_audio4ft/389.wav  \n",
            "  inflating: sampled_audio4ft/39.wav  \n",
            "  inflating: sampled_audio4ft/390.wav  \n",
            "  inflating: sampled_audio4ft/391.wav  \n",
            "  inflating: sampled_audio4ft/392.wav  \n",
            "  inflating: sampled_audio4ft/393.wav  \n",
            "  inflating: sampled_audio4ft/394.wav  \n",
            "  inflating: sampled_audio4ft/395.wav  \n",
            "  inflating: sampled_audio4ft/396.wav  \n",
            "  inflating: sampled_audio4ft/397.wav  \n",
            "  inflating: sampled_audio4ft/398.wav  \n",
            "  inflating: sampled_audio4ft/399.wav  \n",
            "  inflating: sampled_audio4ft/4.wav  \n",
            "  inflating: sampled_audio4ft/40.wav  \n",
            "  inflating: sampled_audio4ft/400.wav  \n",
            "  inflating: sampled_audio4ft/401.wav  \n",
            "  inflating: sampled_audio4ft/402.wav  \n",
            "  inflating: sampled_audio4ft/403.wav  \n",
            "  inflating: sampled_audio4ft/404.wav  \n",
            "  inflating: sampled_audio4ft/405.wav  \n",
            "  inflating: sampled_audio4ft/406.wav  \n",
            "  inflating: sampled_audio4ft/407.wav  \n",
            "  inflating: sampled_audio4ft/408.wav  \n",
            "  inflating: sampled_audio4ft/409.wav  \n",
            "  inflating: sampled_audio4ft/41.wav  \n",
            "  inflating: sampled_audio4ft/410.wav  \n",
            "  inflating: sampled_audio4ft/411.wav  \n",
            "  inflating: sampled_audio4ft/412.wav  \n",
            "  inflating: sampled_audio4ft/413.wav  \n",
            "  inflating: sampled_audio4ft/414.wav  \n",
            "  inflating: sampled_audio4ft/415.wav  \n",
            "  inflating: sampled_audio4ft/416.wav  \n",
            "  inflating: sampled_audio4ft/417.wav  \n",
            "  inflating: sampled_audio4ft/418.wav  \n",
            "  inflating: sampled_audio4ft/419.wav  \n",
            "  inflating: sampled_audio4ft/42.wav  \n",
            "  inflating: sampled_audio4ft/420.wav  \n",
            "  inflating: sampled_audio4ft/421.wav  \n",
            "  inflating: sampled_audio4ft/422.wav  \n",
            "  inflating: sampled_audio4ft/423.wav  \n",
            "  inflating: sampled_audio4ft/424.wav  \n",
            "  inflating: sampled_audio4ft/425.wav  \n",
            "  inflating: sampled_audio4ft/426.wav  \n",
            "  inflating: sampled_audio4ft/427.wav  \n",
            "  inflating: sampled_audio4ft/428.wav  \n",
            "  inflating: sampled_audio4ft/429.wav  \n",
            "  inflating: sampled_audio4ft/43.wav  \n",
            "  inflating: sampled_audio4ft/430.wav  \n",
            "  inflating: sampled_audio4ft/431.wav  \n",
            "  inflating: sampled_audio4ft/432.wav  \n",
            "  inflating: sampled_audio4ft/433.wav  \n",
            "  inflating: sampled_audio4ft/434.wav  \n",
            "  inflating: sampled_audio4ft/435.wav  \n",
            "  inflating: sampled_audio4ft/436.wav  \n",
            "  inflating: sampled_audio4ft/437.wav  \n",
            "  inflating: sampled_audio4ft/438.wav  \n",
            "  inflating: sampled_audio4ft/439.wav  \n",
            "  inflating: sampled_audio4ft/44.wav  \n",
            "  inflating: sampled_audio4ft/440.wav  \n",
            "  inflating: sampled_audio4ft/441.wav  \n",
            "  inflating: sampled_audio4ft/442.wav  \n",
            "  inflating: sampled_audio4ft/443.wav  \n",
            "  inflating: sampled_audio4ft/444.wav  \n",
            "  inflating: sampled_audio4ft/445.wav  \n",
            "  inflating: sampled_audio4ft/446.wav  \n",
            "  inflating: sampled_audio4ft/447.wav  \n",
            "  inflating: sampled_audio4ft/448.wav  \n",
            "  inflating: sampled_audio4ft/449.wav  \n",
            "  inflating: sampled_audio4ft/45.wav  \n",
            "  inflating: sampled_audio4ft/450.wav  \n",
            "  inflating: sampled_audio4ft/451.wav  \n",
            "  inflating: sampled_audio4ft/452.wav  \n",
            "  inflating: sampled_audio4ft/453.wav  \n",
            "  inflating: sampled_audio4ft/454.wav  \n",
            "  inflating: sampled_audio4ft/455.wav  \n",
            "  inflating: sampled_audio4ft/456.wav  \n",
            "  inflating: sampled_audio4ft/457.wav  \n",
            "  inflating: sampled_audio4ft/458.wav  \n",
            "  inflating: sampled_audio4ft/459.wav  \n",
            "  inflating: sampled_audio4ft/46.wav  \n",
            "  inflating: sampled_audio4ft/460.wav  \n",
            "  inflating: sampled_audio4ft/461.wav  \n",
            "  inflating: sampled_audio4ft/462.wav  \n",
            "  inflating: sampled_audio4ft/463.wav  \n",
            "  inflating: sampled_audio4ft/464.wav  \n",
            "  inflating: sampled_audio4ft/465.wav  \n",
            "  inflating: sampled_audio4ft/466.wav  \n",
            "  inflating: sampled_audio4ft/467.wav  \n",
            "  inflating: sampled_audio4ft/468.wav  \n",
            "  inflating: sampled_audio4ft/469.wav  \n",
            "  inflating: sampled_audio4ft/47.wav  \n",
            "  inflating: sampled_audio4ft/470.wav  \n",
            "  inflating: sampled_audio4ft/471.wav  \n",
            "  inflating: sampled_audio4ft/472.wav  \n",
            "  inflating: sampled_audio4ft/473.wav  \n",
            "  inflating: sampled_audio4ft/474.wav  \n",
            "  inflating: sampled_audio4ft/475.wav  \n",
            "  inflating: sampled_audio4ft/476.wav  \n",
            "  inflating: sampled_audio4ft/477.wav  \n",
            "  inflating: sampled_audio4ft/478.wav  \n",
            "  inflating: sampled_audio4ft/479.wav  \n",
            "  inflating: sampled_audio4ft/48.wav  \n",
            "  inflating: sampled_audio4ft/480.wav  \n",
            "  inflating: sampled_audio4ft/481.wav  \n",
            "  inflating: sampled_audio4ft/482.wav  \n",
            "  inflating: sampled_audio4ft/483.wav  \n",
            "  inflating: sampled_audio4ft/484.wav  \n",
            "  inflating: sampled_audio4ft/485.wav  \n",
            "  inflating: sampled_audio4ft/486.wav  \n",
            "  inflating: sampled_audio4ft/487.wav  \n",
            "  inflating: sampled_audio4ft/488.wav  \n",
            "  inflating: sampled_audio4ft/489.wav  \n",
            "  inflating: sampled_audio4ft/49.wav  \n",
            "  inflating: sampled_audio4ft/490.wav  \n",
            "  inflating: sampled_audio4ft/491.wav  \n",
            "  inflating: sampled_audio4ft/492.wav  \n",
            "  inflating: sampled_audio4ft/493.wav  \n",
            "  inflating: sampled_audio4ft/494.wav  \n",
            "  inflating: sampled_audio4ft/495.wav  \n",
            "  inflating: sampled_audio4ft/496.wav  \n",
            "  inflating: sampled_audio4ft/497.wav  \n",
            "  inflating: sampled_audio4ft/498.wav  \n",
            "  inflating: sampled_audio4ft/499.wav  \n",
            "  inflating: sampled_audio4ft/5.wav  \n",
            "  inflating: sampled_audio4ft/50.wav  \n",
            "  inflating: sampled_audio4ft/500.wav  \n",
            "  inflating: sampled_audio4ft/501.wav  \n",
            "  inflating: sampled_audio4ft/502.wav  \n",
            "  inflating: sampled_audio4ft/503.wav  \n",
            "  inflating: sampled_audio4ft/504.wav  \n",
            "  inflating: sampled_audio4ft/505.wav  \n",
            "  inflating: sampled_audio4ft/506.wav  \n",
            "  inflating: sampled_audio4ft/507.wav  \n",
            "  inflating: sampled_audio4ft/508.wav  \n",
            "  inflating: sampled_audio4ft/509.wav  \n",
            "  inflating: sampled_audio4ft/51.wav  \n",
            "  inflating: sampled_audio4ft/510.wav  \n",
            "  inflating: sampled_audio4ft/511.wav  \n",
            "  inflating: sampled_audio4ft/512.wav  \n",
            "  inflating: sampled_audio4ft/513.wav  \n",
            "  inflating: sampled_audio4ft/514.wav  \n",
            "  inflating: sampled_audio4ft/515.wav  \n",
            "  inflating: sampled_audio4ft/516.wav  \n",
            "  inflating: sampled_audio4ft/517.wav  \n",
            "  inflating: sampled_audio4ft/518.wav  \n",
            "  inflating: sampled_audio4ft/519.wav  \n",
            "  inflating: sampled_audio4ft/52.wav  \n",
            "  inflating: sampled_audio4ft/520.wav  \n",
            "  inflating: sampled_audio4ft/521.wav  \n",
            "  inflating: sampled_audio4ft/522.wav  \n",
            "  inflating: sampled_audio4ft/523.wav  \n",
            "  inflating: sampled_audio4ft/524.wav  \n",
            "  inflating: sampled_audio4ft/525.wav  \n",
            "  inflating: sampled_audio4ft/526.wav  \n",
            "  inflating: sampled_audio4ft/527.wav  \n",
            "  inflating: sampled_audio4ft/528.wav  \n",
            "  inflating: sampled_audio4ft/529.wav  \n",
            "  inflating: sampled_audio4ft/53.wav  \n",
            "  inflating: sampled_audio4ft/530.wav  \n",
            "  inflating: sampled_audio4ft/531.wav  \n",
            "  inflating: sampled_audio4ft/532.wav  \n",
            "  inflating: sampled_audio4ft/533.wav  \n",
            "  inflating: sampled_audio4ft/534.wav  \n",
            "  inflating: sampled_audio4ft/535.wav  \n",
            "  inflating: sampled_audio4ft/536.wav  \n",
            "  inflating: sampled_audio4ft/537.wav  \n",
            "  inflating: sampled_audio4ft/538.wav  \n",
            "  inflating: sampled_audio4ft/539.wav  \n",
            "  inflating: sampled_audio4ft/54.wav  \n",
            "  inflating: sampled_audio4ft/540.wav  \n",
            "  inflating: sampled_audio4ft/541.wav  \n",
            "  inflating: sampled_audio4ft/542.wav  \n",
            "  inflating: sampled_audio4ft/543.wav  \n",
            "  inflating: sampled_audio4ft/544.wav  \n",
            "  inflating: sampled_audio4ft/545.wav  \n",
            "  inflating: sampled_audio4ft/546.wav  \n",
            "  inflating: sampled_audio4ft/547.wav  \n",
            "  inflating: sampled_audio4ft/548.wav  \n",
            "  inflating: sampled_audio4ft/549.wav  \n",
            "  inflating: sampled_audio4ft/55.wav  \n",
            "  inflating: sampled_audio4ft/550.wav  \n",
            "  inflating: sampled_audio4ft/551.wav  \n",
            "  inflating: sampled_audio4ft/552.wav  \n",
            "  inflating: sampled_audio4ft/553.wav  \n",
            "  inflating: sampled_audio4ft/554.wav  \n",
            "  inflating: sampled_audio4ft/555.wav  \n",
            "  inflating: sampled_audio4ft/556.wav  \n",
            "  inflating: sampled_audio4ft/557.wav  \n",
            "  inflating: sampled_audio4ft/558.wav  \n",
            "  inflating: sampled_audio4ft/559.wav  \n",
            "  inflating: sampled_audio4ft/56.wav  \n",
            "  inflating: sampled_audio4ft/560.wav  \n",
            "  inflating: sampled_audio4ft/561.wav  \n",
            "  inflating: sampled_audio4ft/562.wav  \n",
            "  inflating: sampled_audio4ft/563.wav  \n",
            "  inflating: sampled_audio4ft/564.wav  \n",
            "  inflating: sampled_audio4ft/565.wav  \n",
            "  inflating: sampled_audio4ft/566.wav  \n",
            "  inflating: sampled_audio4ft/567.wav  \n",
            "  inflating: sampled_audio4ft/568.wav  \n",
            "  inflating: sampled_audio4ft/569.wav  \n",
            "  inflating: sampled_audio4ft/57.wav  \n",
            "  inflating: sampled_audio4ft/570.wav  \n",
            "  inflating: sampled_audio4ft/571.wav  \n",
            "  inflating: sampled_audio4ft/572.wav  \n",
            "  inflating: sampled_audio4ft/573.wav  \n",
            "  inflating: sampled_audio4ft/574.wav  \n",
            "  inflating: sampled_audio4ft/575.wav  \n",
            "  inflating: sampled_audio4ft/576.wav  \n",
            "  inflating: sampled_audio4ft/577.wav  \n",
            "  inflating: sampled_audio4ft/578.wav  \n",
            "  inflating: sampled_audio4ft/579.wav  \n",
            "  inflating: sampled_audio4ft/58.wav  \n",
            "  inflating: sampled_audio4ft/580.wav  \n",
            "  inflating: sampled_audio4ft/581.wav  \n",
            "  inflating: sampled_audio4ft/582.wav  \n",
            "  inflating: sampled_audio4ft/583.wav  \n",
            "  inflating: sampled_audio4ft/584.wav  \n",
            "  inflating: sampled_audio4ft/585.wav  \n",
            "  inflating: sampled_audio4ft/586.wav  \n",
            "  inflating: sampled_audio4ft/587.wav  \n",
            "  inflating: sampled_audio4ft/588.wav  \n",
            "  inflating: sampled_audio4ft/589.wav  \n",
            "  inflating: sampled_audio4ft/59.wav  \n",
            "  inflating: sampled_audio4ft/590.wav  \n",
            "  inflating: sampled_audio4ft/591.wav  \n",
            "  inflating: sampled_audio4ft/592.wav  \n",
            "  inflating: sampled_audio4ft/593.wav  \n",
            "  inflating: sampled_audio4ft/594.wav  \n",
            "  inflating: sampled_audio4ft/595.wav  \n",
            "  inflating: sampled_audio4ft/596.wav  \n",
            "  inflating: sampled_audio4ft/597.wav  \n",
            "  inflating: sampled_audio4ft/598.wav  \n",
            "  inflating: sampled_audio4ft/599.wav  \n",
            "  inflating: sampled_audio4ft/6.wav  \n",
            "  inflating: sampled_audio4ft/60.wav  \n",
            "  inflating: sampled_audio4ft/600.wav  \n",
            "  inflating: sampled_audio4ft/601.wav  \n",
            "  inflating: sampled_audio4ft/602.wav  \n",
            "  inflating: sampled_audio4ft/603.wav  \n",
            "  inflating: sampled_audio4ft/604.wav  \n",
            "  inflating: sampled_audio4ft/605.wav  \n",
            "  inflating: sampled_audio4ft/606.wav  \n",
            "  inflating: sampled_audio4ft/607.wav  \n",
            "  inflating: sampled_audio4ft/608.wav  \n",
            "  inflating: sampled_audio4ft/609.wav  \n",
            "  inflating: sampled_audio4ft/61.wav  \n",
            "  inflating: sampled_audio4ft/610.wav  \n",
            "  inflating: sampled_audio4ft/611.wav  \n",
            "  inflating: sampled_audio4ft/612.wav  \n",
            "  inflating: sampled_audio4ft/613.wav  \n",
            "  inflating: sampled_audio4ft/614.wav  \n",
            "  inflating: sampled_audio4ft/615.wav  \n",
            "  inflating: sampled_audio4ft/616.wav  \n",
            "  inflating: sampled_audio4ft/617.wav  \n",
            "  inflating: sampled_audio4ft/618.wav  \n",
            "  inflating: sampled_audio4ft/619.wav  \n",
            "  inflating: sampled_audio4ft/62.wav  \n",
            "  inflating: sampled_audio4ft/620.wav  \n",
            "  inflating: sampled_audio4ft/621.wav  \n",
            "  inflating: sampled_audio4ft/622.wav  \n",
            "  inflating: sampled_audio4ft/623.wav  \n",
            "  inflating: sampled_audio4ft/624.wav  \n",
            "  inflating: sampled_audio4ft/625.wav  \n",
            "  inflating: sampled_audio4ft/626.wav  \n",
            "  inflating: sampled_audio4ft/627.wav  \n",
            "  inflating: sampled_audio4ft/628.wav  \n",
            "  inflating: sampled_audio4ft/629.wav  \n",
            "  inflating: sampled_audio4ft/63.wav  \n",
            "  inflating: sampled_audio4ft/630.wav  \n",
            "  inflating: sampled_audio4ft/631.wav  \n",
            "  inflating: sampled_audio4ft/632.wav  \n",
            "  inflating: sampled_audio4ft/633.wav  \n",
            "  inflating: sampled_audio4ft/634.wav  \n",
            "  inflating: sampled_audio4ft/635.wav  \n",
            "  inflating: sampled_audio4ft/636.wav  \n",
            "  inflating: sampled_audio4ft/637.wav  \n",
            "  inflating: sampled_audio4ft/638.wav  \n",
            "  inflating: sampled_audio4ft/639.wav  \n",
            "  inflating: sampled_audio4ft/64.wav  \n",
            "  inflating: sampled_audio4ft/640.wav  \n",
            "  inflating: sampled_audio4ft/641.wav  \n",
            "  inflating: sampled_audio4ft/642.wav  \n",
            "  inflating: sampled_audio4ft/643.wav  \n",
            "  inflating: sampled_audio4ft/644.wav  \n",
            "  inflating: sampled_audio4ft/645.wav  \n",
            "  inflating: sampled_audio4ft/646.wav  \n",
            "  inflating: sampled_audio4ft/647.wav  \n",
            "  inflating: sampled_audio4ft/648.wav  \n",
            "  inflating: sampled_audio4ft/649.wav  \n",
            "  inflating: sampled_audio4ft/65.wav  \n",
            "  inflating: sampled_audio4ft/650.wav  \n",
            "  inflating: sampled_audio4ft/651.wav  \n",
            "  inflating: sampled_audio4ft/652.wav  \n",
            "  inflating: sampled_audio4ft/653.wav  \n",
            "  inflating: sampled_audio4ft/654.wav  \n",
            "  inflating: sampled_audio4ft/655.wav  \n",
            "  inflating: sampled_audio4ft/656.wav  \n",
            "  inflating: sampled_audio4ft/657.wav  \n",
            "  inflating: sampled_audio4ft/658.wav  \n",
            "  inflating: sampled_audio4ft/659.wav  \n",
            "  inflating: sampled_audio4ft/66.wav  \n",
            "  inflating: sampled_audio4ft/660.wav  \n",
            "  inflating: sampled_audio4ft/661.wav  \n",
            "  inflating: sampled_audio4ft/662.wav  \n",
            "  inflating: sampled_audio4ft/663.wav  \n",
            "  inflating: sampled_audio4ft/664.wav  \n",
            "  inflating: sampled_audio4ft/665.wav  \n",
            "  inflating: sampled_audio4ft/666.wav  \n",
            "  inflating: sampled_audio4ft/667.wav  \n",
            "  inflating: sampled_audio4ft/668.wav  \n",
            "  inflating: sampled_audio4ft/669.wav  \n",
            "  inflating: sampled_audio4ft/67.wav  \n",
            "  inflating: sampled_audio4ft/670.wav  \n",
            "  inflating: sampled_audio4ft/671.wav  \n",
            "  inflating: sampled_audio4ft/672.wav  \n",
            "  inflating: sampled_audio4ft/673.wav  \n",
            "  inflating: sampled_audio4ft/674.wav  \n",
            "  inflating: sampled_audio4ft/675.wav  \n",
            "  inflating: sampled_audio4ft/676.wav  \n",
            "  inflating: sampled_audio4ft/677.wav  \n",
            "  inflating: sampled_audio4ft/678.wav  \n",
            "  inflating: sampled_audio4ft/679.wav  \n",
            "  inflating: sampled_audio4ft/68.wav  \n",
            "  inflating: sampled_audio4ft/680.wav  \n",
            "  inflating: sampled_audio4ft/681.wav  \n",
            "  inflating: sampled_audio4ft/682.wav  \n",
            "  inflating: sampled_audio4ft/683.wav  \n",
            "  inflating: sampled_audio4ft/684.wav  \n",
            "  inflating: sampled_audio4ft/685.wav  \n",
            "  inflating: sampled_audio4ft/686.wav  \n",
            "  inflating: sampled_audio4ft/687.wav  \n",
            "  inflating: sampled_audio4ft/688.wav  \n",
            "  inflating: sampled_audio4ft/689.wav  \n",
            "  inflating: sampled_audio4ft/69.wav  \n",
            "  inflating: sampled_audio4ft/690.wav  \n",
            "  inflating: sampled_audio4ft/691.wav  \n",
            "  inflating: sampled_audio4ft/692.wav  \n",
            "  inflating: sampled_audio4ft/693.wav  \n",
            "  inflating: sampled_audio4ft/694.wav  \n",
            "  inflating: sampled_audio4ft/695.wav  \n",
            "  inflating: sampled_audio4ft/696.wav  \n",
            "  inflating: sampled_audio4ft/697.wav  \n",
            "  inflating: sampled_audio4ft/698.wav  \n",
            "  inflating: sampled_audio4ft/699.wav  \n",
            "  inflating: sampled_audio4ft/7.wav  \n",
            "  inflating: sampled_audio4ft/70.wav  \n",
            "  inflating: sampled_audio4ft/700.wav  \n",
            "  inflating: sampled_audio4ft/701.wav  \n",
            "  inflating: sampled_audio4ft/702.wav  \n",
            "  inflating: sampled_audio4ft/703.wav  \n",
            "  inflating: sampled_audio4ft/704.wav  \n",
            "  inflating: sampled_audio4ft/705.wav  \n",
            "  inflating: sampled_audio4ft/706.wav  \n",
            "  inflating: sampled_audio4ft/707.wav  \n",
            "  inflating: sampled_audio4ft/708.wav  \n",
            "  inflating: sampled_audio4ft/709.wav  \n",
            "  inflating: sampled_audio4ft/71.wav  \n",
            "  inflating: sampled_audio4ft/710.wav  \n",
            "  inflating: sampled_audio4ft/711.wav  \n",
            "  inflating: sampled_audio4ft/712.wav  \n",
            "  inflating: sampled_audio4ft/713.wav  \n",
            "  inflating: sampled_audio4ft/714.wav  \n",
            "  inflating: sampled_audio4ft/715.wav  \n",
            "  inflating: sampled_audio4ft/716.wav  \n",
            "  inflating: sampled_audio4ft/717.wav  \n",
            "  inflating: sampled_audio4ft/718.wav  \n",
            "  inflating: sampled_audio4ft/719.wav  \n",
            "  inflating: sampled_audio4ft/72.wav  \n",
            "  inflating: sampled_audio4ft/720.wav  \n",
            "  inflating: sampled_audio4ft/721.wav  \n",
            "  inflating: sampled_audio4ft/722.wav  \n",
            "  inflating: sampled_audio4ft/723.wav  \n",
            "  inflating: sampled_audio4ft/724.wav  \n",
            "  inflating: sampled_audio4ft/725.wav  \n",
            "  inflating: sampled_audio4ft/726.wav  \n",
            "  inflating: sampled_audio4ft/727.wav  \n",
            "  inflating: sampled_audio4ft/728.wav  \n",
            "  inflating: sampled_audio4ft/729.wav  \n",
            "  inflating: sampled_audio4ft/73.wav  \n",
            "  inflating: sampled_audio4ft/730.wav  \n",
            "  inflating: sampled_audio4ft/731.wav  \n",
            "  inflating: sampled_audio4ft/732.wav  \n",
            "  inflating: sampled_audio4ft/733.wav  \n",
            "  inflating: sampled_audio4ft/734.wav  \n",
            "  inflating: sampled_audio4ft/735.wav  \n",
            "  inflating: sampled_audio4ft/736.wav  \n",
            "  inflating: sampled_audio4ft/737.wav  \n",
            "  inflating: sampled_audio4ft/738.wav  \n",
            "  inflating: sampled_audio4ft/739.wav  \n",
            "  inflating: sampled_audio4ft/74.wav  \n",
            "  inflating: sampled_audio4ft/740.wav  \n",
            "  inflating: sampled_audio4ft/741.wav  \n",
            "  inflating: sampled_audio4ft/742.wav  \n",
            "  inflating: sampled_audio4ft/743.wav  \n",
            "  inflating: sampled_audio4ft/744.wav  \n",
            "  inflating: sampled_audio4ft/745.wav  \n",
            "  inflating: sampled_audio4ft/746.wav  \n",
            "  inflating: sampled_audio4ft/747.wav  \n",
            "  inflating: sampled_audio4ft/748.wav  \n",
            "  inflating: sampled_audio4ft/749.wav  \n",
            "  inflating: sampled_audio4ft/75.wav  \n",
            "  inflating: sampled_audio4ft/750.wav  \n",
            "  inflating: sampled_audio4ft/751.wav  \n",
            "  inflating: sampled_audio4ft/752.wav  \n",
            "  inflating: sampled_audio4ft/753.wav  \n",
            "  inflating: sampled_audio4ft/754.wav  \n",
            "  inflating: sampled_audio4ft/755.wav  \n",
            "  inflating: sampled_audio4ft/756.wav  \n",
            "  inflating: sampled_audio4ft/757.wav  \n",
            "  inflating: sampled_audio4ft/758.wav  \n",
            "  inflating: sampled_audio4ft/759.wav  \n",
            "  inflating: sampled_audio4ft/76.wav  \n",
            "  inflating: sampled_audio4ft/760.wav  \n",
            "  inflating: sampled_audio4ft/761.wav  \n",
            "  inflating: sampled_audio4ft/762.wav  \n",
            "  inflating: sampled_audio4ft/763.wav  \n",
            "  inflating: sampled_audio4ft/764.wav  \n",
            "  inflating: sampled_audio4ft/765.wav  \n",
            "  inflating: sampled_audio4ft/766.wav  \n",
            "  inflating: sampled_audio4ft/767.wav  \n",
            "  inflating: sampled_audio4ft/768.wav  \n",
            "  inflating: sampled_audio4ft/769.wav  \n",
            "  inflating: sampled_audio4ft/77.wav  \n",
            "  inflating: sampled_audio4ft/770.wav  \n",
            "  inflating: sampled_audio4ft/771.wav  \n",
            "  inflating: sampled_audio4ft/772.wav  \n",
            "  inflating: sampled_audio4ft/773.wav  \n",
            "  inflating: sampled_audio4ft/774.wav  \n",
            "  inflating: sampled_audio4ft/775.wav  \n",
            "  inflating: sampled_audio4ft/776.wav  \n",
            "  inflating: sampled_audio4ft/777.wav  \n",
            "  inflating: sampled_audio4ft/778.wav  \n",
            "  inflating: sampled_audio4ft/779.wav  \n",
            "  inflating: sampled_audio4ft/78.wav  \n",
            "  inflating: sampled_audio4ft/780.wav  \n",
            "  inflating: sampled_audio4ft/781.wav  \n",
            "  inflating: sampled_audio4ft/782.wav  \n",
            "  inflating: sampled_audio4ft/783.wav  \n",
            "  inflating: sampled_audio4ft/784.wav  \n",
            "  inflating: sampled_audio4ft/785.wav  \n",
            "  inflating: sampled_audio4ft/786.wav  \n",
            "  inflating: sampled_audio4ft/787.wav  \n",
            "  inflating: sampled_audio4ft/788.wav  \n",
            "  inflating: sampled_audio4ft/789.wav  \n",
            "  inflating: sampled_audio4ft/79.wav  \n",
            "  inflating: sampled_audio4ft/790.wav  \n",
            "  inflating: sampled_audio4ft/791.wav  \n",
            "  inflating: sampled_audio4ft/792.wav  \n",
            "  inflating: sampled_audio4ft/793.wav  \n",
            "  inflating: sampled_audio4ft/794.wav  \n",
            "  inflating: sampled_audio4ft/795.wav  \n",
            "  inflating: sampled_audio4ft/796.wav  \n",
            "  inflating: sampled_audio4ft/797.wav  \n",
            "  inflating: sampled_audio4ft/798.wav  \n",
            "  inflating: sampled_audio4ft/799.wav  \n",
            "  inflating: sampled_audio4ft/8.wav  \n",
            "  inflating: sampled_audio4ft/80.wav  \n",
            "  inflating: sampled_audio4ft/800.wav  \n",
            "  inflating: sampled_audio4ft/801.wav  \n",
            "  inflating: sampled_audio4ft/802.wav  \n",
            "  inflating: sampled_audio4ft/803.wav  \n",
            "  inflating: sampled_audio4ft/804.wav  \n",
            "  inflating: sampled_audio4ft/805.wav  \n",
            "  inflating: sampled_audio4ft/806.wav  \n",
            "  inflating: sampled_audio4ft/807.wav  \n",
            "  inflating: sampled_audio4ft/808.wav  \n",
            "  inflating: sampled_audio4ft/809.wav  \n",
            "  inflating: sampled_audio4ft/81.wav  \n",
            "  inflating: sampled_audio4ft/810.wav  \n",
            "  inflating: sampled_audio4ft/811.wav  \n",
            "  inflating: sampled_audio4ft/812.wav  \n",
            "  inflating: sampled_audio4ft/813.wav  \n",
            "  inflating: sampled_audio4ft/814.wav  \n",
            "  inflating: sampled_audio4ft/815.wav  \n",
            "  inflating: sampled_audio4ft/816.wav  \n",
            "  inflating: sampled_audio4ft/817.wav  \n",
            "  inflating: sampled_audio4ft/818.wav  \n",
            "  inflating: sampled_audio4ft/819.wav  \n",
            "  inflating: sampled_audio4ft/82.wav  \n",
            "  inflating: sampled_audio4ft/820.wav  \n",
            "  inflating: sampled_audio4ft/821.wav  \n",
            "  inflating: sampled_audio4ft/822.wav  \n",
            "  inflating: sampled_audio4ft/823.wav  \n",
            "  inflating: sampled_audio4ft/824.wav  \n",
            "  inflating: sampled_audio4ft/825.wav  \n",
            "  inflating: sampled_audio4ft/826.wav  \n",
            "  inflating: sampled_audio4ft/827.wav  \n",
            "  inflating: sampled_audio4ft/828.wav  \n",
            "  inflating: sampled_audio4ft/829.wav  \n",
            "  inflating: sampled_audio4ft/83.wav  \n",
            "  inflating: sampled_audio4ft/830.wav  \n",
            "  inflating: sampled_audio4ft/831.wav  \n",
            "  inflating: sampled_audio4ft/832.wav  \n",
            "  inflating: sampled_audio4ft/833.wav  \n",
            "  inflating: sampled_audio4ft/834.wav  \n",
            "  inflating: sampled_audio4ft/835.wav  \n",
            "  inflating: sampled_audio4ft/836.wav  \n",
            "  inflating: sampled_audio4ft/837.wav  \n",
            "  inflating: sampled_audio4ft/838.wav  \n",
            "  inflating: sampled_audio4ft/839.wav  \n",
            "  inflating: sampled_audio4ft/84.wav  \n",
            "  inflating: sampled_audio4ft/840.wav  \n",
            "  inflating: sampled_audio4ft/841.wav  \n",
            "  inflating: sampled_audio4ft/842.wav  \n",
            "  inflating: sampled_audio4ft/843.wav  \n",
            "  inflating: sampled_audio4ft/844.wav  \n",
            "  inflating: sampled_audio4ft/845.wav  \n",
            "  inflating: sampled_audio4ft/846.wav  \n",
            "  inflating: sampled_audio4ft/847.wav  \n",
            "  inflating: sampled_audio4ft/848.wav  \n",
            "  inflating: sampled_audio4ft/849.wav  \n",
            "  inflating: sampled_audio4ft/85.wav  \n",
            "  inflating: sampled_audio4ft/850.wav  \n",
            "  inflating: sampled_audio4ft/851.wav  \n",
            "  inflating: sampled_audio4ft/852.wav  \n",
            "  inflating: sampled_audio4ft/853.wav  \n",
            "  inflating: sampled_audio4ft/854.wav  \n",
            "  inflating: sampled_audio4ft/855.wav  \n",
            "  inflating: sampled_audio4ft/856.wav  \n",
            "  inflating: sampled_audio4ft/857.wav  \n",
            "  inflating: sampled_audio4ft/858.wav  \n",
            "  inflating: sampled_audio4ft/859.wav  \n",
            "  inflating: sampled_audio4ft/86.wav  \n",
            "  inflating: sampled_audio4ft/860.wav  \n",
            "  inflating: sampled_audio4ft/861.wav  \n",
            "  inflating: sampled_audio4ft/862.wav  \n",
            "  inflating: sampled_audio4ft/863.wav  \n",
            "  inflating: sampled_audio4ft/864.wav  \n",
            "  inflating: sampled_audio4ft/865.wav  \n",
            "  inflating: sampled_audio4ft/866.wav  \n",
            "  inflating: sampled_audio4ft/867.wav  \n",
            "  inflating: sampled_audio4ft/868.wav  \n",
            "  inflating: sampled_audio4ft/869.wav  \n",
            "  inflating: sampled_audio4ft/87.wav  \n",
            "  inflating: sampled_audio4ft/870.wav  \n",
            "  inflating: sampled_audio4ft/871.wav  \n",
            "  inflating: sampled_audio4ft/872.wav  \n",
            "  inflating: sampled_audio4ft/873.wav  \n",
            "  inflating: sampled_audio4ft/874.wav  \n",
            "  inflating: sampled_audio4ft/875.wav  \n",
            "  inflating: sampled_audio4ft/876.wav  \n",
            "  inflating: sampled_audio4ft/877.wav  \n",
            "  inflating: sampled_audio4ft/878.wav  \n",
            "  inflating: sampled_audio4ft/879.wav  \n",
            "  inflating: sampled_audio4ft/88.wav  \n",
            "  inflating: sampled_audio4ft/880.wav  \n",
            "  inflating: sampled_audio4ft/881.wav  \n",
            "  inflating: sampled_audio4ft/882.wav  \n",
            "  inflating: sampled_audio4ft/883.wav  \n",
            "  inflating: sampled_audio4ft/884.wav  \n",
            "  inflating: sampled_audio4ft/885.wav  \n",
            "  inflating: sampled_audio4ft/886.wav  \n",
            "  inflating: sampled_audio4ft/887.wav  \n",
            "  inflating: sampled_audio4ft/888.wav  \n",
            "  inflating: sampled_audio4ft/889.wav  \n",
            "  inflating: sampled_audio4ft/89.wav  \n",
            "  inflating: sampled_audio4ft/890.wav  \n",
            "  inflating: sampled_audio4ft/891.wav  \n",
            "  inflating: sampled_audio4ft/892.wav  \n",
            "  inflating: sampled_audio4ft/893.wav  \n",
            "  inflating: sampled_audio4ft/894.wav  \n",
            "  inflating: sampled_audio4ft/895.wav  \n",
            "  inflating: sampled_audio4ft/896.wav  \n",
            "  inflating: sampled_audio4ft/897.wav  \n",
            "  inflating: sampled_audio4ft/898.wav  \n",
            "  inflating: sampled_audio4ft/899.wav  \n",
            "  inflating: sampled_audio4ft/9.wav  \n",
            "  inflating: sampled_audio4ft/90.wav  \n",
            "  inflating: sampled_audio4ft/900.wav  \n",
            "  inflating: sampled_audio4ft/901.wav  \n",
            "  inflating: sampled_audio4ft/902.wav  \n",
            "  inflating: sampled_audio4ft/903.wav  \n",
            "  inflating: sampled_audio4ft/904.wav  \n",
            "  inflating: sampled_audio4ft/905.wav  \n",
            "  inflating: sampled_audio4ft/906.wav  \n",
            "  inflating: sampled_audio4ft/907.wav  \n",
            "  inflating: sampled_audio4ft/908.wav  \n",
            "  inflating: sampled_audio4ft/909.wav  \n",
            "  inflating: sampled_audio4ft/91.wav  \n",
            "  inflating: sampled_audio4ft/910.wav  \n",
            "  inflating: sampled_audio4ft/911.wav  \n",
            "  inflating: sampled_audio4ft/912.wav  \n",
            "  inflating: sampled_audio4ft/913.wav  \n",
            "  inflating: sampled_audio4ft/914.wav  \n",
            "  inflating: sampled_audio4ft/915.wav  \n",
            "  inflating: sampled_audio4ft/916.wav  \n",
            "  inflating: sampled_audio4ft/917.wav  \n",
            "  inflating: sampled_audio4ft/918.wav  \n",
            "  inflating: sampled_audio4ft/919.wav  \n",
            "  inflating: sampled_audio4ft/92.wav  \n",
            "  inflating: sampled_audio4ft/920.wav  \n",
            "  inflating: sampled_audio4ft/921.wav  \n",
            "  inflating: sampled_audio4ft/922.wav  \n",
            "  inflating: sampled_audio4ft/923.wav  \n",
            "  inflating: sampled_audio4ft/924.wav  \n",
            "  inflating: sampled_audio4ft/925.wav  \n",
            "  inflating: sampled_audio4ft/926.wav  \n",
            "  inflating: sampled_audio4ft/927.wav  \n",
            "  inflating: sampled_audio4ft/928.wav  \n",
            "  inflating: sampled_audio4ft/929.wav  \n",
            "  inflating: sampled_audio4ft/93.wav  \n",
            "  inflating: sampled_audio4ft/930.wav  \n",
            "  inflating: sampled_audio4ft/931.wav  \n",
            "  inflating: sampled_audio4ft/932.wav  \n",
            "  inflating: sampled_audio4ft/933.wav  \n",
            "  inflating: sampled_audio4ft/934.wav  \n",
            "  inflating: sampled_audio4ft/935.wav  \n",
            "  inflating: sampled_audio4ft/936.wav  \n",
            "  inflating: sampled_audio4ft/937.wav  \n",
            "  inflating: sampled_audio4ft/938.wav  \n",
            "  inflating: sampled_audio4ft/939.wav  \n",
            "  inflating: sampled_audio4ft/94.wav  \n",
            "  inflating: sampled_audio4ft/940.wav  \n",
            "  inflating: sampled_audio4ft/941.wav  \n",
            "  inflating: sampled_audio4ft/942.wav  \n",
            "  inflating: sampled_audio4ft/943.wav  \n",
            "  inflating: sampled_audio4ft/944.wav  \n",
            "  inflating: sampled_audio4ft/945.wav  \n",
            "  inflating: sampled_audio4ft/946.wav  \n",
            "  inflating: sampled_audio4ft/947.wav  \n",
            "  inflating: sampled_audio4ft/948.wav  \n",
            "  inflating: sampled_audio4ft/949.wav  \n",
            "  inflating: sampled_audio4ft/95.wav  \n",
            "  inflating: sampled_audio4ft/950.wav  \n",
            "  inflating: sampled_audio4ft/951.wav  \n",
            "  inflating: sampled_audio4ft/952.wav  \n",
            "  inflating: sampled_audio4ft/953.wav  \n",
            "  inflating: sampled_audio4ft/954.wav  \n",
            "  inflating: sampled_audio4ft/955.wav  \n",
            "  inflating: sampled_audio4ft/956.wav  \n",
            "  inflating: sampled_audio4ft/957.wav  \n",
            "  inflating: sampled_audio4ft/958.wav  \n",
            "  inflating: sampled_audio4ft/959.wav  \n",
            "  inflating: sampled_audio4ft/96.wav  \n",
            "  inflating: sampled_audio4ft/960.wav  \n",
            "  inflating: sampled_audio4ft/961.wav  \n",
            "  inflating: sampled_audio4ft/962.wav  \n",
            "  inflating: sampled_audio4ft/963.wav  \n",
            "  inflating: sampled_audio4ft/964.wav  \n",
            "  inflating: sampled_audio4ft/965.wav  \n",
            "  inflating: sampled_audio4ft/966.wav  \n",
            "  inflating: sampled_audio4ft/967.wav  \n",
            "  inflating: sampled_audio4ft/968.wav  \n",
            "  inflating: sampled_audio4ft/969.wav  \n",
            "  inflating: sampled_audio4ft/97.wav  \n",
            "  inflating: sampled_audio4ft/970.wav  \n",
            "  inflating: sampled_audio4ft/971.wav  \n",
            "  inflating: sampled_audio4ft/972.wav  \n",
            "  inflating: sampled_audio4ft/973.wav  \n",
            "  inflating: sampled_audio4ft/974.wav  \n",
            "  inflating: sampled_audio4ft/975.wav  \n",
            "  inflating: sampled_audio4ft/976.wav  \n",
            "  inflating: sampled_audio4ft/977.wav  \n",
            "  inflating: sampled_audio4ft/978.wav  \n",
            "  inflating: sampled_audio4ft/979.wav  \n",
            "  inflating: sampled_audio4ft/98.wav  \n",
            "  inflating: sampled_audio4ft/980.wav  \n",
            "  inflating: sampled_audio4ft/981.wav  \n",
            "  inflating: sampled_audio4ft/982.wav  \n",
            "  inflating: sampled_audio4ft/983.wav  \n",
            "  inflating: sampled_audio4ft/984.wav  \n",
            "  inflating: sampled_audio4ft/985.wav  \n",
            "  inflating: sampled_audio4ft/986.wav  \n",
            "  inflating: sampled_audio4ft/987.wav  \n",
            "  inflating: sampled_audio4ft/988.wav  \n",
            "  inflating: sampled_audio4ft/989.wav  \n",
            "  inflating: sampled_audio4ft/99.wav  \n",
            "  inflating: sampled_audio4ft/990.wav  \n",
            "  inflating: sampled_audio4ft/991.wav  \n",
            "  inflating: sampled_audio4ft/992.wav  \n",
            "  inflating: sampled_audio4ft/993.wav  \n",
            "  inflating: sampled_audio4ft/994.wav  \n",
            "  inflating: sampled_audio4ft/995.wav  \n",
            "  inflating: sampled_audio4ft/996.wav  \n",
            "  inflating: sampled_audio4ft/997.wav  \n",
            "  inflating: sampled_audio4ft/998.wav  \n",
            "  inflating: sampled_audio4ft/999.wav  \n",
            "  inflating: sampled_audio4ft.txt    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title STEP 1.5 选择预训练模型\n",
        "#@markdown ###STEP 1.5 选择预训练模型\n",
        "#@markdown ###Choose pretrained model to start\n",
        "#@markdown CJE为中日英三语模型，CJ为中日双语模型，C为纯中文模型\n",
        "\n",
        "#@markdown CJE for Chinese, Japanese & English model，CJ for Chinese & Japanese model\n",
        "PRETRAINED_MODEL = \"CJ\" #@param [\"CJE\",\"CJ\",\"C\"]\n",
        "if PRETRAINED_MODEL == \"CJ\":\n",
        "  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth -O ./pretrained_models/D_0.pth\n",
        "  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth -O ./pretrained_models/G_0.pth\n",
        "  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json -O ./configs/finetune_speaker.json\n",
        "elif PRETRAINED_MODEL == \"CJE\":\n",
        "  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth\n",
        "  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth\n",
        "  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json\n",
        "elif PRETRAINED_MODEL == \"C\":\n",
        "  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/D_0.pth -O ./pretrained_models/D_0.pth\n",
        "  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/G_0.pth -O ./pretrained_models/G_0.pth\n",
        "  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/config.json -O ./configs/finetune_speaker.json"
      ],
      "metadata": {
        "id": "2tzsb5mR6-d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546aacec-4638-4616-faf1-8054f2f3effe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-08 02:23:55--  https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.59, 3.165.160.61, 3.165.160.11, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /spaces/zomehwh/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth [following]\n",
            "--2025-01-08 02:23:55--  https://huggingface.co/spaces/zomehwh/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/73/57/7357194223863ef0c28d9dd59386c0c4933f0105f0b51e2d107958e679c17cd6/afb0deef1470921019c7edff2e648eee4c35eeae6d4458d1b86fe2ad6c86a4e0?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27D_0-p.pth%3B+filename%3D%22D_0-p.pth%22%3B&Expires=1736562235&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNjU2MjIzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83My81Ny83MzU3MTk0MjIzODYzZWYwYzI4ZDlkZDU5Mzg2YzBjNDkzM2YwMTA1ZjBiNTFlMmQxMDc5NThlNjc5YzE3Y2Q2L2FmYjBkZWVmMTQ3MDkyMTAxOWM3ZWRmZjJlNjQ4ZWVlNGMzNWVlYWU2ZDQ0NThkMWI4NmZlMmFkNmM4NmE0ZTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=DFPFGlpxwzTp9YWdj17v4-VV5feW%7EAwjDlQSALCIHFJLEz0Tz%7E7tF2CGiHjkLdThoHSHoH-VJA8zA1IRrxaVaWrnKsudYvz9xGr2TGUWuj%7Et53iK2oOujK5NiaLAVKWJeHPpuA6fauWyTIu-%7EHz4YOFO8Q0NCQ362HGLJyb9UIJNrigqtWI81UM3b8K8eimVPnO5aIFgggefimN38KrkeetW6lsg%7EehppQc91RcMCvLb%7EPWm%7E8sbqTnlNfP63mxRjEnrCOZrZTjMCl1Ubp%7Ehx0e7xm1ot2xbR4OqmUtGuAavTAVeQ8P1pj8q%7EwTNolsOVb-S-MDnGiu3XBPeaEGvOA__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-01-08 02:23:55--  https://cdn-lfs.hf.co/repos/73/57/7357194223863ef0c28d9dd59386c0c4933f0105f0b51e2d107958e679c17cd6/afb0deef1470921019c7edff2e648eee4c35eeae6d4458d1b86fe2ad6c86a4e0?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27D_0-p.pth%3B+filename%3D%22D_0-p.pth%22%3B&Expires=1736562235&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNjU2MjIzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83My81Ny83MzU3MTk0MjIzODYzZWYwYzI4ZDlkZDU5Mzg2YzBjNDkzM2YwMTA1ZjBiNTFlMmQxMDc5NThlNjc5YzE3Y2Q2L2FmYjBkZWVmMTQ3MDkyMTAxOWM3ZWRmZjJlNjQ4ZWVlNGMzNWVlYWU2ZDQ0NThkMWI4NmZlMmFkNmM4NmE0ZTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=DFPFGlpxwzTp9YWdj17v4-VV5feW%7EAwjDlQSALCIHFJLEz0Tz%7E7tF2CGiHjkLdThoHSHoH-VJA8zA1IRrxaVaWrnKsudYvz9xGr2TGUWuj%7Et53iK2oOujK5NiaLAVKWJeHPpuA6fauWyTIu-%7EHz4YOFO8Q0NCQ362HGLJyb9UIJNrigqtWI81UM3b8K8eimVPnO5aIFgggefimN38KrkeetW6lsg%7EehppQc91RcMCvLb%7EPWm%7E8sbqTnlNfP63mxRjEnrCOZrZTjMCl1Ubp%7Ehx0e7xm1ot2xbR4OqmUtGuAavTAVeQ8P1pj8q%7EwTNolsOVb-S-MDnGiu3XBPeaEGvOA__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.238.217.113, 18.238.217.120, 18.238.217.81, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.238.217.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187022499 (178M) [binary/octet-stream]\n",
            "Saving to: ‘./pretrained_models/D_0.pth’\n",
            "\n",
            "./pretrained_models 100%[===================>] 178.36M   172MB/s    in 1.0s    \n",
            "\n",
            "2025-01-08 02:23:57 (172 MB/s) - ‘./pretrained_models/D_0.pth’ saved [187022499/187022499]\n",
            "\n",
            "--2025-01-08 02:23:57--  https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.59, 3.165.160.11, 3.165.160.12, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /spaces/zomehwh/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth [following]\n",
            "--2025-01-08 02:23:57--  https://huggingface.co/spaces/zomehwh/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/73/57/7357194223863ef0c28d9dd59386c0c4933f0105f0b51e2d107958e679c17cd6/18915a2f2021f39cea821795fa78c8145e3a9fbcc0ef72744b478b7fb403304d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27G_0-p.pth%3B+filename%3D%22G_0-p.pth%22%3B&Expires=1736562237&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNjU2MjIzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83My81Ny83MzU3MTk0MjIzODYzZWYwYzI4ZDlkZDU5Mzg2YzBjNDkzM2YwMTA1ZjBiNTFlMmQxMDc5NThlNjc5YzE3Y2Q2LzE4OTE1YTJmMjAyMWYzOWNlYTgyMTc5NWZhNzhjODE0NWUzYTlmYmNjMGVmNzI3NDRiNDc4YjdmYjQwMzMwNGQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=j82Pz-6ImG2hF28LMXIBU0lzrjsyAJSrufS4ENk-08ooVVdgbXyXnjnqkNthB0UxYEx9Z2ulUOrbqWkIbAXs%7EnfjV6fsJGzUsTBJpvERjezO%7E7H6iXSKm8L%7EjcEQXKzm6-XrG574lIZwOLEmfYJMwARSJZIME0bMR%7EWoUPZYzRPhqlST5MS-GJydCcEl-AISl2wo7K4lgsg27PzOQGsPFXq%7EEIbwC5vvT7vF5DyFENsPTWQGimasGyT9izxEUMVUKKucN29sqJ3UeHarHpQx5klNn2LcSH0FmtlPk%7E10tRoQGWYWdQwEkmnoBtIH%7EAJ2Mk-yHGWjZJYz89qcfu8FzA__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-01-08 02:23:57--  https://cdn-lfs.hf.co/repos/73/57/7357194223863ef0c28d9dd59386c0c4933f0105f0b51e2d107958e679c17cd6/18915a2f2021f39cea821795fa78c8145e3a9fbcc0ef72744b478b7fb403304d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27G_0-p.pth%3B+filename%3D%22G_0-p.pth%22%3B&Expires=1736562237&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNjU2MjIzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83My81Ny83MzU3MTk0MjIzODYzZWYwYzI4ZDlkZDU5Mzg2YzBjNDkzM2YwMTA1ZjBiNTFlMmQxMDc5NThlNjc5YzE3Y2Q2LzE4OTE1YTJmMjAyMWYzOWNlYTgyMTc5NWZhNzhjODE0NWUzYTlmYmNjMGVmNzI3NDRiNDc4YjdmYjQwMzMwNGQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=j82Pz-6ImG2hF28LMXIBU0lzrjsyAJSrufS4ENk-08ooVVdgbXyXnjnqkNthB0UxYEx9Z2ulUOrbqWkIbAXs%7EnfjV6fsJGzUsTBJpvERjezO%7E7H6iXSKm8L%7EjcEQXKzm6-XrG574lIZwOLEmfYJMwARSJZIME0bMR%7EWoUPZYzRPhqlST5MS-GJydCcEl-AISl2wo7K4lgsg27PzOQGsPFXq%7EEIbwC5vvT7vF5DyFENsPTWQGimasGyT9izxEUMVUKKucN29sqJ3UeHarHpQx5klNn2LcSH0FmtlPk%7E10tRoQGWYWdQwEkmnoBtIH%7EAJ2Mk-yHGWjZJYz89qcfu8FzA__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.238.217.113, 18.238.217.120, 18.238.217.81, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.238.217.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 158856783 (151M) [binary/octet-stream]\n",
            "Saving to: ‘./pretrained_models/G_0.pth’\n",
            "\n",
            "./pretrained_models 100%[===================>] 151.50M   185MB/s    in 0.8s    \n",
            "\n",
            "2025-01-08 02:23:58 (185 MB/s) - ‘./pretrained_models/G_0.pth’ saved [158856783/158856783]\n",
            "\n",
            "--2025-01-08 02:23:58--  https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.59, 3.165.160.11, 3.165.160.12, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /spaces/zomehwh/vits-uma-genshin-honkai/resolve/main/model/config.json [following]\n",
            "--2025-01-08 02:23:58--  https://huggingface.co/spaces/zomehwh/vits-uma-genshin-honkai/resolve/main/model/config.json\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22375 (22K) [text/plain]\n",
            "Saving to: ‘./configs/finetune_speaker.json’\n",
            "\n",
            "./configs/finetune_ 100%[===================>]  21.85K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-08 02:23:58 (296 MB/s) - ‘./configs/finetune_speaker.json’ saved [22375/22375]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title （可选）加载Google云端硬盘 / Mount Google drive\n",
        "#@title (optional)\n",
        "\n",
        "#@markdown 加载Google云端硬盘（更快地上传数据集文件）\n",
        "\n",
        "#@markdown Mount Google drive for faster data upload\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j1Q43oXND7Ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44258ac8-b8c0-4d9f-8961-e4a352607c9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2 上传您的角色音频数据\n",
        "## Upload your character voices\n",
        "见[数据集上传选项](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/DATA.MD)\n",
        "See [data upload options](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/DATA_EN.MD)\n"
      ],
      "metadata": {
        "id": "Z5G1jozPFd6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STEP 2.1 上传短音频\n",
        "### Short audio upload"
      ],
      "metadata": {
        "id": "Wjpr__yCPp_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 上传选项1：运行该代码块会出现一个文件上传的入口\n",
        "\n",
        "#@markdown Upload option 1: Running this code block will prompt you to upload a file.\n",
        "%run scripts/voice_upload.py --type zip\n",
        "!unzip ./custom_character_voice/custom_character_voice.zip -d ./custom_character_voice/"
      ],
      "metadata": {
        "id": "hmNHnpBL5sgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 上传选项2：若您装载了Google云端硬盘，可以直接从Google云端硬盘加载文件。将`.zip`文件上传云端硬盘后，在下面填写文件路径：\n",
        "\n",
        "#@markdown Upload option 2: If you have mounted Google drive, you can load your files from Google drive directly. After uploading your `.zip` file to Google drive, fill in the path to your file below:\n",
        "ZIP_PATH = \"../drive/MyDrive/samples.zip\"  #@param {type:\"string\"}\n",
        "!cp {ZIP_PATH} ./custom_character_voice/custom_character_voice.zip\n",
        "!unzip ./custom_character_voice/custom_character_voice.zip -d ./custom_character_voice/"
      ],
      "metadata": {
        "id": "YOfe2ercNLal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2.2 上传长音频 （单个不应长于20分钟）\n",
        "### Long audio upload"
      ],
      "metadata": {
        "id": "FLGkhbvhP33f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 上传选项1：运行该代码块会出现一个文件上传的入口\n",
        "\n",
        "#@markdown Upload option 1: Running this code block will prompt you to upload a file.\n",
        "%run scripts/voice_upload.py --type audio"
      ],
      "metadata": {
        "id": "unvLB7zrQTVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 上传选项2：若您装载了Google云端硬盘，可以直接从Google云端硬盘加载文件。将所有长音频文件上传至云端硬盘的同一个文件夹下，在下面填写文件夹路径：\n",
        "\n",
        "#@markdown Upload option 2: If you have mounted Google drive, you can load your files from Google drive directly. Put all the long audios under one folder, and fill in the path to your folder below:\n",
        "AUDIO_FOLDER_PATH = \"../drive/MyDrive/long_audios/\"  #@param {type:\"string\"}\n",
        "!cp {AUDIO_FOLDER_PATH}/* ./raw_audio/"
      ],
      "metadata": {
        "id": "-GWXUozRTZsj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2.3 上传视频（单个不应长于20分钟）\n",
        "### Video upload"
      ],
      "metadata": {
        "id": "5IDg3hAgWY0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 上传选项1：运行该代码块会出现一个文件上传的入口\n",
        "\n",
        "#@markdown Upload option 1: Running this code block will prompt you to upload a file.\n",
        "%run scripts/voice_upload.py --type video"
      ],
      "metadata": {
        "id": "A4Fk-06bXq7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 上传选项2：若您装载了Google云端硬盘，可以直接从Google云端硬盘加载文件。将所有视频文件上传至云端硬盘的同一个文件夹下，在下面填写文件夹路径:\n",
        "\n",
        "#@markdown Upload option 2: If you have mounted Google drive, you can load your files from Google drive directly. Put all the videos under one folder, and fill in the path to your folder below:\n",
        "VIDEO_FOLDER_PATH = \"../drive/MyDrive/videos/\"  #@param {type:\"string\"}\n",
        "!cp {VIDEO_FOLDER_PATH}/* ./video_data/"
      ],
      "metadata": {
        "id": "VuDsoW84X3BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2.4 上传视频链接（单个不应长于20分钟）\n",
        "### Video link upload"
      ],
      "metadata": {
        "id": "n1UxoAnoY8Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 运行该代码块会出现一个文件上传的入口，上传单个`.txt`文件。若格式正确的话，视频会自动下载并将下载后的文件名打印在下方。\n",
        "\n",
        "#@markdown Running this code block will prompt you to upload a file.\n",
        "#@markdown Please upload a single `.txt` file. If you have put the links in the correct format,\n",
        "#@markdown the videos will be automatically downloaded and displayed below.\n",
        "%run scripts/download_video.py\n",
        "!ls ./video_data/"
      ],
      "metadata": {
        "id": "ua_Blt02Cg97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im70r9IdsLVY",
        "outputId": "84a85aae-3acd-4128-c88e-1eae4037bd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3 自动处理所有上传的数据"
      ],
      "metadata": {
        "id": "YQGC-JyAaD2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 运行该单元格会对所有上传的数据进行自动去背景音&标注。\n",
        "#@markdown 由于需要调用Whisper和Demucs，运行时间可能较长。\n",
        "\n",
        "#@markdown Running this codeblock will perform automatic vocal seperation & annotation.\n",
        "#@markdown Since this step uses Whisper & Demucs, it may take a while to complete.\n",
        "\n",
        "#@markdown <br>是否保存标注和训练信息: (推荐)<br>\n",
        "#@markdown Whether to save annotation and training information: (recommended)\n",
        "\n",
        "SAVE_DATA = False #@param {type:\"boolean\"}\n",
        "#@markdown 注意，保存标注和训练信息可能会占用大量Google Drive空间<br>\n",
        "#@markdown Please note that saving annotations and training information may take up a lot of Google Drive space\n",
        "\n",
        "# 将所有视频（无论是上传的还是下载的，且必须是.mp4格式）抽取音频\n",
        "%run scripts/video2audio.py\n",
        "# 将所有音频（无论是上传的还是从视频抽取的，必须是.wav格式）去噪\n",
        "!python scripts/denoise_audio.py\n",
        "# 分割并标注长音频\n",
        "!python scripts/long_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large\n",
        "# 标注短音频\n",
        "!python scripts/short_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large\n",
        "# 底模采样率可能与辅助数据不同，需要重采样\n",
        "!python scripts/resample.py\n",
        "\n",
        "# 保存训练集与标注信息\n",
        "if not os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "  raise RuntimeError(\"Please mount Google Drive before saving annotations.\")\n",
        "\n",
        "if SAVE_DATA:\n",
        "  !mkdir ../drive/MyDrive/voice_data/\n",
        "  !cp -rf ./custom_character_voice/ ../drive/MyDrive/voice_data/\n",
        "  !cp -rf ./segmented_character_voice/ ../drive/MyDrive/voice_data/\n",
        "  !cp long_character_anno.txt ../drive/MyDrive/voice_data/long_character_anno.txt\n",
        "  !cp short_character_anno.txt ../drive/MyDrive/voice_data/short_character_anno.txt"
      ],
      "metadata": {
        "id": "aJOO7VsPQf3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f22761-d980-45dc-b320-137df90f99cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/VITS-fast-fine-tuning/separated/htdemucs\n",
            "Separating track raw_audio/whitebear_0006.wav\n",
            "100%|██████████████████████████████████████████████| 397.79999999999995/397.79999999999995 [00:22<00:00, 17.31seconds/s]\n",
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/VITS-fast-fine-tuning/separated/htdemucs\n",
            "Separating track raw_audio/whitebear_0005.wav\n",
            "100%|██████████████████████████████████████████████| 269.09999999999997/269.09999999999997 [00:14<00:00, 17.97seconds/s]\n",
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/VITS-fast-fine-tuning/separated/htdemucs\n",
            "Separating track raw_audio/whitebear_0004.wav\n",
            "100%|██████████████████████████████████████████████| 251.54999999999998/251.54999999999998 [00:14<00:00, 17.23seconds/s]\n",
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/VITS-fast-fine-tuning/separated/htdemucs\n",
            "Separating track raw_audio/whitebear_0001.wav\n",
            "100%|████████████████████████████████████████████████| 801.4499999999999/801.4499999999999 [00:41<00:00, 19.15seconds/s]\n",
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/VITS-fast-fine-tuning/separated/htdemucs\n",
            "Separating track raw_audio/whitebear_0003.wav\n",
            "100%|████████████████████████████████████████████████████████████████████████| 105.3/105.3 [00:07<00:00, 14.81seconds/s]\n",
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/VITS-fast-fine-tuning/separated/htdemucs\n",
            "Separating track raw_audio/whitebear_0002.wav\n",
            "100%|████████████████████████████████████████████████████████████████████████| 783.9/783.9 [00:41<00:00, 19.08seconds/s]\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "transcribing ./denoised_audio/whitebear_0006.wav...\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_0.wav|whitebear|[ZH]處理物體感知的人工智慧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_1.wav|whitebear|[ZH]這個目標的第二部分是語言處理[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_2.wav|whitebear|[ZH]分析和解釋自然語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_3.wav|whitebear|[ZH]在人工智慧中解決問題的技術之一是搜尋[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_4.wav|whitebear|[ZH]搜尋可以描述為使用一組狀態情況來解決問題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_5.wav|whitebear|[ZH]搜尋的兩大類是強力搜尋和啟發式搜尋[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_6.wav|whitebear|[ZH]如果智能體應該像人類一樣形式[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_7.wav|whitebear|[ZH]它可能需要學習[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_8.wav|whitebear|[ZH]已經使用了幾種方法來為未來創造希望[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_9.wav|whitebear|[ZH]大多數方法使用歸納學習或透過規範學習[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_10.wav|whitebear|[ZH]一種常見的方法涉及使用神經網路[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_11.wav|whitebear|[ZH]嘗試使用神經元網路來模擬人腦的學習過程[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_12.wav|whitebear|[ZH]描述圖靈測試[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_13.wav|whitebear|[ZH]您認為這個測試可以用來準確定義智慧系統嗎?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_14.wav|whitebear|[ZH]詢問者提出一系列問題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_15.wav|whitebear|[ZH]這個問題被轉發給電腦和人類[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_16.wav|whitebear|[ZH]詢問器收到兩組回應[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_17.wav|whitebear|[ZH]一組來自計算機,一組來自人類[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_18.wav|whitebear|[ZH]仔細檢查兩組後[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_19.wav|whitebear|[ZH]如果詢問器不能確定哪一組來自計算機[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_20.wav|whitebear|[ZH]則計算機已通過智慧測試[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_21.wav|whitebear|[ZH]有專家認為這是對智慧系統的標準定義[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_22.wav|whitebear|[ZH]有人認為測試不一定是智慧系統的定義[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_23.wav|whitebear|[ZH]定義智慧系統並列出兩大類代理程式[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_24.wav|whitebear|[ZH]智慧代理是一個能夠感知環境[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_25.wav|whitebear|[ZH]從中學習並與知智慧互動的系統[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_26.wav|whitebear|[ZH]智能代理可分為兩大類[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_27.wav|whitebear|[ZH]軟體代理程式和實體代理程式[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_28.wav|whitebear|[ZH]比較和對比LISP和Prolog[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_29.wav|whitebear|[ZH]在人工智慧中的應用[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_30.wav|whitebear|[ZH]LISP是一種操作清單的程式語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_31.wav|whitebear|[ZH]LISP將資料和程序都視為清單[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_32.wav|whitebear|[ZH]這意味著LISP程式可以改變自身[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_33.wav|whitebear|[ZH]此功能與智慧代理的理念相匹配[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_34.wav|whitebear|[ZH]智慧代理可以從環境中學習並改善其行為[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_35.wav|whitebear|[ZH]Prolog是一種可以建立事實資料庫和規則資料庫的語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_36.wav|whitebear|[ZH]Prolog中的程式可以使用邏輯推理[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_37.wav|whitebear|[ZH]來回答可以從資料庫推斷的問題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_38.wav|whitebear|[ZH]描述知識表示的需求並列出四種不同的方法[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_39.wav|whitebear|[ZH]如果人工智慧要解決一些現實世界相關的問題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_40.wav|whitebear|[ZH]它就需要以某種方式表示知識[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_41.wav|whitebear|[ZH]表示知識的四種常見方式是語意網路、框架、[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_42.wav|whitebear|[ZH]未詞邏輯和基於規則的系統[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_43.wav|whitebear|[ZH]比較和對比未詞邏輯和命題邏輯[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_44.wav|whitebear|[ZH]命題邏輯是一種由一組句子組成的語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_45.wav|whitebear|[ZH]可以用來對世界進行邏輯推理[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_46.wav|whitebear|[ZH]在命題邏輯中,代表句子的符號是原子的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_47.wav|whitebear|[ZH]無法破解它來查找有關組件的一些資訊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_48.wav|whitebear|[ZH]為此,我們需要未詞邏輯[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_49.wav|whitebear|[ZH]也就是定義命題中各部分之間的關係的邏輯[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_50.wav|whitebear|[ZH]比較和對比框架和語意網路[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_51.wav|whitebear|[ZH]語意網路使用頂點、括弧、節點來表示概念[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_52.wav|whitebear|[ZH]使用邊、括弧箭頭來表示概念之間的關係[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_53.wav|whitebear|[ZH]在框架中,資料結構、括弧記錄用於表示相同的知識[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_54.wav|whitebear|[ZH]語意網路中的節點和邊分別成為正宗的物件和槽[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_55.wav|whitebear|[ZH]定義規則庫系統並與語意網路進行比較[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_56.wav|whitebear|[ZH]基於規則的系統,使用一組規則來表示知識[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_57.wav|whitebear|[ZH]這些規則可以用來從已知的事實中推找出一些新的事實[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_58.wav|whitebear|[ZH]語意網路中實體及其關係的圖形表示[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_59.wav|whitebear|[ZH]比較和對比框架和語意網路[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_60.wav|whitebear|[ZH]比較和對比專家系統和普通系統[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_61.wav|whitebear|[ZH]專家系統執行具有專業知識的人所期望的任務[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_62.wav|whitebear|[ZH]系統執行不需要專業知識的任務,例如說話或步行[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_63.wav|whitebear|[ZH]列出影像處理中的不同步驟[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_64.wav|whitebear|[ZH]影像處理的五個階段是邊緣測試、邊緣偵測、分割、查找深度、尋找方向和物體辨識[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_65.wav|whitebear|[ZH]邊緣偵測、分割、查找深度、尋找方向和物體辨識[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_66.wav|whitebear|[ZH]列出語言處理中的不同步驟[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_67.wav|whitebear|[ZH]語言處理的四個步驟是語音辨識、句法分析、語意分析和語用分析[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_68.wav|whitebear|[ZH]定義神經網路以及它如何模擬人類的學習過程[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_69.wav|whitebear|[ZH]神經網路試圖利用神經網路來模擬人腦的學習過程[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_70.wav|whitebear|[ZH]人工神經元網路[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_71.wav|whitebear|[ZH]定義一個感知器[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0006_72.wav|whitebear|[ZH]感知器是類似單一生物神經元的人工神經元[ZH]\n",
            "\n",
            "transcribing ./denoised_audio/whitebear_0005.wav...\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_0.wav|whitebear|[ZH]DBMS的五個必要元件是什麼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_1.wav|whitebear|[ZH]DBMS的五個必要組成部分[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_2.wav|whitebear|[ZH]是硬體、軟體、資料、使用者和程序[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_3.wav|whitebear|[ZH]三種資料庫模型是什麼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_4.wav|whitebear|[ZH]今天哪個最受歡迎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_5.wav|whitebear|[ZH]資料庫的三種模型[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_6.wav|whitebear|[ZH]是層次型、網路型和關係型[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_7.wav|whitebear|[ZH]關係型模型就是今天使用的模型[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_8.wav|whitebear|[ZH]關係資料庫中的關係是什麼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_9.wav|whitebear|[ZH]在關係模型中[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_10.wav|whitebear|[ZH]關係是組織在二維表中的一組資料[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_11.wav|whitebear|[ZH]關係是關聯在一起的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_12.wav|whitebear|[ZH]在關係中[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_13.wav|whitebear|[ZH]什麼是屬性、什麼是原組[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_14.wav|whitebear|[ZH]屬性是關係中的直行[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_15.wav|whitebear|[ZH]原組是關係中的橫列[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_16.wav|whitebear|[ZH]列出關係資料庫中的一些應援運算[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_17.wav|whitebear|[ZH]一些應援操作包括插入、刪除、更新、選擇和項目[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_18.wav|whitebear|[ZH]列出關係資料庫中的一些二進位操作[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_19.wav|whitebear|[ZH]一些二元操作包括連接、並集、交集和插集[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_20.wav|whitebear|[ZH]什麼是SQL、什麼是XML[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_21.wav|whitebear|[ZH]哪一種是關係資料庫的查詢語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_22.wav|whitebear|[ZH]固件導向語言的查詢語言是哪一種[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_23.wav|whitebear|[ZH]結構化查詢語言SQL[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_24.wav|whitebear|[ZH]是由美國國家標準協會MSI和國際標準化組織ISO[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_25.wav|whitebear|[ZH]用於關聯式資料庫[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_26.wav|whitebear|[ZH]廣泛的標記語言XML[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_27.wav|whitebear|[ZH]是一種只在添加標記的標記語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_28.wav|whitebear|[ZH]資料到文本文檔[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_29.wav|whitebear|[ZH]但它也找到了作為查詢的應用[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_30.wav|whitebear|[ZH]資料庫中的語言[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_31.wav|whitebear|[ZH]SQL用於關聯式資料庫[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_32.wav|whitebear|[ZH]XML用於固件導向的資料庫[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_33.wav|whitebear|[ZH]使用參考資料或網路尋找有關第三範式3NF的一些資訊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_34.wav|whitebear|[ZH]這種範式涉及什麼樣的函數依賴[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_35.wav|whitebear|[ZH]若一個關係滿足以下兩個條件[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_36.wav|whitebear|[ZH]則該關係為第三範式3NF版本[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_37.wav|whitebear|[ZH]滿足第二範式2NF的要求[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_38.wav|whitebear|[ZH]沒有非組件性[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_39.wav|whitebear|[ZH]可以傳遞依賴語件[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_40.wav|whitebear|[ZH]例如[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_41.wav|whitebear|[ZH]考慮下面的簡單表格[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_42.wav|whitebear|[ZH]其中顯示了國際科學挑戰賽的獲勝者[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_43.wav|whitebear|[ZH]其中表格中的關鍵字帶有下劃線[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_44.wav|whitebear|[ZH]主題 優勝者 得獎者國籍[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_45.wav|whitebear|[ZH]該表不滿足3NF的要求[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_46.wav|whitebear|[ZH]因為非素數 屬性 獲勝者國籍[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_47.wav|whitebear|[ZH]透過非屬性 獲勝者 傳遞依賴語件 主題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_48.wav|whitebear|[ZH]透過將表格更改為下面兩個表[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_49.wav|whitebear|[ZH]我們可以消除異常[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_50.wav|whitebear|[ZH]主題 優勝者 優勝者 得獎者國籍[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_51.wav|whitebear|[ZH]使用參考資料或網路尋找有關[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_52.wav|whitebear|[ZH]Voice Code 範式BCNF的一些資訊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_53.wav|whitebear|[ZH]這種範式涉及什麼樣的函數依賴[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_54.wav|whitebear|[ZH]Voice Code 範式BCNF[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_55.wav|whitebear|[ZH]是修訂後的3NF[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_56.wav|whitebear|[ZH]涵蓋了特殊的3NF不涵蓋的情況[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0005_57.wav|whitebear|[ZH]更多資訊請參閱最後的參考資料正文章節[ZH]\n",
            "\n",
            "transcribing ./denoised_audio/whitebear_0004.wav...\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_0.wav|whitebear|[ZH]文字答案和二进位答案有什么区别?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_1.wav|whitebear|[ZH]文字答案是自源文件,而二进位答案是以电脑内部格式储存的资料集合。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_2.wav|whitebear|[ZH]文件处理中的常见演算法是合并两个按键值排序的顺序文件,[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_3.wav|whitebear|[ZH]以建立新的文件顺序。该文件也已排序。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_4.wav|whitebear|[ZH]如果每个文件末尾都有一个虚拟记录,且其唯一键值大于任意文件中的任何键值,[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_5.wav|whitebear|[ZH]则合并演算法可能会非常简单,唯一的键值称为哨兵。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_6.wav|whitebear|[ZH]在这种假设情况下,无需检查文件中的EOF标记,[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_7.wav|whitebear|[ZH]会寄一个UML图来合并这个假设情况的两个答案。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_8.wav|whitebear|[ZH]文件存取方式有哪两种常见类型?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_9.wav|whitebear|[ZH]两种访问方式是顺序访问和随机访问。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_10.wav|whitebear|[ZH]新组文件和旧组文件有什么关系?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_11.wav|whitebear|[ZH]旧的组文件是应该更新的文件,新的组文件是应该更新的文件。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_12.wav|whitebear|[ZH]新的组文件包含当前数据,旧组文件中的数据,包括更新过程中所做的任何更改。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_13.wav|whitebear|[ZH]事物文件更新顺序文件的目的是什么?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_14.wav|whitebear|[ZH]交易文件包含应对旧组文件进行的更改文件。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_15.wav|whitebear|[ZH]描述随机存取文件中的地址的功能。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_16.wav|whitebear|[ZH]要随机存取文件中的记录,我们需要知道该记录的地址记录。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_17.wav|whitebear|[ZH]索引与索引档案中的资料档案有何关系?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_18.wav|whitebear|[ZH]索引是将资料项目的鉴于储存资料的档案中的位置相关联的表。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_19.wav|whitebear|[ZH]文件直接哈希中的密钥和地址有什么关系?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_20.wav|whitebear|[ZH]在直接杂凑中,键是档案中记录的位置。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_21.wav|whitebear|[ZH]档案的模除哈希中键和位置之间的关系是什么?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_22.wav|whitebear|[ZH]在模除杂凑中,密钥除以档案大小,余数加1,作为该记录在文件中的位置。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_23.wav|whitebear|[ZH]档案数字提取哈希中的密钥和地址之间有什么关系?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_24.wav|whitebear|[ZH]在数字提取哈希中,某些数字从键中删除并用作记录的位置。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_25.wav|whitebear|[ZH]列出并描述三种冲突解决方式。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_26.wav|whitebear|[ZH]当两个杂凑记录具有相同的位置时,就会发生冲突。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_27.wav|whitebear|[ZH]这三种冲突方法分别是开放寻址、列表解析和同散列。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_28.wav|whitebear|[ZH]在开放寻址中,在主要区域搜寻未占用的位置。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_29.wav|whitebear|[ZH]在列表解析中,第一个记录储存在其实位置中,但它包含指向第二笔记录的指标。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_30.wav|whitebear|[ZH]在同散列中,一组记录储存在桶中。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_31.wav|whitebear|[ZH]桶是可以容纳多个记录的位置。[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_32.wav|whitebear|[ZH]文字档和二进位档案有什么区别?[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0004_33.wav|whitebear|[ZH]文字档案是资源文件,而二进位档案是以电脑内部格式储存的资料集合。[ZH]\n",
            "\n",
            "transcribing ./denoised_audio/whitebear_0001.wav...\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_0.wav|whitebear|[ZH]哈囉大家好我是白熊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_1.wav|whitebear|[ZH]今天呢我要來玩的是一張小瓶解謎地圖[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_2.wav|whitebear|[ZH]叫做密室之戀[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_3.wav|whitebear|[ZH]那就開始囉[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_4.wav|whitebear|[ZH]剛剛一進來就看到這裡很黑[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_5.wav|whitebear|[ZH]所以其實我也不太確定是要幹嘛[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_6.wav|whitebear|[ZH]OK過關神器[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_7.wav|whitebear|[ZH]開啟將會破壞遊戲體驗請三思[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_8.wav|whitebear|[ZH]好那就先不看了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_9.wav|whitebear|[ZH]在古老城市中心有一座荒廢多年的貴族宅邸[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_10.wav|whitebear|[ZH]傳說中藏有無數寶藏卻被蟲蟲機關和謎題保護[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_11.wav|whitebear|[ZH]無數探險者在此時中[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_12.wav|whitebear|[ZH]今天你們將面臨層層機關和謎題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_13.wav|whitebear|[ZH]若不能成功逃脫將遠遠被困在這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_14.wav|whitebear|[ZH]成為下一個失蹤的傳說[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_15.wav|whitebear|[ZH]下水道似乎有動靜[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_16.wav|whitebear|[ZH]箱子務必開啟前往查看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_17.wav|whitebear|[ZH]OK[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_18.wav|whitebear|[ZH]還有其他箱子嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_19.wav|whitebear|[ZH]看來這裡游不過去[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_20.wav|whitebear|[ZH]等一下喔[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_21.wav|whitebear|[ZH]雖然我很久沒有玩麥塊了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_22.wav|whitebear|[ZH]但是我還是認得出來它是陷阱儲物箱[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_23.wav|whitebear|[ZH]OK[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_24.wav|whitebear|[ZH]我剛剛沒有注意到這裡有沒有按鈕[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_25.wav|whitebear|[ZH]只有注意到有個start[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_26.wav|whitebear|[ZH]嘶[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_27.wav|whitebear|[ZH]哼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_28.wav|whitebear|[ZH]書櫃暗藏了什麼玄機[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_29.wav|whitebear|[ZH]那玄機應該就是這把鏟子了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_30.wav|whitebear|[ZH]把這裡挖空看看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_31.wav|whitebear|[ZH]哇 其他竟然都是木頭[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_32.wav|whitebear|[ZH]可放置於鑽石方塊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_33.wav|whitebear|[ZH]這是什麼呢[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_34.wav|whitebear|[ZH]哼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_35.wav|whitebear|[ZH]喔 對了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_36.wav|whitebear|[ZH]木桶也可以開[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_37.wav|whitebear|[ZH]看來木桶沒有東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_38.wav|whitebear|[ZH]好吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_39.wav|whitebear|[ZH]看來我現在把這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_40.wav|whitebear|[ZH]可以開的東西都開過了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_41.wav|whitebear|[ZH]只能來好好找找看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_42.wav|whitebear|[ZH]不對 這裡也是木桶[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_43.wav|whitebear|[ZH]喔 不[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_44.wav|whitebear|[ZH]這裡也沒有東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_45.wav|whitebear|[ZH]哼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_46.wav|whitebear|[ZH]這裡看起來好像也沒有其他東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_47.wav|whitebear|[ZH]等一下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_48.wav|whitebear|[ZH]這樣子就可以跳上來了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_49.wav|whitebear|[ZH]但是跳上來[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_50.wav|whitebear|[ZH]好像也沒有其他的東西了嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_51.wav|whitebear|[ZH]只有看到另一張臉[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_52.wav|whitebear|[ZH]哼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_53.wav|whitebear|[ZH]我想要先爬上去那邊看看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_54.wav|whitebear|[ZH]說不定可以在走的路上找到什麼東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_55.wav|whitebear|[ZH]嗯[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_56.wav|whitebear|[ZH]喝個水[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_57.wav|whitebear|[ZH]看來其實藏在這個洞裡面[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_58.wav|whitebear|[ZH]如果藏在這個洞裡面的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_59.wav|whitebear|[ZH]哼 要想辦法跳過去[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_60.wav|whitebear|[ZH]嗯[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_61.wav|whitebear|[ZH]和解謎地圖會做成像跑酷地圖一樣嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_62.wav|whitebear|[ZH]這個我還真的是不確定[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_63.wav|whitebear|[ZH]喔 吊燈可以直接走上來[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_64.wav|whitebear|[ZH]那我就不用跳了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_65.wav|whitebear|[ZH]還真的在這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_66.wav|whitebear|[ZH]不對 這界伏盒裡面也沒東西啊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_67.wav|whitebear|[ZH]等一下 我記得界伏盒可以讓我掉下去吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_68.wav|whitebear|[ZH]這樣子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_69.wav|whitebear|[ZH]Nice[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_70.wav|whitebear|[ZH]這樣[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_71.wav|whitebear|[ZH]哼[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_72.wav|whitebear|[ZH]哼 音階盒嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_73.wav|whitebear|[ZH]但踩下去沒有聲音[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_74.wav|whitebear|[ZH]先開箱子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_75.wav|whitebear|[ZH]關卡說明 謎題[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_76.wav|whitebear|[ZH]XBOX OK[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_77.wav|whitebear|[ZH]過關需滿足以下規則[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_78.wav|whitebear|[ZH]按照A到Z的順序踩壓力板[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_79.wav|whitebear|[ZH]等等 再看一次[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_80.wav|whitebear|[ZH]所以這樣子的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_81.wav|whitebear|[ZH]感覺我需要再拿筆過來[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_82.wav|whitebear|[ZH]抽屜裡面應該有筆[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_83.wav|whitebear|[ZH]如果是這樣子的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_84.wav|whitebear|[ZH]這張地圖上面是寫L[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_85.wav|whitebear|[ZH]D[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_86.wav|whitebear|[ZH]H[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_87.wav|whitebear|[ZH]A[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_88.wav|whitebear|[ZH]B[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_89.wav|whitebear|[ZH]C[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_90.wav|whitebear|[ZH]X[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_91.wav|whitebear|[ZH]C[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_92.wav|whitebear|[ZH]F[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_93.wav|whitebear|[ZH]然後再看這個本子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_94.wav|whitebear|[ZH]A是2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_95.wav|whitebear|[ZH]B是4[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_96.wav|whitebear|[ZH]C是2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_97.wav|whitebear|[ZH]D是3[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_98.wav|whitebear|[ZH]F是3[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_99.wav|whitebear|[ZH]H2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_100.wav|whitebear|[ZH]L2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_101.wav|whitebear|[ZH]X3[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_102.wav|whitebear|[ZH]但這樣子就有重複的數字[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_103.wav|whitebear|[ZH]那如果再按照A到Z的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_104.wav|whitebear|[ZH]那應該是[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_105.wav|whitebear|[ZH]先踩A2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_106.wav|whitebear|[ZH]然後B是4的話感覺就[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_107.wav|whitebear|[ZH]不符合嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_108.wav|whitebear|[ZH]那先踩C2好了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_109.wav|whitebear|[ZH]然後H2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_110.wav|whitebear|[ZH]L2[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_111.wav|whitebear|[ZH]再來是3的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_112.wav|whitebear|[ZH]D3[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_113.wav|whitebear|[ZH]F3[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_114.wav|whitebear|[ZH]跟X3[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_115.wav|whitebear|[ZH]再來是B4[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_116.wav|whitebear|[ZH]看來不是這樣[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_117.wav|whitebear|[ZH]再喝個水[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_118.wav|whitebear|[ZH]讓我想一下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_119.wav|whitebear|[ZH]先踩ABC的順序看看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_120.wav|whitebear|[ZH]B[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_121.wav|whitebear|[ZH]C[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_122.wav|whitebear|[ZH]D[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_123.wav|whitebear|[ZH]E[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_124.wav|whitebear|[ZH]EF[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_125.wav|whitebear|[ZH]H[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_126.wav|whitebear|[ZH]L[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_127.wav|whitebear|[ZH]X[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_128.wav|whitebear|[ZH]我剛剛在踩的路上我是突然想到[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_129.wav|whitebear|[ZH]他說[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_130.wav|whitebear|[ZH]等一下喔這個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_131.wav|whitebear|[ZH]A到Z的順序去踩壓力板[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_132.wav|whitebear|[ZH]那這樣子的話也有可能是[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_133.wav|whitebear|[ZH]代表是[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_134.wav|whitebear|[ZH]要踩那個壓力板幾下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_135.wav|whitebear|[ZH]所以[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_136.wav|whitebear|[ZH]A兩下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_137.wav|whitebear|[ZH]然後B四下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_138.wav|whitebear|[ZH]再來[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_139.wav|whitebear|[ZH]不對[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_140.wav|whitebear|[ZH]B不是這一個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_141.wav|whitebear|[ZH]再來一次[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_142.wav|whitebear|[ZH]A兩下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_143.wav|whitebear|[ZH]B四下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_144.wav|whitebear|[ZH]再來是C兩下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_145.wav|whitebear|[ZH]C[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_146.wav|whitebear|[ZH]D[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_147.wav|whitebear|[ZH]D三下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_148.wav|whitebear|[ZH]ABCD[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_149.wav|whitebear|[ZH]EF[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_150.wav|whitebear|[ZH]所以F三下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_151.wav|whitebear|[ZH]H兩下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_152.wav|whitebear|[ZH]再來是L兩下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_153.wav|whitebear|[ZH]L是前面這個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_154.wav|whitebear|[ZH]X三下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_155.wav|whitebear|[ZH]可放置於基岩[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_156.wav|whitebear|[ZH]所以我現在要做的是尋找基岩囉[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_157.wav|whitebear|[ZH]這上面都是木頭[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_158.wav|whitebear|[ZH]基岩在這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_159.wav|whitebear|[ZH]木頭又有碎裂聲[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_160.wav|whitebear|[ZH]在這邊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_161.wav|whitebear|[ZH]啊哈[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_162.wav|whitebear|[ZH]我現在只剩下影片結尾動畫[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_163.wav|whitebear|[ZH]然後我不知道把我的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_164.wav|whitebear|[ZH]BGM丟到哪裡了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_165.wav|whitebear|[ZH]所以我現在只能自己在這裡製造一些噪音[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_166.wav|whitebear|[ZH]讓我的結尾動畫有點聲音[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_167.wav|whitebear|[ZH]大概就是這樣子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_168.wav|whitebear|[ZH]我是白熊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_169.wav|whitebear|[ZH]我們下次再見[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_170.wav|whitebear|[ZH]記得按讚訂閱開啟小鈴鐺[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0001_171.wav|whitebear|[ZH]拜拜[ZH]\n",
            "\n",
            "transcribing ./denoised_audio/whitebear_0003.wav...\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_0.wav|whitebear|[JA]こんにちは[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_1.wav|whitebear|[JA]おはようございます[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_2.wav|whitebear|[JA]こんばんは[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_3.wav|whitebear|[JA]おやすみなさい[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_4.wav|whitebear|[JA]さよなら[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_5.wav|whitebear|[JA]お元気ですか?[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_6.wav|whitebear|[JA]初めまして[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_7.wav|whitebear|[JA]よろしくお願いします[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_8.wav|whitebear|[JA]ありがとうございます[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_9.wav|whitebear|[JA]ありがとう[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_10.wav|whitebear|[JA]どういたしまして[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_11.wav|whitebear|[JA]はい[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_12.wav|whitebear|[JA]いいえ[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_13.wav|whitebear|[JA]そうです[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_14.wav|whitebear|[JA]違います[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_15.wav|whitebear|[JA]わかりました[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_16.wav|whitebear|[JA]わかりません[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_17.wav|whitebear|[JA]大丈夫[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_18.wav|whitebear|[JA]ごめんなさい[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_19.wav|whitebear|[JA]すみません[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_20.wav|whitebear|[JA]どうも[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_21.wav|whitebear|[JA]マルマルが欲しいです[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_22.wav|whitebear|[JA]マルマルしたいです[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_23.wav|whitebear|[JA]マルマルはどこですか?[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_24.wav|whitebear|[JA]マルマルはありますか?[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_25.wav|whitebear|[JA]マルマルしていいですか?[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_26.wav|whitebear|[JA]いくらですか?[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_27.wav|whitebear|[JA]もう一度言ってください[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_28.wav|whitebear|[JA]ゆっくり話してください[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_29.wav|whitebear|[JA]日本語は話せません[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_30.wav|whitebear|[JA]中国語、英語がわかる人はいますか?[JA]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0003_31.wav|whitebear|[JA]書いてください[JA]\n",
            "\n",
            "transcribing ./denoised_audio/whitebear_0002.wav...\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_0.wav|whitebear|[ZH]有一個金磚 中間是 應該是綠寶石磚吧 鐵磚 鑽磚 還有 應該不是什麼磚[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_1.wav|whitebear|[ZH]雪下似乎有東西 關卡說明[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_2.wav|whitebear|[ZH]此關卡區收集5個能量方塊即可自中央裝置充能 共3個可啟動生成能量方塊的地方[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_3.wav|whitebear|[ZH]啟動生成能量方塊裝置後 將發放能量方塊至木桶 數量為隨機[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_4.wav|whitebear|[ZH]這是其中一個進去的門 所以這裡應該是其中一個房間[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_5.wav|whitebear|[ZH]雪下的東西 好像先到雪女 喔 鷹架[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_6.wav|whitebear|[ZH]好吧 我不知道逃關是幹嘛用的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_7.wav|whitebear|[ZH]能量方塊生成至木桶 所以這裡就結束了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_8.wav|whitebear|[ZH]再來是 另一間房間嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_9.wav|whitebear|[ZH]可以用來破壞中介石[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_10.wav|whitebear|[ZH]這裡面看起來都沒有東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_11.wav|whitebear|[ZH]巧克力門[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_12.wav|whitebear|[ZH]不過倒是看到了一個南瓜 但總不可能是挖南瓜吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_13.wav|whitebear|[ZH]看起來也挖不到什麼東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_14.wav|whitebear|[ZH]半線溝 半了好像也沒有反應嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_15.wav|whitebear|[ZH]先前往下一格[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_16.wav|whitebear|[ZH]水槽與羊毛 可以放置到方塊上[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_17.wav|whitebear|[ZH]這裡有一個箱子 地圖[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_18.wav|whitebear|[ZH]所以這應該是要我裝水[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_19.wav|whitebear|[ZH]在第一間房間裡有水 要靠這兩個玻璃瓶[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_20.wav|whitebear|[ZH]木桶裡面就沒有東西了 又回到了外面[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_21.wav|whitebear|[ZH]先來裝水[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_22.wav|whitebear|[ZH]這裡放一個 這裡放兩個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_23.wav|whitebear|[ZH]最後一個要放三個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_24.wav|whitebear|[ZH]應該是這一本吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_25.wav|whitebear|[ZH]現在有白色 紅色 藍色[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_26.wav|whitebear|[ZH]黃色再鑽鑽 藍色金鑽 紅色獄髓[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_27.wav|whitebear|[ZH]這個應該是獄髓[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_28.wav|whitebear|[ZH]藍色是金鑽 黃色鑽鑽 白色應該是鐵鑽[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_29.wav|whitebear|[ZH]鐵砧落地的聲音 OK[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_30.wav|whitebear|[ZH]十分黑暗的小房間[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_31.wav|whitebear|[ZH]我記得我調到明亮了 好吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_32.wav|whitebear|[ZH]那這已經是最亮了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_33.wav|whitebear|[ZH]說實在有點困難 因為我不懂紅石[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_34.wav|whitebear|[ZH]所以如果想要讓它打開的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_35.wav|whitebear|[ZH]好吧 看起來打開了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_36.wav|whitebear|[ZH]好像有點厚[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_37.wav|whitebear|[ZH]有雞叫聲[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_38.wav|whitebear|[ZH]然後 這裡看起來是有東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_39.wav|whitebear|[ZH]出現通往樹上的小徑[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_40.wav|whitebear|[ZH]叉叉回憶錄[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_41.wav|whitebear|[ZH]先把這裡的東西 看我還有沒有東西可以挖在常識網樹上好了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_42.wav|whitebear|[ZH]這裡是一個洞[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_43.wav|whitebear|[ZH]曾經這裡是繁華的都市 如今已荒廢多時 挑戰者繼續前進吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_44.wav|whitebear|[ZH]Google Lock[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_45.wav|whitebear|[ZH]屬實有點黑[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_46.wav|whitebear|[ZH]可放置於浮雕石磚[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_47.wav|whitebear|[ZH]不過 浮雕石磚又在哪裡呢[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_48.wav|whitebear|[ZH]我可能要先知道浮雕石磚長什麼樣子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_49.wav|whitebear|[ZH]應該是中間有圈圈的那個石磚 但是呢[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_50.wav|whitebear|[ZH]這次直播要先到此結束了 因為我要先去吃午餐[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_51.wav|whitebear|[ZH]感謝你的收看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_52.wav|whitebear|[ZH]如果你喜歡我的影片或者是直播的話 記得訂閱按讚開啟小鈴鐺[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_53.wav|whitebear|[ZH]我們下次再見[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_54.wav|whitebear|[ZH]哈囉大家好我是白熊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_55.wav|whitebear|[ZH]我們要來繼續玩小品解謎地圖 密室之戀[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_56.wav|whitebear|[ZH]我去吃個午餐回來之後 發現好像回到了最初的起點[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_57.wav|whitebear|[ZH]還蠻神奇的 明明都還是同一張地圖[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_58.wav|whitebear|[ZH]好吧 它沒有記錄我上一次進去的時間[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_59.wav|whitebear|[ZH]不過也只能這樣了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_60.wav|whitebear|[ZH]再來一次吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_61.wav|whitebear|[ZH]好 新的地圖回來了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_62.wav|whitebear|[ZH]看起來就跟新的一樣[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_63.wav|whitebear|[ZH]這樣子我還需要再去拿一次書嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_64.wav|whitebear|[ZH]噢 浮雕石磚在這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_65.wav|whitebear|[ZH]然後[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_66.wav|whitebear|[ZH]噢[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_67.wav|whitebear|[ZH]這樣子我們就回到離開前的進度了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_68.wav|whitebear|[ZH]浮雕石磚[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_69.wav|whitebear|[ZH]不是這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_70.wav|whitebear|[ZH]浮雕石磚[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_71.wav|whitebear|[ZH]好像也不是這裡 等等[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_72.wav|whitebear|[ZH]這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_73.wav|whitebear|[ZH]帳篷頂部出現裂痕[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_74.wav|whitebear|[ZH]那應該是這個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_75.wav|whitebear|[ZH]哼 我都不知道現在還有藍色蠟燭[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_76.wav|whitebear|[ZH]那就來看一下吧[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_77.wav|whitebear|[ZH]金字塔外的四種顏色方塊似乎對應牆上的蠟燭[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_78.wav|whitebear|[ZH]操作按鈕試試[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_79.wav|whitebear|[ZH]所以應該是看蠟燭顏色然後對應牆壁上的顏色來按它的數字[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_80.wav|whitebear|[ZH]那這邊的話應該是按三次[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_81.wav|whitebear|[ZH]不小心跑進來了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_82.wav|whitebear|[ZH]再來這邊是紅色 紅色的話有四個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_83.wav|whitebear|[ZH]這邊是黃色 黃色的話有三個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_84.wav|whitebear|[ZH]最後一個是綠色 綠色有五個[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_85.wav|whitebear|[ZH]地板機關已觸發[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_86.wav|whitebear|[ZH]看來地板機關不在這裡嗎[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_87.wav|whitebear|[ZH]在這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_88.wav|whitebear|[ZH]可以放置於黃金方塊上面[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_89.wav|whitebear|[ZH]接下來要尋找黃金方塊[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_90.wav|whitebear|[ZH]黑黑的鑰匙[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_91.wav|whitebear|[ZH]如果有實況影片請發文字板上[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_92.wav|whitebear|[ZH]巴哈文章點此[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_93.wav|whitebear|[ZH]天啊 那這樣子的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_94.wav|whitebear|[ZH]其實距離我剛剛[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_95.wav|whitebear|[ZH]結束那一部份[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_96.wav|whitebear|[ZH]感覺那裡大概是四分之三了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_97.wav|whitebear|[ZH]然後就到這裡[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_98.wav|whitebear|[ZH]不過[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_99.wav|whitebear|[ZH]我還是想說[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_100.wav|whitebear|[ZH][ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_101.wav|whitebear|[ZH][ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_102.wav|whitebear|[ZH][ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_103.wav|whitebear|[ZH]沒辦法了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_104.wav|whitebear|[ZH]畢竟要暫停還是要暫停[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_105.wav|whitebear|[ZH]偷偷看一下[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_106.wav|whitebear|[ZH]這裡有沒有什麼東西[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_107.wav|whitebear|[ZH]好吧 看來是沒有[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_108.wav|whitebear|[ZH]那[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_109.wav|whitebear|[ZH]非常的快[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_110.wav|whitebear|[ZH]感謝你的收看[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_111.wav|whitebear|[ZH]那這次的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_112.wav|whitebear|[ZH]直播還有影片就到此結束[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_113.wav|whitebear|[ZH]因為這次是先直播[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_114.wav|whitebear|[ZH]然後之後應該會把直播下載下來[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_115.wav|whitebear|[ZH]再剪完之後丟到YT上面[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_116.wav|whitebear|[ZH]那大概就是這樣子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_117.wav|whitebear|[ZH]如果你喜歡我的直播或者是我的影片的話[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_118.wav|whitebear|[ZH]歡迎訂閱我或者是[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_119.wav|whitebear|[ZH]追蹤我[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_120.wav|whitebear|[ZH]那記得按讚訂閱開啟小鈴鐺[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_121.wav|whitebear|[ZH]我是八熊 我們下次再見[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_122.wav|whitebear|[ZH]掰掰[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_123.wav|whitebear|[ZH]啊哈 我現在只剩下影片結尾動畫[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_124.wav|whitebear|[ZH]然後不知道把我的[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_125.wav|whitebear|[ZH]BGM丟到哪裡了[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_126.wav|whitebear|[ZH]所以我現在只能自己在這裡製造一些噪音[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_127.wav|whitebear|[ZH]讓我的結尾動畫有點聲音[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_128.wav|whitebear|[ZH]大概就是這樣子[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_129.wav|whitebear|[ZH]我是八熊 我們下次再見[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_130.wav|whitebear|[ZH]記得按讚訂閱開啟小鈴鐺[ZH]\n",
            "\n",
            "Transcribed segment: ./segmented_character_voice/whitebear/whitebear_0002_131.wav|whitebear|[ZH]掰掰[ZH]\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "Warning: no short audios found, this IS expected if you have only uploaded long audios, videos or video links.\n",
            "this IS NOT expected if you have uploaded a zip file of short audios. Please check your file structure or make sure your audio language is supported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpIZ_bYAqBJC",
        "outputId": "ebac057f-50d9-47ea-b8b7-3c05cc447660"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attentions.py            losses.py           \u001b[0m\u001b[01;34msampled_audio4ft\u001b[0m/\n",
            "cmd_inference.py         mel_processing.py   sampled_audio4ft.txt\n",
            "commons.py               models_infer.py     sampled_audio4ft_v2.zip\n",
            "\u001b[01;34mconfigs\u001b[0m/                 models.py           \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;34mcustom_character_voice\u001b[0m/  modules.py          \u001b[01;34msegmented_character_voice\u001b[0m/\n",
            "DATA_EN.MD               \u001b[01;34mmonotonic_align\u001b[0m/    \u001b[01;34mtext\u001b[0m/\n",
            "DATA.MD                  preprocess_v2.py    transforms.py\n",
            "data_utils.py            \u001b[01;34mpretrained_models\u001b[0m/  utils.py\n",
            "\u001b[01;34mdenoised_audio\u001b[0m/          \u001b[01;34mraw_audio\u001b[0m/          VC_inference.py\n",
            "finetune_speaker_v2.py   README.md           \u001b[01;34mvideo_data\u001b[0m/\n",
            "LICENSE                  README_ZH.md\n",
            "LOCAL.md                 requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd VITS-fast-fine-tuning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSn6U3ZiqDIm",
        "outputId": "1516ab18-b110-4cc8-fafd-11b08f8c570f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VITS-fast-fine-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#！！！训练质量相关：实验发现目前使用CJ模型+勾选ADD_AUXILIARY，对于中/日均能训练出最好的效果，第一次训练建议默认使用该组合！！！"
      ],
      "metadata": {
        "id": "WY12Ien-BUE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##STEP 3.5\n",
        "#@markdown 运行该单元格会生成划分好训练/测试集的最终标注，以及配置文件\n",
        "\n",
        "#@markdown Running this block will generate final annotations for training & validation, as well as config file.\n",
        "\n",
        "#@markdown 选择是否加入辅助训练数据：/ Choose whether to add auxiliary data:\n",
        "ADD_AUXILIARY = True #@param {type:\"boolean\"}\n",
        "#@markdown 辅助训练数据是从预训练的大数据集抽样得到的，作用在于防止模型在标注不准确的数据上形成错误映射。\n",
        "\n",
        "#@markdown Auxiliary data is to prevent overfitting when the audio samples are small or with low quality.\n",
        "\n",
        "#@markdown 以下情况请勾选：\n",
        "\n",
        "#@markdown 总样本少于100条/样本质量一般或较差/样本来自爬取的视频\n",
        "\n",
        "#@markdown 以下情况可以不勾选：\n",
        "\n",
        "#@markdown 总样本量很大/样本质量很高/希望加速训练/只有二次元角色\n",
        "\n",
        "# assert(not (ADD_AUXILIARY and PRETRAINED_MODEL != \"CJE\")), \"add auxiliary data is available only available for CJE model!\"\n",
        "if ADD_AUXILIARY:\n",
        "  %run preprocess_v2.py --add_auxiliary_data True --languages \"{PRETRAINED_MODEL}\"\n",
        "else:\n",
        "  %run preprocess_v2.py --languages \"{PRETRAINED_MODEL}\""
      ],
      "metadata": {
        "id": "G_IM97N2e6fk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251,
          "referenced_widgets": [
            "46c0702ae15944c9a1b434761dbfd883",
            "75ca7a0bb6744df6b5630b8d37c95939",
            "0eb7d94740e74cf7874bb542c26af4c2",
            "11f43d70c0fa4ec88426206a44d6ef97",
            "385db37ecba541c58f97cd88d8c2ee3a",
            "427552cb69974a65a69fbda252c54c4e",
            "8afd67e4347c4893ab3ef68e04777a04",
            "972d5022af3a4bcc82c52cc33c51a5d7",
            "d6af452c410a4cc4a3a2bfcf539cf2bd",
            "2ba958f395314bf1b5a723d9a2ee5a9e",
            "9f4f5d61eab54bc18be584f47e42b6d5"
          ]
        },
        "outputId": "f1c33c43-7ede-46f7-ef69-ac84e1d5d512"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.739 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.739 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/r9y9/open_jtalk/releases/download/v1.11.1/open_jtalk_dic_utf_8-1.11.tar.gz\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dic.tar.gz: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46c0702ae15944c9a1b434761dbfd883"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting tar file /usr/local/lib/python3.10/dist-packages/pyopenjtalk/dic.tar.gz\n",
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conda install -c conda-forge 'ffmpeg<7'"
      ],
      "metadata": {
        "id": "Owe_dKcl48Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4 开始训练"
      ],
      "metadata": {
        "id": "VA4hV2G_fyKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #STEP 4 (>=20 min)\n",
        "#@markdown 开始微调模型。\n",
        "#@markdown 训练时长取决于你录入/上传的音频总数。\n",
        "\n",
        "#@markdown 根据声线和样本质量的不同，所需的训练epochs数也不同。\n",
        "\n",
        "#@markdown 你也可以在Tensorboard中预览合成效果，若效果满意可提前停止。\n",
        "\n",
        "#@markdown Model fine-tuning\n",
        "#@markdown Total time cost depends on the number of voices you recorded/uploaded.\n",
        "\n",
        "#@markdown Best epoch number varies depending on different uploaded voices / sample quality.\n",
        "\n",
        "#@markdown You can also preview synthezied audio in Tensorboard, it's OK to shut down training manually if you find the quality is satisfying.\n",
        "import os\n",
        "os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "  !python scripts/rearrange_speaker.py\n",
        "  !cp ./G_latest.pth ../drive/MyDrive/G_checkpoint.pth\n",
        "  !cp ./OUTPUT_MODEL/D_latest.pth ../drive/MyDrive/D_checkpoint.pth\n",
        "  !cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n",
        "  !cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"./OUTPUT_MODEL\"\n",
        "Maximum_epochs = \"200\" #@param {type:\"string\"}\n",
        "#@markdown 继续之前的模型训练/Continue training from previous checkpoint\n",
        "CONTINUE = True #@param {type:\"boolean\"}\n",
        "if CONTINUE:\n",
        "  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed False --cont True --preserved 1\n",
        "else:\n",
        "  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed True"
      ],
      "metadata": {
        "id": "4gmpTNtcW2Bt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00d00ca3-3052-41aa-d0bb-9c139b82b950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VITS-fast-fine-tuning/scripts/rearrange_speaker.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_sd = torch.load(args.model_dir, map_location='cpu')\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/VITS-fast-fine-tuning/scripts/rearrange_speaker.py\", line 11, in <module>\n",
            "    model_sd = torch.load(args.model_dir, map_location='cpu')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1319, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 659, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 640, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './OUTPUT_MODEL/G_latest.pth'\n",
            "cp: cannot stat './finetune_speaker.json': No such file or directory\n",
            "cp: cannot stat './moegoe_config.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-08 02:49:25.266025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:49:25.286307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:49:25.292377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:49:25.306428: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-08 02:49:26.379403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:49:34.850414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:49:34.882574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:49:34.892451: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:49:36.487543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "INFO:OUTPUT_MODEL:{'train': {'log_interval': 10, 'eval_interval': 100, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 16, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'training_files': 'final_annotation_train.txt', 'validation_files': 'final_annotation_val.txt', 'text_cleaners': ['zh_ja_mixture_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 3, 'cleaned_text': True}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 256}, 'speakers': {'whitebear': 0, 'specialweek': 1, 'zhongli': 2}, 'symbols': ['_', ',', '.', '!', '?', '-', '~', '…', 'A', 'E', 'I', 'N', 'O', 'Q', 'U', 'a', 'b', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'ʃ', 'ʧ', 'ʦ', 'ɯ', 'ɹ', 'ə', 'ɥ', '⁼', 'ʰ', '`', '→', '↓', '↑', ' '], 'model_dir': '././OUTPUT_MODEL', 'max_epochs': 200, 'cont': True, 'drop_speaker_embed': False, 'train_with_pretrained_model': True, 'preserved': 1}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "Failed to find latest checkpoint, loading G_0.pth...\n",
            "Train with pretrained model...\n",
            "/content/VITS-fast-fine-tuning/utils.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
            "INFO:OUTPUT_MODEL:emb_g.weight is not in the checkpoint\n",
            "INFO:OUTPUT_MODEL:Loaded checkpoint './pretrained_models/G_0.pth' (iteration None)\n",
            "INFO:OUTPUT_MODEL:Loaded checkpoint './pretrained_models/D_0.pth' (iteration None)\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:150: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=hps.train.fp16_run)\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 02:49:50.482652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:49:50.502462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:49:50.508906: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:49:51.606383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:50:01.829731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:50:01.850027: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:50:01.856067: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:50:02.919460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=hps.train.fp16_run):\n",
            "/content/VITS-fast-fine-tuning/mel_processing.py:78: FutureWarning: Pass sr=22050, n_fft=1024, n_mels=80, fmin=0.0, fmax=None as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
            "/content/VITS-fast-fine-tuning/mel_processing.py:96: FutureWarning: Pass sr=22050, n_fft=1024, n_mels=80, fmin=0.0, fmax=None as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=False):\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:216: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=hps.train.fp16_run):\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=False):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
            "grad.sizes() = [1, 9, 96], strides() = [49248, 96, 1]\n",
            "bucket_view.sizes() = [1, 9, 96], strides() = [864, 96, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "INFO:OUTPUT_MODEL:Train Epoch: 1 [0%]\n",
            "INFO:OUTPUT_MODEL:[2.687987804412842, 1.8934342861175537, 10.664692878723145, 26.634418487548828, 1.7163931131362915, 10.795206069946289, 0, 0.0002]\n",
            "DEBUG:matplotlib:(private) matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "DEBUG:matplotlib:matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "DEBUG:matplotlib:CONFIGDIR=/root/.config/matplotlib\n",
            "DEBUG:matplotlib:matplotlib version 3.3.1\n",
            "DEBUG:matplotlib:interactive is False\n",
            "DEBUG:matplotlib:platform is linux\n",
            "DEBUG:matplotlib:loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', '_io', 'marshal', 'posix', '_frozen_importlib_external', 'time', 'zipimport', '_codecs', 'codecs', 'encodings.aliases', 'encodings', 'encodings.utf_8', '_signal', '_abc', 'abc', 'io', '__main__', 'types', 'enum', '_sre', 'sre_constants', 'sre_parse', 'sre_compile', '_collections_abc', 'itertools', 'keyword', '_operator', 'operator', 'reprlib', '_collections', 'collections', '_functools', 'functools', '_locale', 'copyreg', 're', 'warnings', '_stat', 'stat', 'genericpath', 'posixpath', 'os.path', 'os', '_sitebuiltins', '_distutils_hack', 'importlib._bootstrap', 'importlib._bootstrap_external', 'importlib', 'importlib._abc', 'contextlib', 'importlib.util', 'importlib.machinery', 'google', 'google.cloud', 'mpl_toolkits', 'sphinxcontrib', 'sitecustomize', 'site', '_weakrefset', 'threading', 'signal', 'multiprocessing.process', '_struct', 'struct', '_compat_pickle', '_pickle', 'pickle', '_socket', 'collections.abc', 'math', 'select', 'selectors', 'errno', 'array', 'socket', 'multiprocessing.reduction', 'multiprocessing.context', '__mp_main__', 'multiprocessing', 'runpy', 'weakref', 'atexit', 'fcntl', '_posixsubprocess', 'subprocess', 'multiprocessing.util', 'multiprocessing.spawn', '_multiprocessing', '_posixshmem', 'multiprocessing.resource_tracker', 'pkgutil', '_json', 'json.scanner', 'json.decoder', 'json.encoder', 'json', 'gettext', 'argparse', '_ctypes', 'ctypes._endian', 'ctypes', 'fnmatch', 'glob', '_ast', 'ast', '_opcode', 'opcode', 'dis', 'token', 'tokenize', 'linecache', 'inspect', 'platform', 'textwrap', 'typing.io', 'typing.re', 'typing', 'typing_extensions', 'traceback', '_string', 'string', 'logging', 'torch._utils', 'zlib', '_compression', '_bz2', 'bz2', '_lzma', 'lzma', 'shutil', '_bisect', 'bisect', '_random', '_sha512', 'random', 'tempfile', 'torch._strobelight', '_datetime', 'datetime', 'gc', 'timeit', 'torch._strobelight.cli_function_profiler', 'torch._strobelight.compile_time_profiler', 'torch._utils_internal', 'torch._vendor', 'torch._vendor.packaging', 'torch._vendor.packaging._structures', 'torch._vendor.packaging.version', 'torch.version', 'torch.torch_version', 'numpy._globals', 'numpy.__config__', 'numpy._distributor_init', '__future__', 'numpy._version', 'numpy.version', 'numpy.core._multiarray_umath', 'numpy.compat._inspect', 'ntpath', 'urllib', 'urllib.parse', 'pathlib', 'numpy.compat.py3k', 'numpy.compat', 'numpy.core.overrides', 'numpy.core.multiarray', 'numpy.core.umath', 'numbers', 'numpy.core._string_helpers', 'numpy.core._dtype', 'numpy.core._type_aliases', 'numpy.core.numerictypes', 'numpy.core._exceptions', '_contextvars', 'contextvars', 'numpy.core._ufunc_config', 'numpy.core._methods', 'numpy.core.fromnumeric', 'numpy.core.shape_base', 'numpy.core.arrayprint', 'numpy.core._asarray', 'numpy.core.numeric', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core._machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._multiarray_tests', 'numpy.core._add_newdocs', 'numpy.core._add_newdocs_scalars', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'numpy._pytesttester', 'numpy.core', 'numpy.lib.mixins', 'numpy.lib.ufunclike', 'numpy.lib.type_check', 'numpy.lib.scimath', 'numpy.lib.stride_tricks', 'numpy.lib.twodim_base', 'numpy.linalg._umath_linalg', 'numpy.linalg.linalg', 'numpy.linalg', 'numpy.matrixlib.defmatrix', 'numpy.matrixlib', 'numpy.lib.histograms', 'numpy.lib.function_base', 'numpy.lib.index_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.npyio', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.lib', 'numpy.fft._pocketfft_internal', 'numpy.fft._pocketfft', 'numpy.fft.helper', 'numpy.fft', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.polynomial', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.polynomial', 'cython_runtime', '_cython_0_29_35', 'numpy.random._common', 'binascii', 'base64', '_hashlib', '_blake2', 'hashlib', 'hmac', 'secrets', 'numpy.random.bit_generator', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random.mtrand', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.random._pickle', 'numpy.random', 'numpy.ctypeslib', 'numpy.ma.core', 'numpy.ma.extras', 'numpy.ma', 'numpy', 'torch._C._onnx', 'torch._C._jit', 'torch._C._jit_tree_views', 'torch._C._te', 'torch._C._monitor', 'torch._C._functorch', 'torch._C._profiler', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C._lazy', 'torch._C._lazy_ts_backend', 'torch._C._aoti', 'torch._C._itt', 'torch._C._cudart', 'torch._C._nvtx', 'torch._C._cudnn', 'torch._C._cusparselt', 'torch._C._cpu', 'torch._C._instruction_counter', 'torch._C._verbose', 'torch._C', 'torch._C._dynamo', 'torch._C._dynamo.autograd_compiler', 'torch._C._dynamo.eval_frame', 'torch._C._dynamo.guards', 'torch._C._dynamo.utils', 'torch._C._fft', 'torch._C._linalg', 'torch._C._nested', 'torch._C._nn', 'torch._C._return_types', 'torch._C._sparse', 'torch._C._special', 'copy', 'torch._namedtensor_internals', 'torch.overrides', 'torch._tensor', 'torch.types', 'torch.storage', 'torch.amp.autocast_mode', 'torch.amp.grad_scaler', 'torch.amp', 'torch.random', '_heapq', 'heapq', 'difflib', 'pwd', 'grp', 'tarfile', 'torch._weights_only_unpickler', 'torch._sources', 'mmap', 'torch.serialization', 'dataclasses', 'torch._tensor_str', 'torch.cuda.gds', 'torch.cuda._utils', 'torch.cuda.graphs', 'torch._streambase', 'torch.cuda.streams', 'torch.cuda._memory_viz', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.amp.autocast_mode', 'torch.cuda.amp.common', 'torch.cuda.amp.grad_scaler', 'torch.cuda.amp', 'torch.cuda.jiterator', 'torch.cuda.nvtx', 'torch.cuda.profiler', 'torch.cuda.sparse', 'torch.cuda.tunable', 'torch.cuda', 'torch.sparse._semi_structured_conversions', 'torch.sparse._semi_structured_ops', 'torch.sparse.semi_structured', 'torch.sparse', 'torch._compile', 'torch._VF', 'torch.nn.parameter', 'torch._prims_common', 'torch.utils.backcompat', 'locale', 'torch.utils.collect_env', '_queue', 'queue', 'cmd', 'bdb', 'codeop', 'code', 'pprint', 'pdb', 'torch._C._distributed_c10d', 'torch.utils._typing_utils', 'torch.distributed.logging_handlers', 'torch.distributed.c10d_logger', 'torch.distributed.constants', 'torch.distributed.rendezvous', 'torch.distributed.distributed_c10d', 'torch.distributed.device_mesh', 'torch.distributed.remote_device', 'torch.distributed', 'torch.utils.data.datapipes._hook_iterator', 'torch.utils.data.datapipes._typing', 'torch.utils._import_utils', 'torch.utils.data.datapipes.utils', 'torch.utils.data.datapipes.utils.common', 'torch.utils.data.dataset', 'torch.utils.data.datapipes.datapipe', 'torch.utils.data.datapipes._decorator', 'torch.utils.data.datapipes.dataframe.dataframe_wrapper', 'torch.utils.data.datapipes.dataframe.structures', 'torch.utils.data.datapipes.dataframe.dataframes', 'torch.utils.data.datapipes.dataframe.datapipes', 'torch.utils.data.datapipes.dataframe', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.worker', 'torch.utils.data._utils', 'torch.utils.data.datapipes.iter.callable', 'torch.utils.data.sampler', 'torch.utils.data.datapipes.iter.combinatorics', 'torch.utils.data.datapipes.iter.combining', 'torch.utils.data.datapipes.iter.utils', 'torch.utils.data.datapipes.iter.filelister', 'torch.utils.data.datapipes.iter.fileopener', 'torch.utils.data.datapipes.iter.sharding', 'torch.utils.data.datapipes.iter.grouping', 'torch.utils.data.datapipes.utils.decoder', 'torch.utils.data.datapipes.iter.routeddecoder', 'torch.utils.data.datapipes.iter.selecting', 'torch.utils.data.datapipes.iter.streamreader', 'torch.utils.data.datapipes.iter', 'torch.utils.data.datapipes.map.callable', 'torch.utils.data.datapipes.map.combinatorics', 'torch.utils.data.datapipes.map.combining', 'torch.utils.data.datapipes.map.grouping', 'torch.utils.data.datapipes.map.utils', 'torch.utils.data.datapipes.map', 'torch.utils.data.datapipes', 'torch.utils.data.graph', 'torch.utils.data.graph_settings', 'torch.utils.data.dataloader', 'torch.utils.data.distributed', 'torch.utils.data', 'torch.utils.deterministic', 'torch.utils.hooks', 'torch.utils.backend_registration', 'torch.utils.cpp_backtrace', 'torch.utils.throughput_benchmark', 'torch.utils', 'torchgen', 'torchgen.code_template', 'torchgen.utils', 'torchgen.model', 'torch.utils._python_dispatch', 'torch.nn.modules.module', 'torch._C._distributed_rpc', 'torch._C._distributed_autograd', 'torch.distributed.autograd', 'torch.futures', 'torch.distributed.rpc._utils', 'torch.distributed.rpc.constants', 'torch.distributed.rpc.internal', 'torch.distributed.rpc.api', 'torch.distributed.rpc.backend_registry', 'torch.distributed.rpc.functions', 'torch.distributed.rpc.options', 'torch.utils._pytree', 'torch._vmap_internals', 'torch.utils._contextlib', 'torch.autograd.grad_mode', 'torch.autograd.forward_ad', 'torch.autograd.functional', 'torch.autograd.variable', 'torch.autograd.graph', 'torch.autograd.anomaly_mode', 'torch._functorch', 'torch.utils._exposed_in', 'torch._functorch.utils', 'torch._functorch.vmap', 'torch._functorch.apis', 'torch._functorch.pyfunctorch', 'torch._ops', 'torch._functorch.autograd_function', 'torch.autograd.function', 'torch.testing._utils', 'cmath', 'torch.testing._comparison', 'torch.testing._creation', 'torch.testing', 'torch.autograd.gradcheck', 'torch._C._autograd', 'torch.autograd.profiler_util', 'torch.autograd.profiler', 'torch.autograd', 'torch.autograd.profiler_legacy', 'torch.distributed.rpc.server_process_global_profiler', 'torch.distributed.rpc', 'pickletools', 'torch.package._digraph', 'torch.package._importlib', 'torch.package._mangling', 'torch.package.importer', 'torch.package._package_pickler', 'torch.package._stdlib', 'torch.package.find_file_dependencies', 'torch.package.glob_group', 'torch.package.package_exporter', 'torch.package.analyze.find_first_use_of_broken_modules', 'torch.package.analyze.trace_dependencies', 'torch.package.analyze', 'torch.package.analyze.is_from_package', 'torch.package.file_structure_representation', 'torch.package._directory_reader', 'torch.package._package_unpickler', 'torch.package.package_importer', 'torch.package', 'torch._awaits', 'torch._jit_internal', 'torch._torch_docs', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn.functional', 'torch.nn.init', 'torch.nn.modules.lazy', 'torch.nn.modules.linear', 'torch.nn.modules.activation', 'torch.nn.modules.container', 'torch.nn.modules.adaptive', 'torch.nn.modules._functions', 'torch.nn.modules.batchnorm', 'torch.nn.modules.channelshuffle', 'torch.nn.common_types', 'torch.nn.modules.conv', 'torch.nn.modules.distance', 'torch.nn.modules.dropout', 'torch.nn.modules.flatten', 'torch.nn.modules.fold', 'torch.nn.modules.instancenorm', 'torch.nn.modules.loss', 'torch.nn.modules.normalization', 'torch.nn.modules.padding', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.pooling', 'torch.__future__', 'torch.nn.utils.parametrize', 'torch.nn.utils.parametrizations', 'torch.nn.utils.rnn', 'torch.nn.utils._named_member_accessor', 'torch.nn.utils.stateless', 'torch.utils._foreach_utils', 'torch.nn.utils.clip_grad', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.fusion', 'torch.nn.utils.init', 'torch.nn.utils.memory_format', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.weight_norm', 'torch.nn.utils', 'torch.nn.modules.rnn', 'torch.nn.modules.sparse', 'torch.nn.modules.transformer', 'torch.nn.modules.upsampling', 'torch.nn.modules', 'torch.backends.cpu', 'torch.backends.cuda', 'torch.backends.cudnn', 'torch.backends.cusparselt', 'torch.backends.mha', 'torch.backends.mkl', 'torch.backends.mkldnn', 'torch._library.utils', 'torch._library.autograd', 'torch._library.fake_impl', 'torch._library.simple_registry', 'torch._library.fake_class_registry', 'torch._library.custom_ops', 'torch._library.infer_schema', 'torch._library.triton', 'torch._library', 'torch.library', 'torch.backends.mps', 'torch.backends.nnpack', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.backends', 'torch.nn.attention', 'torch.nn.parallel.parallel_apply', 'torch.cuda.nccl', 'torch.nn.parallel.comm', 'torch.nn.parallel.replicate', 'torch.nn.parallel._functions', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel.data_parallel', 'torch.distributed.algorithms.join', 'torch.distributed.algorithms', 'torch.distributed.utils', 'torch.nn.parallel.distributed', 'torch.nn.parallel', 'torch.nn', 'torch._linalg_utils', 'torch._lowrank', 'torch.functional', 'torch.__config__', 'torch.cpu.amp.autocast_mode', 'torch.cpu.amp.grad_scaler', 'torch.cpu.amp', 'torch.cpu', 'torch.distributions.constraints', 'torch.distributions.utils', 'torch.distributions.transforms', 'torch.distributions.distribution', 'torch.distributions.exp_family', 'torch.distributions.bernoulli', 'torch.distributions.dirichlet', 'torch.distributions.beta', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.gamma', 'torch.distributions.chi2', 'torch.distributions.constraint_registry', 'torch.distributions.continuous_bernoulli', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.independent', 'torch.distributions.transformed_distribution', 'torch.distributions.uniform', 'torch.distributions.gumbel', 'torch.distributions.half_cauchy', 'torch.distributions.normal', 'torch.distributions.half_normal', 'torch.distributions.inverse_gamma', 'torch.distributions.laplace', 'torch.distributions.multivariate_normal', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.kl', 'torch.distributions.kumaraswamy', 'torch.distributions.lkj_cholesky', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.mixture_same_family', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.jit._builtins', 'torch.jit._async', 'torch.jit._await', 'torch.jit._decomposition_utils', 'torch._classes', 'torch.jit._fuser', 'torch.jit._monkeytype_config', 'torch.jit._check', 'torch.jit._state', 'torch.jit.annotations', 'torch.jit._dataclass_impls', 'six', 'six.moves', 'astunparse.unparser', 'astunparse.printer', 'astunparse', 'torch.jit.frontend', 'torch.jit._recursive', 'torch.jit._serialization', 'torch.jit._script', 'torch.jit._freeze', 'torch.jit._ir_utils', 'torch.jit._trace', 'torch.jit', 'torch.distributions.von_mises', 'torch.distributions.weibull', 'torch.distributions.wishart', 'torch.distributions', 'torch.fft', '_uuid', 'uuid', 'zipfile', 'urllib.response', 'urllib.error', 'email', 'http', 'email.errors', 'email.quoprimime', 'email.base64mime', 'quopri', 'email.encoders', 'email.charset', 'email.header', 'calendar', 'email._parseaddr', 'email.utils', 'email._policybase', 'email.feedparser', 'email.parser', 'uu', 'email._encoded_words', 'email.iterators', 'email.message', '_ssl', 'ssl', 'http.client', 'urllib.request', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'unicodedata', 'tqdm.utils', 'tqdm.std', 'tqdm._dist_ver', 'tqdm.version', 'tqdm.cli', 'tqdm.gui', 'tqdm', 'torch.hub', 'torch.linalg', 'torch.mps.profiler', 'torch.mps.event', 'torch.mps', 'torch.mtia._utils', 'torch.mtia', 'multiprocessing.resource_sharer', 'torch.multiprocessing.reductions', 'multiprocessing.connection', 'concurrent', 'concurrent.futures._base', 'concurrent.futures', 'concurrent.futures.thread', 'torch.multiprocessing.spawn', 'torch.multiprocessing', 'torch.nested', 'torch.optim.optimizer', 'torch.optim.lr_scheduler', 'torch.optim.swa_utils', 'torch.optim._adafactor', 'torch.optim.adadelta', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamax', 'torch.optim.adamw', 'torch.optim.asgd', 'torch.optim.lbfgs', 'torch.optim.nadam', 'torch.optim.radam', 'torch.optim.rmsprop', 'torch.optim.rprop', 'torch.optim.sgd', 'torch.optim._functional', 'torch.optim.sparse_adam', 'torch.optim', 'gzip', 'torch.profiler._utils', 'torch.profiler._memory_profiler', 'torch.profiler.profiler', 'torch.profiler.itt', 'torch.profiler', 'torch.special', 'torch.xpu._utils', 'torch.xpu.streams', 'torch.xpu.memory', 'torch.xpu.random', 'torch.xpu', 'torch.signal.windows.windows', 'torch.signal.windows', 'torch.signal', 'torch.ao', 'torch.ao.nn', 'torch.ao.nn.intrinsic.modules.fused', 'torch.ao.nn.intrinsic.modules', 'torch.ao.nn.intrinsic', 'torch.nn.intrinsic.modules.fused', 'torch.nn.intrinsic.modules', 'torch.ao.nn.qat.modules.conv', 'torch.ao.nn.qat.modules.embedding_ops', 'torch.ao.nn.qat.modules.linear', 'torch.ao.nn.qat.modules', 'torch.ao.nn.qat', 'torch.ao.nn.intrinsic.qat.modules.conv_fused', 'torch.ao.nn.intrinsic.qat.modules.linear_fused', 'torch.ao.nn.intrinsic.qat.modules.linear_relu', 'torch.ao.nn.intrinsic.qat.modules', 'torch.ao.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch.nn.intrinsic.qat.modules.linear_fused', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat', 'torch.ao.nn.quantizable.modules.activation', 'torch.ao.nn.quantizable.modules.rnn', 'torch.ao.nn.quantizable.modules', 'torch.ao.nn.quantizable', 'torch.ao.nn.quantized.modules.activation', 'torch.ao.nn.quantized.modules.batchnorm', 'torch.ao.nn.quantized.modules.utils', 'torch.ao.nn.quantized.modules.conv', 'torch.ao.nn.quantized.modules.dropout', 'torch.ao.nn.quantized.modules.embedding_ops', 'torch.ao.nn.quantized.modules.functional_modules', 'torch.ao.nn.quantized.modules.linear', 'torch.ao.nn.quantized.modules.normalization', 'torch.ao.nn.quantized.modules.rnn', 'torch.ao.nn.quantized.modules', 'torch.ao.nn.quantized.functional', 'torch.ao.nn.quantized', 'torch.ao.nn.intrinsic.quantized.modules.bn_relu', 'torch.ao.nn.intrinsic.quantized.modules.conv_add', 'torch.ao.nn.intrinsic.quantized.modules.conv_relu', 'torch.ao.nn.intrinsic.quantized.modules.linear_relu', 'torch.ao.nn.intrinsic.quantized.modules', 'torch.ao.nn.intrinsic.quantized', 'torch.ao.nn.quantized.dynamic.modules.conv', 'torch.ao.nn.quantized.dynamic.modules.linear', 'torch.ao.nn.quantized.dynamic.modules.rnn', 'torch.ao.nn.quantized.dynamic.modules', 'torch.ao.nn.quantized.dynamic', 'torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu', 'torch.ao.nn.intrinsic.quantized.dynamic.modules', 'torch.ao.nn.intrinsic.quantized.dynamic', 'torch.nn.intrinsic.quantized.dynamic.modules.linear_relu', 'torch.nn.intrinsic.quantized.dynamic.modules', 'torch.nn.intrinsic.quantized.dynamic', 'torch.nn.intrinsic.quantized.modules.bn_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic', 'torch.ao.nn.qat.dynamic.modules.linear', 'torch.ao.nn.qat.dynamic.modules', 'torch.ao.nn.qat.dynamic', 'torch.nn.qat.dynamic.modules.linear', 'torch.nn.qat.dynamic.modules', 'torch.nn.qat.dynamic', 'torch.nn.qat.modules.conv', 'torch.nn.qat.modules.embedding_ops', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules', 'torch.nn.qat', 'torch.nn.quantizable.modules', 'torch.nn.quantizable', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules', 'torch.nn.quantized', 'torch._size_docs', 'torch._storage_docs', 'torch._tensor_docs', 'torch.ops', 'torch.classes', 'torch.ao.quantization.quant_type', 'torch.fx._compatibility', 'torch.fx.immutable_collections', 'torch.fx.operator_schemas', 'torch.fx.node', 'torch.return_types', 'torch.fx._pytree', 'torch.fx.graph', 'torch.fx.graph_module', 'torch.fx._lazy_graph_module', 'torch.utils._traceback', 'torch.fx.traceback', 'torch.fx.proxy', 'torch.fx._symbolic_trace', 'torch.fx.config', 'torch.fx.interpreter', 'torch.fx.subgraph_rewriter', 'torch.fx', 'torch.ao.quantization.utils', 'torch.ao.quantization.observer', 'torch.ao.quantization.fake_quantize', 'torch.ao.quantization.fuser_method_mappings', 'torch.ao.quantization.fuse_modules', 'torch.ao.quantization.pt2e', 'torch.ao.ns', 'torch.ao.ns.fx', 'torch.ao.ns.fx.ns_types', 'torch.ao.ns.fx.utils', 'torch.ao.quantization.pt2e._numeric_debugger', 'torch.ao.quantization.pt2e.export_utils', 'torch.ao.quantization.qconfig', 'torch.ao.quantization.qconfig_mapping', 'torch.ao.nn.quantized.reference.modules.utils', 'torch.ao.nn.quantized.reference.modules.conv', 'torch.ao.nn.quantized.reference.modules.linear', 'torch.ao.nn.quantized.reference.modules.rnn', 'torch.ao.nn.quantized.reference.modules.sparse', 'torch.ao.nn.quantized.reference.modules', 'torch.ao.nn.quantized.reference', 'torch.ao.nn.sparse.quantized.linear', 'torch.ao.nn.sparse.quantized.utils', 'torch.ao.nn.sparse.quantized.dynamic.linear', 'torch.ao.nn.sparse.quantized.dynamic', 'torch.ao.nn.sparse.quantized', 'torch.ao.nn.sparse', 'torch.ao.quantization.stubs', 'torch.ao.quantization.quantization_mappings', 'torch.ao.quantization.quantize', 'torch.ao.quantization.quantize_jit', 'torch.ao.quantization', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.quantization.fuser_method_mappings', 'torch.quantization.observer', 'torch.quantization.qconfig', 'torch.quantization.quant_type', 'torch.quantization.quantization_mappings', 'torch.quantization.quantize', 'torch.quantization.quantize_jit', 'torch.quantization.stubs', 'torch.quantization', 'torch.quasirandom', 'torch.multiprocessing._atfork', 'torch._lobpcg', 'torch.masked._docs', 'torch.masked.maskedtensor.core', 'torch.masked.maskedtensor.binary', 'torch.masked.maskedtensor.passthrough', 'torch.masked.maskedtensor.creation', 'torch.masked.maskedtensor.reductions', 'torch.masked.maskedtensor.unary', 'torch.masked.maskedtensor', 'torch.masked._ops', 'torch.masked', 'torch.utils.dlpack', 'torch._dispatch', 'unittest.util', 'unittest.result', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.signals', 'unittest.runner', 'unittest.main', 'unittest', 'asyncio.constants', 'asyncio.format_helpers', 'asyncio.base_futures', 'asyncio.log', 'asyncio.coroutines', 'asyncio.exceptions', 'asyncio.base_tasks', '_asyncio', 'asyncio.events', 'asyncio.futures', 'asyncio.protocols', 'asyncio.transports', 'asyncio.sslproto', 'asyncio.mixins', 'asyncio.tasks', 'asyncio.locks', 'asyncio.staggered', 'asyncio.trsock', 'asyncio.base_events', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.threads', 'asyncio.base_subprocess', 'asyncio.selector_events', 'asyncio.unix_events', 'asyncio', 'unittest.mock', 'torch._dispatch.python', 'torch.utils.weak', 'torch._guards', 'torch._logging.structured', 'torch._logging._internal', 'torch._logging._registrations', 'torch._logging', 'torch.utils._mode_utils', 'torch._subclasses.meta_utils', 'torch.utils._backport_slots', 'torch.utils._stats', 'torch.fx.experimental', 'torch.fx.experimental.sym_node', 'torch._subclasses._fake_tensor_utils', 'torch._custom_op', 'torch._subclasses.fake_impls', 'torch._subclasses.fake_tensor', 'torch._subclasses.fake_utils', 'torch._subclasses', 'torch.fx.passes.shape_prop', 'pyparsing.util', 'pyparsing.unicode', 'pyparsing.exceptions', 'pyparsing.actions', 'pyparsing.results', 'pyparsing.core', 'html.entities', 'html', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'pyparsing', 'pydot.dot_parser', 'pydot._vendor', 'pydot._vendor.tempfile', 'pydot.core', 'pydot.exceptions', 'pydot', 'torch.fx.passes.graph_drawer', 'torch.fx.passes.graph_manipulation', 'torch.fx.passes.utils.matcher_utils', 'torch.fx.passes.utils.common', 'torch.fx.passes.utils', 'torch.fx.passes.tools_common', 'torch.fx.passes.split_utils', 'torch.fx.passes.net_min_base', 'torch.fx.passes.operator_support', 'torch.fx.passes.param_fetch', 'torch.fx.passes.reinplace', 'torch.fx._utils', 'torch.utils._thunk', 'torch.fx.experimental._backward_state', 'torch.fx.experimental.proxy_tensor', 'torch.fx.passes.runtime_assert', 'torch.fx.passes.split_module', 'torch.fx.passes.splitter_base', 'torch.fx.passes', 'torch.fx.passes.infra.pass_base', 'torch.fx.passes.infra.pass_manager', 'torch.fx.passes.infra', 'torch._inductor', 'torch.utils._config_module', 'torch._inductor.config', 'torch._subclasses.functional_tensor', 'torch._higher_order_ops.utils', 'torch._higher_order_ops.cond', 'torch._higher_order_ops.flex_attention', 'torch._higher_order_ops.hints_wrap', 'torch._higher_order_ops.while_loop', 'torch._higher_order_ops', 'torch.export._tree_utils', 'torch.export.graph_signature', 'torch._custom_op.autograd', 'torch._custom_op.impl', 'torch._custom_ops', 'torch._higher_order_ops.strict_mode', 'torch._export.wrappers', 'torch._export', 'torch._export.utils', 'torch._export.verifier', 'torch.export.exported_program', 'torch.export.dynamic_shapes', 'torch._functorch._aot_autograd', 'torch._functorch._aot_autograd.utils', 'torch._higher_order_ops.torchbind', 'torch._higher_order_ops.effects', 'torch.export._remove_effect_tokens_pass', 'torch.export.unflatten', 'torch.export', 'torch.fx.experimental.const_fold', 'torch._functorch.eager_transforms', 'torch._functorch.functional_call', 'torch._functorch.batch_norm_replacement', 'torch.func', 'torch.utils._content_store', 'torch._prims.debug_prims', 'torch._prims.rng_prims', 'torch._prims_common.wrappers', 'torch._prims', 'torch._higher_order_ops.out_dtype', 'torch._decomp.decompositions', 'torch._refs._conversions', 'torch._refs.fft', 'torch._refs.linalg', 'torch._refs.nn', 'torch._refs.nn.functional', 'torch._refs.special', 'torch._refs', 'torch._decomp', 'torch._meta_registrations', 'torch.compiler', '_csv', 'csv', 'importlib.metadata._functools', 'importlib.metadata._text', 'importlib.metadata._adapters', 'importlib.metadata._meta', 'importlib.metadata._collections', 'importlib.metadata._itertools', 'importlib.abc', 'importlib.metadata', 'torch', 'tensorboard.lazy', 'tensorboard.version', 'tensorboard', 'tensorboard.compat', 'tensorboard.compat.proto', 'google.protobuf', 'google.protobuf.internal', 'google.protobuf.internal.enum_type_wrapper', 'google._upb', 'google.protobuf.message', 'google._upb._message', 'google.protobuf.internal.api_implementation', 'google.protobuf.descriptor', 'google.protobuf.descriptor_database', 'google.protobuf.text_encoding', 'encodings.raw_unicode_escape', 'encodings.unicode_escape', 'google.protobuf.internal.containers', 'google.protobuf.internal.wire_format', 'google.protobuf.internal.encoder', 'google.protobuf.internal.decoder', 'google.protobuf.internal.type_checkers', 'google.protobuf.unknown_fields', 'google.protobuf.text_format', 'google.protobuf.internal.extension_dict', 'google.protobuf.internal.message_listener', 'google.protobuf.internal.field_mask', 'google.protobuf.internal.well_known_types', 'google.protobuf.internal.python_message', 'google.protobuf.descriptor_pool', 'google.protobuf.pyext', 'google.protobuf.pyext.cpp_message', 'google.protobuf.message_factory', 'google.protobuf.symbol_database', 'google.protobuf.reflection', 'tensorboard.compat.proto.histogram_pb2', 'tensorboard.compat.proto.tensor_shape_pb2', 'tensorboard.compat.proto.types_pb2', 'tensorboard.compat.proto.resource_handle_pb2', 'tensorboard.compat.proto.tensor_pb2', 'tensorboard.compat.proto.summary_pb2', 'tensorboard.compat.proto.event_pb2', 'tensorboard.plugins', 'tensorboard.plugins.projector.metadata', 'tensorboard.plugins.projector.projector_config_pb2', 'tensorboard.plugins.projector', 'tensorboard.plugins.audio', 'tensorboard.util', 'tensorboard.util.op_evaluator', 'tensorboard.util.encoder', 'tensorboard.plugins.audio.plugin_data_pb2', 'tensorboard.plugins.audio.metadata', 'tensorboard.util.lazy_tensor_creator', 'tensorboard.plugins.audio.summary_v2', 'tensorboard.plugins.audio.summary', 'tensorboard.plugins.custom_scalar', 'tensorboard.plugins.custom_scalar.layout_pb2', 'tensorboard.plugins.custom_scalar.metadata', 'tensorboard.plugins.custom_scalar.summary', 'tensorboard.plugins.histogram', 'tensorboard.plugins.histogram.plugin_data_pb2', 'tensorboard.plugins.histogram.metadata', 'tensorboard.compat.proto.cost_graph_pb2', 'tensorboard.compat.proto.attr_value_pb2', 'tensorboard.compat.proto.full_type_pb2', 'tensorboard.compat.proto.node_def_pb2', 'tensorboard.compat.proto.op_def_pb2', 'tensorboard.compat.proto.function_pb2', 'tensorboard.compat.proto.graph_debug_info_pb2', 'tensorboard.compat.proto.versions_pb2', 'tensorboard.compat.proto.graph_pb2', 'tensorboard.compat.proto.allocation_description_pb2', 'tensorboard.compat.proto.tensor_description_pb2', 'tensorboard.compat.proto.step_stats_pb2', 'tensorboard.compat.proto.cluster_pb2', 'tensorboard.compat.proto.debug_pb2', 'tensorboard.compat.proto.verifier_config_pb2', 'tensorboard.compat.proto.rewriter_config_pb2', 'tensorboard.compat.proto.rpc_options_pb2', 'tensorboard.compat.proto.coordination_config_pb2', 'tensorboard.compat.proto.config_pb2', 'google.protobuf.internal.builder', 'google.protobuf.any_pb2', 'tensorboard.compat.proto.variable_pb2', 'tensorboard.compat.proto.struct_pb2', 'google.protobuf.wrappers_pb2', 'tensorboard.compat.proto.trackable_object_graph_pb2', 'tensorboard.compat.proto.saved_object_graph_pb2', 'tensorboard.compat.proto.saver_pb2', 'tensorboard.compat.proto.meta_graph_pb2', 'tensorboard.compat.tensorflow_stub.error_codes', 'tensorboard.compat.tensorflow_stub.errors', 'fsspec.caching', 'fsspec._version', 'fsspec.callbacks', 'fsspec.utils', 'configparser', 'fsspec.config', 'fsspec.dircache', 'fsspec.transaction', 'fsspec.spec', 'fsspec.compression', 'fsspec.registry', 'fsspec.core', 'fsspec.exceptions', 'fsspec.mapping', 'fsspec', 'tensorboard.compat.tensorflow_stub.compat.v1', 'tensorboard.compat.tensorflow_stub.compat', 'tensorboard.compat.tensorflow_stub.io.gfile', 'tensorboard.compat.tensorflow_stub.io', 'tensorboard.compat.tensorflow_stub.pywrap_tensorflow', 'tensorboard.compat.tensorflow_stub.dtypes', 'absl', 'getopt', 'termios', 'absl.flags._helpers', 'absl.flags._argument_parser', 'absl.flags._exceptions', 'absl.flags._flag', 'xml', 'xml.dom.domreg', 'xml.dom', 'xml.dom.minicompat', 'xml.dom.NodeFilter', 'xml.dom.xmlbuilder', 'xml.dom.minidom', 'absl.flags._validators_classes', 'absl.flags._flagvalues', 'absl.flags._validators', 'absl.flags._defines', 'absl.flags', 'tensorboard.compat.tensorflow_stub.flags', 'tensorboard.compat.tensorflow_stub.app', 'tensorboard.compat.tensorflow_stub.tensor_shape', 'tensorboard.compat.tensorflow_stub', 'tensorboard.util.tensor_util', 'tensorboard.plugins.histogram.summary_v2', 'tensorboard.plugins.histogram.summary', 'tensorboard.plugins.image', 'tensorboard.plugins.image.plugin_data_pb2', 'tensorboard.plugins.image.metadata', 'tensorboard.plugins.image.summary_v2', 'tensorboard.plugins.image.summary', 'tensorboard.plugins.pr_curve', 'tensorboard.plugins.pr_curve.plugin_data_pb2', 'tensorboard.plugins.pr_curve.metadata', 'tensorboard.plugins.pr_curve.summary', 'tensorboard.plugins.scalar', 'tensorboard.plugins.scalar.plugin_data_pb2', 'tensorboard.plugins.scalar.metadata', 'tensorboard.plugins.scalar.summary_v2', 'tensorboard.plugins.scalar.summary', 'tensorboard.plugins.text', 'tensorboard.plugins.text.plugin_data_pb2', 'tensorboard.plugins.text.metadata', 'tensorboard.plugins.text.summary_v2', 'tensorboard.plugins.text.summary', 'tensorboard.summary.v1', 'tensorboard.summary.v2', 'tensorboard.summary.writer', 'tensorboard.summary.writer.record_writer', 'tensorboard.summary.writer.event_file_writer', 'tensorboard.summary._output', 'tensorboard.summary._writer', 'tensorboard.summary', 'torch.utils.tensorboard._convert_np', 'torch.utils.tensorboard._utils', 'sysconfig', 'jaraco', 'more_itertools.recipes', 'more_itertools.more', 'more_itertools', 'jaraco.functools', 'distutils.compat.py38', 'distutils.compat', 'distutils.compat.py39', 'distutils.errors', 'distutils._log', 'distutils._modified', 'distutils.debug', 'distutils.spawn', 'distutils.util', 'distutils.sysconfig', 'distutils.command', 'importlib._adapters', 'importlib._common', 'importlib.resources', 'backports.tarfile.compat', 'backports.tarfile.compat.py38', 'backports.tarfile', 'jaraco.context', 'importlib.readers', 'jaraco.text', 'jaraco.collections', 'distutils.file_util', 'distutils.dir_util', 'distutils.archive_util', 'distutils.cmd', 'packaging', 'packaging._elffile', 'packaging._manylinux', 'packaging._musllinux', 'packaging.tags', 'packaging._structures', 'packaging.version', 'packaging.utils', 'distutils.fancy_getopt', 'distutils.dist', 'distutils.extension', 'distutils.core', 'distutils.command._framework_compat', 'distutils.command.install', 'distutils.command.install_egg_info', '_distutils_system_mod', 'setuptools._distutils', '_distutils_hack.override', 'distutils.filelist', 'setuptools.monkey', 'distutils.log', 'setuptools.logging', 'setuptools._imp', 'setuptools.depends', 'setuptools._path', 'setuptools.discovery', 'packaging.specifiers', 'packaging._tokenizer', 'packaging._parser', 'packaging.markers', 'setuptools._importlib', 'setuptools._itertools', 'setuptools.errors', 'setuptools._entry_points', 'packaging.requirements', 'setuptools._reqs', 'distutils.command.bdist', 'setuptools.command', 'setuptools.warnings', 'setuptools.config.expand', 'setuptools.config.setupcfg', 'setuptools.config', 'email._header_value_parser', 'email.headerregistry', 'setuptools.extension', 'setuptools.config._apply_pyprojecttoml', 'setuptools.config.pyprojecttoml', 'setuptools.dist', 'setuptools.version', 'setuptools._normalization', 'setuptools._core_metadata', 'setuptools', 'distutils', 'tensorflow.python', 'tensorflow.python.platform', 'tensorflow.python.platform.build_info', 'tensorflow.python.platform.self_check', 'tensorflow.python.platform._pywrap_cpu_feature_guard', 'tensorflow.python._pywrap_tensorflow_internal', 'tensorflow.python.pywrap_tensorflow', 'tensorflow.python.tools', 'tensorflow.python.tools.module_util', 'tensorflow.python.util', 'tensorflow.python.util.tf_decorator', 'tensorflow.python.util.tf_inspect', 'tensorflow.python.util.tf_export', 'tensorflow.python.platform.tf_logging', 'tensorflow.python.util.lazy_loader', 'tensorflow.python.platform._pywrap_tf2', 'tensorflow.python.tf2', 'tensorflow._api', 'tensorflow._api.v2', 'tensorflow.python.util.all_util', 'tensorflow.python.autograph', 'tensorflow.python.autograph.core', 'tensorflow.python.framework', 'absl.command_name', 'getpass', 'absl.logging.converter', 'absl.logging', 'faulthandler', 'absl.app', 'numpy._typing._nested_sequence', 'numpy._typing._nbit', 'numpy._typing._char_codes', 'numpy._typing._scalars', 'numpy._typing._shape', 'numpy._typing._generic_alias', 'numpy._typing._dtype_like', 'numpy._typing._array_like', 'numpy._typing', 'numpy._typing._add_docstring', 'numpy.typing', 'tensorflow.core', 'tensorflow.core.framework', 'tensorflow.core.framework.tensor_shape_pb2', 'tensorflow.core.framework.types_pb2', 'tensorflow.core.framework.resource_handle_pb2', 'tensorflow.core.framework.tensor_pb2', 'tensorflow.core.framework.attr_value_pb2', 'tensorflow.core.framework.full_type_pb2', 'tensorflow.core.framework.node_def_pb2', 'tensorflow.core.framework.op_def_pb2', 'tensorflow.core.framework.function_pb2', 'tensorflow.core.framework.graph_debug_info_pb2', 'tensorflow.core.framework.versions_pb2', 'tensorflow.core.framework.graph_pb2', 'tensorflow.core.protobuf', 'tensorflow.core.framework.cost_graph_pb2', 'tensorflow.core.framework.allocation_description_pb2', 'tensorflow.core.framework.tensor_description_pb2', 'tensorflow.core.framework.step_stats_pb2', 'tensorflow.core.protobuf.cluster_pb2', 'tensorflow.core.protobuf.debug_pb2', 'tensorflow.core.protobuf.verifier_config_pb2', 'tensorflow.core.protobuf.rewriter_config_pb2', 'tensorflow.tsl', 'tensorflow.tsl.protobuf', 'tensorflow.tsl.protobuf.rpc_options_pb2', 'tensorflow.core.protobuf.rpc_options_pb2', 'tensorflow.tsl.protobuf.coordination_config_pb2', 'tensorflow.core.protobuf.config_pb2', 'tensorflow.python._pywrap_tfe', 'tensorflow.python.pywrap_tfe', 'tensorflow.python.client', 'tensorflow.python.client._pywrap_tf_session', 'pybind11_abseil.status', 'tensorflow.python.util._tf_stack', 'tensorflow.python.util.tf_stack', 'tensorflow.python.client.pywrap_tf_session', 'tensorflow.python.eager', 'tensorflow.python.eager.cancellation', 'tensorflow.core.lib', 'tensorflow.core.lib.core', 'tensorflow.tsl.protobuf.error_codes_pb2', 'tensorflow.core.lib.core.error_codes_pb2', 'tensorflow.python._pywrap_py_exception_registry', 'tensorflow.core.framework.api_def_pb2', 'tensorflow.python.util.compat', 'tensorflow.python.util.tf_contextlib', 'tensorflow.python.framework.c_api_util', 'tensorflow.python.framework.strict_mode', 'tensorflow.python.util.decorator_utils', 'tensorflow.python.util.is_in_graph_mode', 'tensorflow.tools', 'tensorflow.tools.docs', 'tensorflow.tools.docs.doc_controls', 'tensorflow.python.util.deprecation', 'tensorflow.python.framework.errors_impl', 'tensorflow.python.framework.errors', 'tensorflow.python.eager.core', 'ml_dtypes._ml_dtypes_ext', 'ml_dtypes._finfo', 'ml_dtypes._iinfo', 'ml_dtypes', 'tensorflow.python.framework._dtypes', 'tensorflow.python.framework.cpp_shape_inference_pb2', 'tensorflow.python.types', 'tensorflow.python.types.doc_typealias', 'tensorflow.python.types.core', 'tensorflow.python.types.trace', 'tensorflow.core.function', 'tensorflow.core.function.trace_type.serialization_pb2', 'tensorflow.core.function.trace_type.default_types_pb2', 'tensorflow.core.function.trace_type.serialization', 'tensorflow.core.function.trace_type.util', 'tensorflow.core.function.trace_type.default_types', 'tensorflow.python.util.custom_nest_protocol', 'tensorflow.core.function.trace_type.custom_nest_trace_type', 'tensorflow.core.function.trace_type.trace_type_builder', 'tensorflow.core.function.trace_type', 'tensorflow.python.framework.dtypes', 'tensorflow.python.framework.tensor_conversion_registry', 'tensorflow.core.protobuf.struct_pb2', 'tensorflow.tsl.protobuf.histogram_pb2', 'tensorflow.core.framework.summary_pb2', 'tensorflow.python.eager.monitoring', 'tensorflow.python.saved_model', 'tensorflow.python.types.internal', 'tensorflow.python.framework.type_spec_registry', 'tensorflow.python.util._pywrap_nest', 'tensorflow.python.util._pywrap_utils', 'wrapt.wrappers', 'wrapt._wrappers', 'wrapt.__wrapt__', 'wrapt.patches', 'wrapt.weakrefs', 'wrapt.arguments', 'wrapt.decorators', 'wrapt.importer', 'wrapt', 'tensorflow.python.util.nest_util', 'tensorflow.python.util.nest', 'tensorflow.python.saved_model.nested_structure_coder', 'tensorflow.python.framework.tensor_shape', 'tensorflow.python.eager.execute', 'tensorflow.python.eager.executor', 'tensorflow.python.framework.device_spec', 'tensorflow.python.framework.device', 'tensorflow.python.framework.tfrt_utils', 'tensorflow.python.util.function_utils', 'tensorflow.python.eager.context', 'tensorflow.python.eager.record', 'tensorflow.python.framework.composite_tensor', 'tensorflow.python.framework.op_callbacks', 'tensorflow.python.framework.registry', 'tensorflow.python.framework.stack', 'tensorflow.python.framework.common_shapes', 'tensorflow.python.framework.tensor_util', 'tensorflow.python.framework.type_spec', 'tensorflow.python.ops', 'tensorflow.python.ops.handle_data_util', 'tensorflow.python.util.object_identity', 'tensorflow.python.framework.tensor', 'tensorflow.python.framework.traceable_stack', 'tensorflow.python.framework.versions', 'tensorflow.python.ops.control_flow_util', 'tensorflow.python.profiler', 'tensorflow.python.profiler.internal', 'tensorflow.python.profiler.internal._pywrap_traceme', 'tensorflow.python.profiler.trace', 'tensorflow.python.util.lock_util', 'tensorflow.python.util.traceback_utils', 'tensorflow.python.framework.ops', 'tensorflow.python.framework.constant_tensor_conversion', 'tensorflow.python.framework.constant_op', 'tensorflow.core.config', 'tensorflow.python.flags_pybind', 'tensorflow.core.config.flags', 'tensorflow.dtensor', 'tensorflow.dtensor.python', 'tensorflow.python.util._pywrap_determinism', 'tensorflow.python.util._pywrap_tensor_float_32_execution', 'tensorflow.python.framework.config', 'tensorflow.dtensor.python.config', 'tensorflow.dtensor.proto', 'tensorflow.dtensor.proto.layout_pb2', 'tensorflow.python._pywrap_dtensor_device', 'tensorflow.dtensor.python.layout', 'tensorflow.security', 'tensorflow.security.fuzzing', 'tensorflow.security.fuzzing.py', 'tensorflow.security.fuzzing.py.annotation_types', 'tensorflow.python.framework._op_def_registry', 'tensorflow.python.framework.op_def_registry', 'tensorflow.python.framework._op_def_library_pybind', 'tensorflow.python.framework.op_def_library_pybind', 'tensorflow.python.framework.op_def_library', 'tensorflow.python.framework._pywrap_python_api_dispatcher', 'tensorflow.python.util.type_annotations', 'tensorflow.python.util.dispatch', 'tensorflow.python.ops.gen_math_ops', 'tensorflow.python.ops.numpy_ops', 'tensorflow.python.ops.numpy_ops.np_dtypes', 'tensorflow.python.framework.override_binary_operator', 'tensorflow.python.framework.tensor_spec', 'tensorflow.python.ops.gen_array_ops', 'tensorflow.python.ops.array_ops_stack', 'tensorflow.python.ops.gen_sparse_ops', 'tensorflow.python.framework.sparse_tensor', 'tensorflow.dtensor.python.dtensor_device', 'tensorflow.dtensor.python.gen_dtensor_ops', 'tensorflow.dtensor.python.api', 'tensorflow.python.framework.composite_tensor_gradient', 'tensorflow.python.framework.indexed_slices', 'tensorflow.python.ops.shape_util', 'tensorflow.python.ops.tensor_getitem_override', 'tensorflow.python.ops.array_ops', 'tensorflow.python.ops.gen_control_flow_ops', 'tensorflow.python.ops.gen_data_flow_ops', 'tensorflow.python.ops.gen_list_ops', 'tensorflow.python.ops.list_ops', 'tensorflow.python.compat', 'tensorflow.python.compat.compat', 'tensorflow.python.ops.gen_bitwise_ops', 'tensorflow.python.ops.gen_logging_ops', 'tensorflow.python.ops.gen_nn_ops', 'tensorflow.python.ops.tensor_math_operator_overrides', 'tensorflow.python.ops.math_ops', 'tensorflow.python.util.tf_should_use', 'tensorflow.python.ops.tensor_array_ops', 'tensorflow.python.autograph.utils.context_managers', 'tensorflow.python.autograph.utils.misc', 'tensorflow.python.autograph.utils.tensor_list', 'tensorflow.python.autograph.utils', 'tensorflow.python.autograph.utils.ag_logging', 'tensorflow.python.autograph.core.ag_ctx', 'tensorflow.python.autograph.impl', 'tensorflow.python.autograph.utils.tensors', 'tensorflow.python.autograph.utils.type_registry', 'tensorflow.python.eager.polymorphic_function', 'tensorflow.python.eager.polymorphic_function.eager_function_run', 'tensorflow.python.eager.backprop_util', 'tensorflow.python.framework.auto_control_deps_utils', 'tensorflow.core.protobuf.control_flow_pb2', 'tensorflow.python.util.variable_utils', 'tensorflow.python.ops.control_flow_ops', 'tensorflow.python.framework.auto_control_deps', 'tensorflow.core.function.capture', 'tensorflow.core.function.capture.capture_container', 'tensorflow.python.eager.polymorphic_function.composite_tensor_utils', 'tensorflow.compiler', 'tensorflow.compiler.tf2xla', 'tensorflow.compiler.tf2xla.ops', 'tensorflow.compiler.tf2xla.ops.gen_xla_ops', 'tensorflow.core.framework.variable_pb2', 'tensorflow.python.checkpoint', 'tensorflow.python.training', 'tensorflow.python.training.saving', 'tensorflow.python.training.saving.saveable_object', 'tensorflow.python.checkpoint.tensor_callable', 'tensorflow.python.eager.tape', 'tensorflow.python.ops.gen_resource_variable_ops', 'tensorflow.python.ops.gen_state_ops', 'tensorflow.python.ops.state_grad', 'tensorflow.python.ops.state_ops', 'tensorflow.python.trackable', 'tensorflow.python.trackable.constants', 'tensorflow.python.trackable.base', 'tensorflow.python.ops.variables', 'tensorflow.python.ops.resource_variable_ops', 'tensorflow.python.framework.error_interpolation', 'tensorflow.python.ops.session_ops', 'tensorflow.python.training.experimental', 'tensorflow.python.training.experimental.mixed_precision_global_state', 'tensorflow.python.client.session', 'tensorflow.python.ops.gen_linalg_ops', 'tensorflow.python.ops.linalg_ops_impl', 'tensorflow.python.framework.random_seed', 'tensorflow.python.ops.gen_random_ops', 'tensorflow.python.ops.random_ops', 'tensorflow.python.ops.init_ops', 'tensorflow.python.ops.resource_variables_toggle', 'tensorflow.python.ops.variable_scope', 'tensorflow.python.saved_model.save_context', 'tensorflow.python.framework.func_graph', 'tensorflow.python.framework.none_tensor', 'tensorflow.core.function.polymorphism', 'tensorflow.core.function.polymorphism.function_type_pb2', 'tensorflow.core.function.polymorphism.function_type', 'tensorflow.python.eager.polymorphic_function.attributes', 'tensorflow.python.eager.polymorphic_function.function_type_utils', 'tensorflow.python.framework.graph_to_function_def', 'tensorflow.python.framework.function', 'tensorflow.python.framework.importer', 'tensorflow.python.framework.function_def_to_graph', 'tensorflow.python.eager.polymorphic_function.atomic_function', 'tensorflow.python.eager.forwardprop_util', 'tensorflow.python.eager.graph_only_ops', 'tensorflow.python.eager.polymorphic_function.saved_model_exported_concrete', 'tensorflow.python.ops.default_gradient', 'tensorflow.python.ops.control_flow_v2_func_graphs', 'tensorflow.python.ops.control_flow_state', 'tensorflow.python.ops.gen_functional_ops', 'tensorflow.python.ops.unconnected_gradients', 'tensorflow.python.ops.gradients_util', 'tensorflow.python.eager.polymorphic_function.concrete_function', 'tensorflow.core.function.polymorphism.type_dispatch', 'tensorflow.core.function.polymorphism.function_cache', 'tensorflow.python.eager.polymorphic_function.function_context', 'tensorflow.python.eager.polymorphic_function.transform', 'tensorflow.python.eager.polymorphic_function.tracing_compilation', 'tensorflow.python.util.keras_deps', 'tensorflow.python.ops.control_flow_util_v2', 'tensorflow.python.ops.gen_optional_ops', 'tensorflow.python.ops.cond_v2', 'tensorflow.python.ops.cond', 'tensorflow.python.ops.control_flow_assert', 'tensorflow.python.ops.gen_parsing_ops', 'tensorflow.python.ops.gen_string_ops', 'tensorflow.python.autograph.operators.py_builtins', 'tensorflow.python.autograph.operators.variables', 'tensorflow.python.framework.tensor_conversion', 'tensorflow.python.ops.while_v2_indexed_slices_rewriter', 'tensorflow.python.ops.while_v2', 'tensorflow.python.ops.while_loop', 'tensorflow.python.types.distribute', 'tensorflow.python.autograph.operators.control_flow', 'tensorflow.python.autograph.operators.conditional_expressions', 'tensorflow.python.autograph.operators.data_structures', 'tensorflow.python.autograph.operators.exceptions', 'tensorflow.python.autograph.operators.logical', 'tensorflow.python.autograph.operators.slices', 'tensorflow.python.autograph.operators', 'tensorflow.python.autograph.converters', 'gast.astn', 'gast.ast3', 'gast.gast', 'gast.version', 'gast', 'tensorflow.python.autograph.pyct', 'tensorflow.python.autograph.pyct.anno', 'tensorflow.python.autograph.pyct.errors', 'tensorflow.python.autograph.pyct.inspect_utils', 'tensorflow.python.autograph.pyct.parser', 'tensorflow.python.autograph.pyct.qual_names', 'tensorflow.python.autograph.pyct.ast_util', 'tensorflow.python.autograph.pyct.templates', 'termcolor._types', 'termcolor.termcolor', 'termcolor', 'tensorflow.python.autograph.pyct.pretty_printer', 'tensorflow.python.autograph.pyct.transformer', 'tensorflow.python.autograph.core.converter', 'tensorflow.python.autograph.converters.asserts', 'tensorflow.python.autograph.pyct.static_analysis', 'tensorflow.python.autograph.pyct.static_analysis.annos', 'tensorflow.python.autograph.pyct.static_analysis.activity', 'tensorflow.python.autograph.converters.break_statements', 'tensorflow.python.autograph.converters.call_trees', 'tensorflow.python.autograph.converters.conditional_expressions', 'tensorflow.python.autograph.converters.continue_statements', 'tensorflow.python.autograph.lang', 'tensorflow.python.autograph.lang.directives', 'tensorflow.python.autograph.pyct.cfg', 'tensorflow.python.autograph.pyct.origin_info', 'tensorflow.python.autograph.pyct.static_analysis.liveness', 'tensorflow.python.autograph.pyct.static_analysis.reaching_definitions', 'tensorflow.python.autograph.pyct.static_analysis.reaching_fndefs', 'tensorflow.python.autograph.converters.control_flow', 'tensorflow.python.autograph.converters.directives', 'tensorflow.python.autograph.converters.functions', 'tensorflow.python.autograph.converters.lists', 'tensorflow.python.autograph.converters.logical_expressions', 'tensorflow.python.autograph.converters.return_statements', 'tensorflow.python.autograph.converters.slices', 'tensorflow.python.autograph.converters.variables', 'tensorflow.python.autograph.core.function_wrappers', 'tensorflow.python.autograph.core.unsupported_features_checker', 'tensorflow.python.autograph.core.config_lib', 'tensorflow.python.autograph.core.config', 'tensorflow.python.autograph.pyct.cache', 'tensorflow.python.eager.polymorphic_function.tf_method_target', 'tensorflow.python.autograph.impl.conversion', 'tensorflow.python.autograph.lang.special_functions', 'tensorflow.python.autograph.pyct.error_utils', 'tensorflow.python.autograph.pyct.loader', 'tensorflow.python.autograph.pyct.naming', 'tensorflow.python.autograph.pyct.transpiler', 'tensorflow.python.autograph.impl.api', 'tensorflow._api.v2.__internal__.autograph', 'tensorflow.python.util.tf_decorator_export', 'tensorflow._api.v2.__internal__.decorator', 'tensorflow._api.v2.__internal__.dispatch', 'tensorflow.python.distribute', 'tensorflow.core.protobuf.device_filters_pb2', 'tensorflow.core.protobuf.tensorflow_server_pb2', 'tensorflow.python.distribute.collective_util', 'multiprocessing.dummy.connection', 'multiprocessing.dummy', 'multiprocessing.pool', 'tensorflow.core.framework.device_attributes_pb2', 'tensorflow.python.client._pywrap_device_lib', 'tensorflow.python.client.device_lib', 'tensorflow.python.distribute.device_util', 'tensorflow.python.data.experimental.ops', 'tensorflow.core.protobuf.data_service_pb2', 'tensorflow.python.data.util', 'tensorflow.python.data.util.nest', 'tensorflow.python.ops.check_ops', 'tensorflow.python.ops.gen_ragged_conversion_ops', 'tensorflow.python.ops.ragged.ragged_config', 'tensorflow.python.ops.gen_ragged_math_ops', 'tensorflow.python.ops.ragged.ragged_util', 'tensorflow.python.ops.ragged.segment_id_ops', 'tensorflow.python.ops.ragged.row_partition', 'tensorflow.python.ops.ragged.ragged_tensor_value', 'tensorflow.python.lib', 'tensorflow.python.lib.io', 'tensorflow.python.lib.io._pywrap_record_io', 'tensorflow.python.lib.io.tf_record', 'tensorflow.python.lib.io.python_io', 'tensorflow.python.ops.data_flow_ops', 'tensorflow.python.ops.gen_ragged_array_ops', 'tensorflow.python.framework._proto_comparators', 'tensorflow.python.framework.graph_util_impl', 'tensorflow.python.framework.graph_util', 'tensorflow.python.ops.nn_grad', 'tensorflow.python.ops.gen_random_index_shuffle_ops', 'tensorflow.python.ops.gen_stateless_random_ops', 'tensorflow.python.ops.gen_stateless_random_ops_v2', 'tensorflow.python.ops.bitwise_ops', 'tensorflow.python.ops.random_ops_util', 'tensorflow.python.ops.stateless_random_ops', 'tensorflow.python.platform.device_context', 'tensorflow.python.ops.nn_ops', 'tensorflow.python.ops.sort_ops', 'tensorflow.python.framework.immutable_dict', 'tensorflow.python.framework.extension_type_field', 'tensorflow.core.protobuf.composite_tensor_variant_pb2', 'tensorflow.python.ops.gen_composite_tensor_ops', 'tensorflow.python.ops.composite_tensor_ops', 'tensorflow.python.framework.extension_type', 'tensorflow.python.ops.ragged.dynamic_ragged_shape', 'tensorflow.python.ops.ragged.ragged_functional_ops', 'tensorflow.python.ops.map_fn', 'tensorflow.python.ops.ragged.ragged_math_ops', 'tensorflow.python.ops.ragged.ragged_array_ops', 'tensorflow.python.ops.ragged.ragged_autograph', 'tensorflow.python.ops.ragged.ragged_gather_ops', 'tensorflow.python.ops.ragged.ragged_batch_gather_ops', 'tensorflow.python.ops.string_ops', 'tensorflow.python.ops.logging_ops', 'tensorflow.python.ops.ragged.ragged_tensor_shape', 'tensorflow.python.ops.ragged.ragged_dispatch', 'tensorflow.python.ops.ragged.ragged_getitem', 'tensorflow.python.ops.ragged.ragged_operators', 'tensorflow.python.ops.ragged.ragged_concat_ops', 'tensorflow.python.ops.ragged.ragged_where_op', 'tensorflow.python.ops.ragged.ragged_batch_gather_with_default_op', 'tensorflow.python.ops.bincount_ops', 'tensorflow.python.ops.gen_count_ops', 'opt_einsum.typing', 'opt_einsum.blas', 'opt_einsum.helpers', '_decimal', 'decimal', 'opt_einsum.paths', 'opt_einsum.path_random', 'opt_einsum._version', 'opt_einsum.parser', 'opt_einsum.sharing', 'opt_einsum.backends.cupy', 'opt_einsum.backends.jax', 'opt_einsum.backends.object_arrays', 'opt_einsum.backends.tensorflow', 'opt_einsum.backends.theano', 'opt_einsum.backends.torch', 'opt_einsum.backends.dispatch', 'opt_einsum.backends', 'opt_einsum.contract', 'opt_einsum', 'tensorflow.python.ops.gen_special_math_ops', 'tensorflow.python.ops.special_math_ops', 'tensorflow.python.ops.sparse_ops', 'tensorflow.python.ops.ragged.ragged_bincount_ops', 'tensorflow.python.ops.ragged.ragged_check_ops', 'tensorflow.python.ops.ragged.ragged_conversion_ops', 'tensorflow.python.ops.clip_ops', 'tensorflow.python.ops.data_flow_grad', 'tensorflow.python.ops.embedding_ops', 'tensorflow.python.ops.ragged.ragged_embedding_ops', 'tensorflow.python.ops.ragged.ragged_factory_ops', 'tensorflow.python.ops.gen_image_ops', 'tensorflow.python.ops.linalg_ops', 'tensorflow.python.distribute.parallel_device', 'tensorflow.python._pywrap_parallel_device', 'tensorflow.python.tpu', 'tensorflow.python.tpu.ops', 'tensorflow.python.ops.gen_tpu_ops', 'tensorflow.python.tpu.tpu_function', 'tensorflow.python.tpu.ops.tpu_ops', 'tensorflow.python.distribute.parallel_device.parallel_device', 'tensorflow.python.ops.op_selector', 'tensorflow.python.eager.lift_to_graph', 'tensorflow.python.eager.polymorphic_function.autograph_util', 'tensorflow.python.eager.polymorphic_function.compiler_ir', 'tensorflow.python.eager.polymorphic_function.polymorphic_function', 'tensorflow.python.eager.def_function', 'tensorflow.python.ops.control_flow_case', 'tensorflow.python.ops.gen_candidate_sampling_ops', 'tensorflow.python.ops.candidate_sampling_ops', 'tensorflow.python.eager.imperative_grad', 'tensorflow.compiler.jit', 'tensorflow.compiler.jit.ops', 'tensorflow.compiler.jit.ops.xla_ops_grad', 'tensorflow.python.ops.array_grad', 'tensorflow.python.ops.control_flow_grad', 'tensorflow.python.ops.gen_cudnn_rnn_ops', 'tensorflow.python.ops.cudnn_rnn_grad', 'tensorflow.python.ops.image_grad', 'tensorflow.python.ops.gen_io_ops', 'tensorflow.python.ops.io_ops', 'tensorflow.python.ops.linalg', 'tensorflow.python.ops.linalg.linalg_impl', 'tensorflow.python.ops.linalg_grad', 'tensorflow.python.ops.lookup_grad', 'tensorflow.python.ops.gen_manip_ops', 'tensorflow.python.ops.manip_ops', 'tensorflow.python.ops.manip_grad', 'tensorflow.python.ops.math_grad', 'tensorflow.python.ops.gen_nccl_ops', 'tensorflow.python.ops.nccl_ops', 'tensorflow.python.ops.optional_grad', 'tensorflow.python.ops.parsing_grad', 'tensorflow.python.ops.gen_decode_proto_ops', 'tensorflow.python.ops.gen_encode_proto_ops', 'tensorflow.python.ops.proto_ops', 'tensorflow.python.ops.random_grad', 'tensorflow.python.ops.gen_rnn_ops', 'tensorflow.python.ops.rnn_grad', 'tensorflow.python.ops.gen_sdca_ops', 'tensorflow.python.ops.sdca_ops', 'tensorflow.python.ops.gen_set_ops', 'tensorflow.python.ops.sets_impl', 'tensorflow.python.ops.sets', 'tensorflow.python.ops.sparse_grad', 'tensorflow.python.ops.tensor_array_grad', 'tensorflow.python.ops.linalg.sparse', 'tensorflow.python.ops.linalg.sparse.gen_sparse_csr_matrix_ops', 'tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops', 'tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_grad', 'tensorflow.python.ops.signal', 'tensorflow.python.ops.gen_spectral_ops', 'tensorflow.python.ops.signal.fft_ops', 'tensorflow.python.ops.gen_checkpoint_ops', 'tensorflow.python.training.checkpoint_ops', 'tensorflow.python.ops.gradients_impl', 'tensorflow.python.ops.parallel_for', 'tensorflow.compiler.tf2xla.python', 'tensorflow.compiler.xla', 'tensorflow.compiler.xla.xla_data_pb2', 'tensorflow.python.framework.weak_tensor', 'tensorflow.python.framework.flexible_dtypes', 'tensorflow.python.ops.numpy_ops.np_arrays', 'tensorflow.python.ops.numpy_ops.np_utils', 'tensorflow.compiler.tf2xla.python.xla', 'tensorflow.python.framework.smart_cond', 'tensorflow.python.ops.control_flow_switch_case', 'tensorflow.python.platform.flags', 'tensorflow.python.ops.parallel_for.pfor', 'tensorflow.python.ops.parallel_for.control_flow_ops', 'tensorflow.python.eager.backprop', 'tensorflow.python.ops.custom_gradient', 'tensorflow.python.ops.functional_ops', 'tensorflow.python.ops.gen_ctc_ops', 'tensorflow.python.ops.inplace_ops', 'tensorflow.python.ops.ctc_ops', 'tensorflow.python.ops.nn_fused_batch_norm_grad', 'tensorflow.python.ops.nn_impl', 'tensorflow.python.ops.variable_v1', 'tensorflow.python.ops.ref_variable', 'tensorflow.python.ops.image_ops_impl', 'tensorflow.python.ops.image_ops', 'tensorflow.python.ops.ragged.ragged_image_ops', 'tensorflow.python.ops.ragged.ragged_map_ops', 'tensorflow.python.ops.ragged.ragged_squeeze_op', 'tensorflow.python.ops.ragged.ragged_string_ops', 'tensorflow.python.ops.ragged.ragged_ops', 'tensorflow.python.ops.ragged.ragged_tensor', 'tensorflow.python.ops.ragged', 'tensorflow.python.data.util.structure', 'tensorflow.python.ops.gen_experimental_dataset_ops', 'tensorflow.python.data.experimental.ops.compression_ops', 'tensorflow.python.data.experimental.service._pywrap_server_lib', 'tensorflow.python.data.experimental.service._pywrap_utils_exp', 'tensorflow.python.data.ops', 'tensorflow.core.framework.dataset_metadata_pb2', 'tensorflow.core.framework.model_pb2', 'tensorflow.core.framework.dataset_options_pb2', 'tensorflow.python.ops.control_flow_v2_toggles', 'tensorflow.python.compat.v2_compat', 'tensorflow.python.data.experimental.ops.take_while_ops', 'tensorflow.python.data.ops.dataset_autograph', 'tensorflow.python.data.ops.debug_mode', 'tensorflow.python.checkpoint.saveable_compat', 'tensorflow.python.data.ops.iterator_autograph', 'tensorflow.python.data.ops.optional_ops', 'tensorflow.python.data.ops.test_mode', 'tensorflow.python.data.util.options', 'tensorflow.python.data.ops.options', 'tensorflow.python.ops.structured', 'tensorflow.python.ops.structured.structured_tensor', 'tensorflow.python.framework.type_utils', 'tensorflow.python.ops.gen_dataset_ops', 'tensorflow.python.ops.parsing_config', 'tensorflow.python.ops.parsing_ops', 'tensorflow.core.protobuf.trackable_object_graph_pb2', 'tensorflow.core.protobuf.saved_object_graph_pb2', 'tensorflow.core.protobuf.saver_pb2', 'tensorflow.core.protobuf.meta_graph_pb2', 'tensorflow.python.checkpoint.sharding', 'tensorflow.python.checkpoint.sharding.sharding_util', 'tensorflow.python.checkpoint.checkpoint_options', 'tensorflow.python.lib.io._pywrap_file_io', 'tensorflow.python.lib.io.file_io', 'tensorflow.python.framework.byte_swap_tensor', 'tensorflow.python.framework.graph_io', 'tensorflow.python.training.training_util', 'tensorflow.python.training.checkpoint_state_pb2', 'tensorflow.python.checkpoint.checkpoint_management', 'tensorflow.python.framework.meta_graph', 'tensorflow.python.platform.gfile', 'tensorflow.python.saved_model.pywrap_saved_model.constants', 'tensorflow.python.saved_model.pywrap_saved_model.metrics', 'tensorflow.python.saved_model.pywrap_saved_model.fingerprinting', 'tensorflow.python.saved_model.pywrap_saved_model', 'tensorflow.python.util._pywrap_checkpoint_reader', 'tensorflow.python.training.py_checkpoint_reader', 'tensorflow.python.trackable.base_delegate', 'tensorflow.python.trackable.python_state', 'tensorflow.python.trackable.trackable_utils', 'tensorflow.python.training.saving.saveable_object_util', 'tensorflow.python.training.saver', 'tensorflow.python.data.ops.iterator_ops', 'tensorflow.python.lib.core', 'tensorflow.python.lib.core._pywrap_py_func', 'tensorflow.python.ops.autograph_ops', 'tensorflow.python.ops.gen_script_ops', 'tensorflow.python.ops.script_ops', 'tensorflow.python.data.ops.structured_function', 'tensorflow.python.data.util.traverse', 'tensorflow.python.eager.function', 'tensorflow.python.trackable.layer_utils', 'tensorflow.python.trackable.data_structures', 'tensorflow.python.eager.wrap_function', 'tensorflow.python.saved_model.constants', 'tensorflow.python.saved_model.path_helpers', 'tensorflow.python.trackable.asset', 'tensorflow.python.trackable.resource', 'tensorflow.python.types.data', 'tensorflow.python.data.ops.batch_op', 'tensorflow.python.data.ops.prefetch_op', 'tensorflow.python.data.util.random_seed', 'tensorflow.python.data.ops.shuffle_op', 'tensorflow.python.data.ops.repeat_op', 'tensorflow.python.data.ops.dataset_ops', 'tensorflow.python.data.experimental.ops.data_service_ops', 'tensorflow.core.protobuf.service_config_pb2', 'tensorflow.python.data.experimental.service.server_lib', 'tensorflow.python.data.experimental.service', 'tensorflow.python.data.util.convert', 'tensorflow.python.data.experimental.ops.batching', 'tensorflow.python.data.experimental.ops.cardinality', 'tensorflow.python.data.experimental.ops.counter', 'tensorflow.python.data.experimental.ops.distribute', 'tensorflow.core.protobuf.snapshot_pb2', 'tensorflow.python.data.experimental.ops.distributed_save_op', 'tensorflow.python.data.experimental.ops.enumerate_ops', 'tensorflow.python.data.experimental.ops.error_ops', 'tensorflow.python.data.experimental.ops.from_list', 'tensorflow.python.data.experimental.ops.get_single_element', 'tensorflow.python.data.experimental.ops.grouping', 'tensorflow.python.data.ops.from_tensor_slices_op', 'tensorflow.python.data.ops.readers', 'tensorflow.python.data.experimental.ops.interleave_ops', 'tensorflow.python.data.experimental.ops.io', 'tensorflow.python.data.experimental.ops.iterator_ops', 'tensorflow.python.ops.gen_lookup_ops', 'tensorflow.python.saved_model.registration.registration', 'tensorflow.python.saved_model.registration', 'tensorflow.python.ops.lookup_ops', 'tensorflow.python.data.experimental.ops.lookup_ops', 'tensorflow.python.data.experimental.ops.pad_to_cardinality', 'tensorflow.python.data.experimental.ops.parsing_ops', 'tensorflow.python.data.experimental.ops.prefetching_ops', 'tensorflow.python.data.experimental.ops.random_access', 'tensorflow.python.data.ops.random_op', 'tensorflow.python.data.experimental.ops.random_ops', 'tensorflow.python.data.ops.map_op', 'tensorflow.python.data.experimental.ops.readers', 'tensorflow.python.data.experimental.ops.resampling', 'tensorflow.python.data.experimental.ops.scan_ops', 'tensorflow.python.data.experimental.ops.shuffle_ops', 'tensorflow.python.data.experimental.ops.snapshot', 'tensorflow.python.data.experimental.ops.unique', 'tensorflow.python.data.experimental.ops.writers', 'tensorflow.python.data.experimental', 'tensorflow.python.data', 'tensorflow.python.distribute.numpy_dataset', 'tensorflow.python.distribute.reduce_util', 'tensorflow.python.ops.gen_summary_ops', 'tensorflow.python.ops.summary_op_util', 'tensorflow.python.profiler.internal._pywrap_profiler', 'tensorflow.python.profiler.profiler_v2', 'tensorflow.python.ops.summary_ops_v2', 'tensorflow.python.distribute.distribute_lib', 'tensorflow.python.distribute.packed_distributed_variable', 'tensorflow.python.saved_model.save_options', 'tensorflow.python.distribute.values_util', 'tensorflow.python.distribute.values', 'tensorflow.python.ops.gen_collective_ops', 'tensorflow.python.ops.collective_ops', 'tensorflow.python.distribute.cross_device_utils', 'tensorflow.python.compiler', 'tensorflow.python.compiler.xla.jit', 'tensorflow.compiler.jit.ops.xla_ops', 'tensorflow.python.distribute.summary_op_util', 'tensorflow.python.compiler.xla.xla', 'tensorflow.python.compiler.xla', 'tensorflow.python.compiler.xla.experimental', 'tensorflow.python.compiler.xla.experimental.xla_sharding', 'tensorflow.core.protobuf.tpu', 'tensorflow.core.protobuf.tpu.topology_pb2', 'tensorflow.python.tpu.topology', 'tensorflow.python.tpu.device_assignment', 'tensorflow.python.tpu.tpu_replication', 'tensorflow.python.distribute.tpu_util', 'tensorflow.python.ops.gen_tpu_partition_ops', 'tensorflow.python.distribute.tpu_replicated_variable', 'tensorflow.python.distribute.tpu_values', 'tensorflow.python.ops.losses', 'tensorflow.python.ops.confusion_matrix', 'tensorflow.python.ops.losses.util', 'tensorflow.python.ops.nn_impl_distribute', 'tensorflow.python.ops.nn', 'tensorflow.python.ops.weights_broadcast_ops', 'tensorflow.python.ops.losses.losses_impl', 'tensorflow.python.distribute.distribute_utils', 'tensorflow.python.distribute.coordinator', 'tensorflow.python.distribute.coordinator.remote_value', 'tensorflow.python.distribute.coordinator.coordinator_context', 'tensorflow.python.distribute.ps_values', 'tensorflow.core.framework.kernel_def_pb2', 'tensorflow.python.framework.kernels', 'tensorflow.python.distribute.cross_device_ops', 'tensorflow.python.data.ops.multi_device_iterator_ops', 'tensorflow.python.distribute.input_ops', 'tensorflow.python.distribute.input_lib', 'tensorflow.python.distribute.v1', 'tensorflow.python.distribute.v1.input_lib', 'tensorflow.python.distribute.input_util', 'tensorflow.python.distribute.shared_variable_creator', 'tensorflow.python.training.coordinator', 'tensorflow.python.distribute.mirrored_run', 'tensorflow.python.distribute.distribute_coordinator_context', 'tensorflow.python.training.server_lib', 'tensorflow.python.distribute.multi_worker_util', 'tensorflow.python.distribute.cluster_resolver.cluster_resolver', 'googleapiclient', 'email.generator', 'email.mime', 'email.contentmanager', 'email.policy', 'email.mime.base', 'email.mime.multipart', 'email.mime.nonmultipart', 'mimetypes', 'google.api_core.version', 'google.api_core', 'google.api_core.client_options', 'google.auth.version', 'google.auth.environment_vars', 'google.auth.exceptions', 'google.auth.transport', 'google.auth.transport._http_client', 'google.auth._default', 'google.auth', 'google.auth.transport._mtls_helper', 'google.auth.transport.mtls', 'google.oauth2', 'google.auth._helpers', 'google.auth.crypt.base', 'cryptography.__about__', 'cryptography', 'cryptography.hazmat', 'cryptography.hazmat.bindings', '_cffi_backend', '_openssl.lib', '_openssl', 'cryptography.hazmat.bindings._rust', 'cryptography.exceptions', 'cryptography.hazmat.backends', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.utils', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.decrepit', 'cryptography.hazmat.decrepit.ciphers', 'cryptography.hazmat.decrepit.ciphers.algorithms', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.serialization', 'cryptography.x509.certificate_transparency', 'ipaddress', 'cryptography.x509.oid', 'cryptography.x509.name', 'cryptography.x509.general_name', 'cryptography.x509.verification', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.extensions', 'cryptography.x509.base', 'cryptography.x509', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl', 'google.auth.crypt._cryptography_rsa', 'google.auth.crypt.rsa', 'google.auth.crypt.es256', 'google.auth.crypt', 'google.auth._service_account_info', 'google.auth.metrics', 'google.auth._refresh_worker', 'google.auth.credentials', 'cachetools.keys', 'cachetools', 'google.auth.jwt', 'google.auth._exponential_backoff', 'google.oauth2._client', 'google.oauth2.service_account', 'socks', 'httplib2.error', 'httplib2.auth', 'httplib2.iri2uri', 'certifi.core', 'certifi', 'httplib2.certs', 'httplib2', 'uritemplate.variable', 'uritemplate.orderedset', 'uritemplate.template', 'uritemplate.api', 'uritemplate', 'google_auth_httplib2', 'google.api_core.universe', 'oauth2client', 'six.moves.urllib', 'oauth2client._helpers', 'oauth2client._pkce', 'oauth2client.clientsecrets', 'oauth2client.transport', 'pyasn1', 'pyasn1.codec', 'pyasn1.codec.der', 'pyasn1.codec.cer', 'pyasn1.error', 'pyasn1.type', 'pyasn1.codec.ber', 'pyasn1.type.error', 'pyasn1.type.constraint', 'pyasn1.type.tag', 'pyasn1.type.tagmap', 'pyasn1.type.base', 'pyasn1.codec.ber.eoo', 'pyasn1.compat', 'pyasn1.compat.integer', 'pyasn1.type.namedtype', 'pyasn1.type.namedval', 'pyasn1.type.univ', 'pyasn1.codec.streaming', 'pyasn1.debug', 'pyasn1.type.char', 'pyasn1.type.useful', 'pyasn1.codec.ber.decoder', 'pyasn1.codec.cer.decoder', 'pyasn1.codec.der.decoder', 'pyasn1_modules', 'pyasn1_modules.pem', 'pyasn1.type.opentype', 'pyasn1_modules.rfc2459', 'pyasn1_modules.rfc2251', 'pyasn1_modules.rfc5208', 'rsa.common', 'rsa.transform', 'rsa.randnum', 'rsa.prime', 'rsa.pem', 'rsa.core', 'rsa.key', 'rsa.pkcs1', 'rsa', 'oauth2client._pure_python_crypt', 'OpenSSL._util', 'OpenSSL.crypto', 'OpenSSL.SSL', 'OpenSSL.version', 'OpenSSL', 'oauth2client._openssl_crypt', 'oauth2client.crypt', 'oauth2client.client', 'googleapiclient._auth', 'googleapiclient.mimeparse', 'googleapiclient._helpers', 'googleapiclient.errors', 'googleapiclient.version', 'google.api_core.version_header', 'googleapiclient.model', 'googleapiclient.http', 'googleapiclient.schema', 'googleapiclient.discovery', 'tensorflow.python.distribute.cluster_resolver.gce_cluster_resolver', 'tensorflow.python.distribute.cluster_resolver.kubernetes_cluster_resolver', 'tensorflow.python.distribute.cluster_resolver.slurm_cluster_resolver', 'tensorflow.python.distribute.cluster_resolver.tfconfig_cluster_resolver', 'tensorflow.python.distribute.cluster_resolver.tpu', 'tensorflow.python.platform.remote_utils', 'tensorflow.python.eager.remote', 'tensorflow.core.protobuf.tpu.dynamic_padding_pb2', 'tensorflow.compiler.xla.service', 'tensorflow.compiler.xla.service.hlo_pb2', 'tensorflow.core.protobuf.tpu.optimization_parameters_pb2', 'tensorflow.core.protobuf.tpu.tpu_embedding_configuration_pb2', 'tensorflow.python.platform.analytics', 'tensorflow.python.summary', 'tensorflow.core.util', 'tensorflow.core.util.event_pb2', 'tensorflow.python.summary.summary_iterator', 'tensorflow.python.tpu.tensor_tracer_flags', 'tensorflow.python.tpu.tensor_tracer_pb2', 'tensorflow.python.tpu.tensor_tracer_report', 'tensorflow.python.tpu.tensor_tracer', 'tensorflow.python.tpu.tpu_name_util', 'tensorflow.python.tpu.tpu_sharding', 'tensorflow.python.tpu.tpu_feed', 'tensorflow.python.tpu.tpu', 'tensorflow.python.tpu.tpu_strategy_util', 'tensorflow.python.tpu.tpu_system_metadata', 'tensorflow.python.tpu.client', 'tensorflow.python.tpu.client.client', 'tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver', 'tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver', 'tensorflow.python.distribute.cluster_resolver', 'tensorflow.python.distribute.mirrored_strategy', 'tensorflow.python.distribute.collective_all_reduce_strategy', 'absl.testing', 'shlex', 'absl.testing._pretty_print_reporter', 'xml.sax.handler', 'xml.sax._exceptions', 'xml.sax.xmlreader', 'xml.sax', 'xml.sax.saxutils', 'absl.testing.xml_reporter', 'absl.testing.absltest', 'absl.testing.parameterized', 'tensorflow.python._pywrap_sanitizers', 'tensorflow.python.pywrap_sanitizers', 'tensorflow.python.framework._test_metrics_util', 'tensorflow.python.framework.gpu_util', 'tensorflow.python.ops.gen_sync_ops', 'tensorflow.python.platform._pywrap_stacktrace_handler', 'tensorflow.tsl.protobuf.test_log_pb2', 'tensorflow.core.util.test_log_pb2', 'tensorflow.python.client.timeline', 'tensorflow.python.platform.benchmark', 'tensorflow.python.platform.googletest', 'tensorflow.python.util._pywrap_util_port', 'tensorflow.python.util.protobuf', 'tensorflow.python.util.protobuf.compare', 'tensorflow.python.framework.test_util', 'tensorflow.python.eager.forwardprop', 'tensorflow.python.ops.gradients', 'tensorflow.python.ops.gradient_checker', 'tensorflow.python.platform.test', 'tensorflow.python.eager.test', 'tensorflow.python.distribute.multi_process_lib', 'tensorflow.python.distribute.multi_process_runner', 'tensorflow.python.checkpoint.checkpoint_context', 'tensorflow.python.eager.polymorphic_function.saved_model_utils', 'tensorflow.python.trackable.converter', 'tensorflow.python.checkpoint.trackable_view', 'tensorflow.python.checkpoint.async_checkpoint_helper', 'tensorflow.python.checkpoint.sharding.sharding_policies', 'tensorflow.python.checkpoint.functional_saver', 'tensorflow.python.checkpoint.util', 'tensorflow.python.checkpoint.save_util_v1', 'tensorflow.python.checkpoint.graph_view', 'tensorflow.python.checkpoint.checkpoint_adapter', 'tensorflow.python.checkpoint.checkpoint_view', 'tensorflow.python.checkpoint.restore', 'tensorflow.python.checkpoint.save_util', 'tensorflow.python.trackable.autotrackable', 'tensorflow.python.checkpoint.checkpoint', 'tensorflow.python.ops.resources', 'google.protobuf.json_format', 'tensorflow.python.summary.tb_summary', 'tensorflow.python.summary.writer', 'tensorflow.python.summary.plugin_asset', 'tensorflow.python.client._pywrap_events_writer', 'tensorflow.python.summary.writer.event_file_writer', 'tensorflow.python.summary.writer.event_file_writer_v2', 'tensorflow.python.summary.writer.writer', 'tensorflow.python.summary.writer.writer_cache', 'tensorflow.python.summary.summary', 'tensorflow.python.training.session_run_hook', 'tensorflow.python.training.summary_io', 'tensorflow.python.training.basic_session_run_hooks', 'tensorflow.core.protobuf.error_codes_pb2', 'tensorflow.core.protobuf.queue_runner_pb2', 'tensorflow.python.training.queue_runner_impl', 'tensorflow.python.training.queue_runner', 'tensorflow.python.training.session_manager', 'tensorflow.python.training.monitored_session', 'tensorflow.python.distribute.distribute_coordinator', 'tensorflow.python.distribute.multi_worker_test_base', 'tensorflow.python.framework.test_combinations', 'tensorflow.python.framework.combinations', 'tensorflow.python.distribute.combinations', 'tensorflow.python.training.device_setter', 'tensorflow.python.distribute.parameter_server_strategy', 'tensorflow.python.distribute.central_storage_strategy', 'tensorflow.python.distribute.one_device_strategy', 'tensorflow.python.distribute.load_context', 'tensorflow.python.ops.partitioned_variables', 'tensorflow.python.distribute.sharded_variable', 'tensorflow.python.distribute.coordinator.metric_utils', 'tensorflow.python.distribute.coordinator.utils', 'tensorflow.python.distribute.coordinator.values', 'tensorflow.python.distribute.coordinator.watchdog', 'tensorflow.python.distribute.coordinator.cluster_coordinator', 'tensorflow.python.distribute.parameter_server_strategy_v2', 'tensorflow.python.tpu.tpu_hardware_feature', 'tensorflow.python.tpu.training_loop', 'tensorflow.python.distribute.tpu_strategy', 'tensorflow.python.distribute.test_util', 'tensorflow.python.distribute.strategy_combinations', 'tensorflow._api.v2.__internal__.distribute.combinations', 'tensorflow.python.distribute.merge_call_interim', 'tensorflow._api.v2.__internal__.distribute.interim', 'tensorflow._api.v2.__internal__.distribute.multi_process_runner', 'tensorflow._api.v2.__internal__.distribute', 'tensorflow._api.v2.__internal__.eager_context', 'tensorflow.python.feature_column', 'tensorflow.python.feature_column.utils', 'tensorflow.python.layers', 'tensorflow.python.keras.distribute', 'tensorflow.python.keras.backend_config', 'tensorflow.python.keras.distribute.distribute_coordinator_utils', 'tensorflow.python.keras.engine', 'tensorflow.python.keras.utils', 'tensorflow.python.keras.utils.object_identity', 'tensorflow.python.keras.engine.keras_tensor', 'tensorflow.python.keras.utils.control_flow_util', 'tensorflow.python.keras.utils.tf_contextlib', 'tensorflow.python.keras.utils.tf_inspect', 'tensorflow.python.training.slot_creator', 'tensorflow.python.training.moving_averages', 'tensorflow.python.keras.backend', 'tensorflow.python.keras.distribute.distributed_training_utils', 'tensorflow.python.keras.utils.generic_utils', 'tensorflow.python.keras.constraints', 'tensorflow.python.keras.initializers.initializers_v1', 'tensorflow.python.keras.initializers.initializers_v2', 'tensorflow.python.keras.initializers', 'tensorflow.python.keras.regularizers', 'tensorflow.python.keras.utils.tf_utils', 'tensorflow.python.keras.engine.base_layer_utils', 'tensorflow.python.keras.engine.input_spec', 'tensorflow.python.keras.saving', 'tensorflow.python.keras.saving.saved_model', 'tensorflow.python.keras.saving.saved_model.json_utils', 'tensorflow.python.keras.engine.node', 'tensorflow.python.keras.mixed_precision', 'tensorflow.python.keras.mixed_precision.autocast_variable', 'tensorflow.python.keras.optimizer_v1', 'tensorflow.python.keras.optimizer_v2', 'tensorflow.python.keras.optimizer_v2.learning_rate_schedule', 'tensorflow.python.keras.optimizer_v2.utils', 'tensorflow.python.keras.utils.layer_utils', 'tensorflow.python.saved_model.revived_types', 'tensorflow.python.keras.optimizer_v2.optimizer_v2', 'tensorflow.python.ops.gen_training_ops', 'tensorflow.python.keras.optimizer_v2.adadelta', 'tensorflow.python.keras.optimizer_v2.adagrad', 'tensorflow.python.keras.optimizer_v2.adam', 'tensorflow.python.keras.optimizer_v2.adamax', 'tensorflow.python.keras.optimizer_v2.ftrl', 'tensorflow.python.keras.optimizer_v2.gradient_descent', 'tensorflow.python.keras.optimizer_v2.nadam', 'tensorflow.python.keras.optimizer_v2.rmsprop', 'tensorflow.python.training.optimizer', 'tensorflow.python.keras.optimizers', 'tensorflow.python.training.experimental.loss_scale', 'tensorflow.python.keras.mixed_precision.loss_scale', 'tensorflow.python.training.experimental.loss_scale_optimizer', 'tensorflow.python.training.experimental.mixed_precision', 'tensorflow.python.keras.mixed_precision.loss_scale_optimizer', 'tensorflow.python.keras.mixed_precision.device_compatibility_check', 'tensorflow.python.keras.mixed_precision.policy', 'tensorflow.python.keras.saving.saved_model.utils', 'tensorflow.python.keras.saving.saved_model.base_serialization', 'tensorflow.python.keras.saving.saved_model.constants', 'tensorflow.python.keras.utils.losses_utils', 'tensorflow.python.keras.losses', 'tensorflow.python.keras.utils.version_utils', 'tensorflow.python.keras.utils.io_utils', 'tensorflow.python.keras.saving.saving_utils', 'tensorflow.python.keras.protobuf', 'tensorflow.python.keras.protobuf.versions_pb2', 'tensorflow.python.keras.protobuf.saved_metadata_pb2', 'tensorflow.python.keras.saving.saved_model.serialized_attributes', 'tensorflow.python.keras.utils.metrics_utils', 'tensorflow.core.function.capture.restore_captures', 'tensorflow.core.protobuf.fingerprint_pb2', 'tensorflow.python.saved_model.fingerprinting', 'tensorflow.python.saved_model.fingerprinting_utils', 'tensorflow.python.saved_model.function_deserialization', 'tensorflow.python.saved_model.load_options', 'tensorflow.core.protobuf.saved_model_pb2', 'tensorflow.python.saved_model.signature_constants', 'tensorflow.python.saved_model.utils_impl', 'tensorflow.python.saved_model.signature_def_utils_impl', 'tensorflow.python.saved_model.signature_def_utils', 'tensorflow.python.saved_model.loader_impl', 'tensorflow.python.saved_model.function_serialization', 'tensorflow.python.saved_model.signature_serialization', 'tensorflow.python.saved_model.load_v1_in_v2', 'tensorflow.python.saved_model.load', 'tensorflow.python.keras.saving.saved_model.load', 'tensorflow.python.keras.saving.saved_model.save_impl', 'tensorflow.python.keras.saving.saved_model.layer_serialization', 'tensorflow.python.module', 'tensorflow.python.module.module', 'tensorflow.python.keras.engine.base_layer', 'tensorflow.python.keras.engine.input_layer', 'tensorflow.python.keras.engine.training_utils', 'six.moves.urllib.request', 'tensorflow.python.keras.utils.data_utils', 'tensorflow.python.keras.utils.dataset_creator', 'tensorflow.python.keras.engine.data_adapter', 'tensorflow.python.keras.engine.base_preprocessing_layer', 'tensorflow.python.keras.layers.advanced_activations', 'tensorflow.python.keras.utils.conv_utils', 'tensorflow.python.keras.layers.pooling', 'tensorflow.python.keras.layers.convolutional', 'tensorflow.python.ops.gen_batch_ops', 'tensorflow.python.ops.batch_ops', 'tensorflow.python.ops.critical_section_ops', 'tensorflow.python.ops.histogram_ops', 'tensorflow.python.ops.numerics', 'tensorflow.python.ops.template', 'tensorflow.compiler.tf2tensorrt', 'tensorflow.compiler.tf2tensorrt._pywrap_py_utils', 'tensorflow.python.compiler.tensorrt.utils', 'tensorflow.python.grappler', 'tensorflow.python.grappler._pywrap_tf_optimizer', 'tensorflow.core.grappler', 'tensorflow.core.grappler.costs', 'tensorflow.core.protobuf.device_properties_pb2', 'tensorflow.core.grappler.costs.op_performance_data_pb2', 'tensorflow.python.grappler._pywrap_tf_cluster', 'tensorflow.python.grappler.cluster', 'tensorflow.python.grappler.tf_optimizer', 'tensorflow.python.framework.convert_to_constants', 'tensorflow.python.saved_model.builder_impl', 'tensorflow.python.saved_model.builder', 'tensorflow.python.saved_model.loader', 'tensorflow.python.saved_model.tag_constants', 'tensorflow.python.saved_model.tracing_utils', 'tensorflow.python.training.saving.trace_saveable_util', 'tensorflow.python.saved_model.save', 'tensorflow.compiler.tf2tensorrt.ops', 'tensorflow.compiler.tf2tensorrt.ops.gen_trt_ops', 'tensorflow.python.compiler.tensorrt.trt_convert', 'tensorflow.python.compiler.tensorrt', 'tensorflow.python.ops.standard_ops', 'tensorflow.python.keras.layers.core', 'tensorflow.python.keras.layers.dense_attention', 'tensorflow.python.keras.layers.embeddings', 'tensorflow.python.keras.layers.merge', 'tensorflow.python.keras.layers.recurrent', 'tensorflow.python.keras.layers.convolutional_recurrent', 'tensorflow.python.keras.layers.legacy_rnn', 'tensorflow.python.keras.layers.legacy_rnn.rnn_cell_wrapper_impl', 'tensorflow.python.keras.layers.rnn_cell_wrapper_v2', 'tensorflow.python.keras.layers.serialization', 'tensorflow.python.keras.layers', 'tensorflow.python.keras.activations', 'tensorflow.python.keras.saving.saved_model.metric_serialization', 'tensorflow.python.keras.metrics', 'tensorflow.python.keras.distribute.distributed_file_utils', 'tensorflow.python.saved_model.model_utils.export_output', 'tensorflow.python.saved_model.utils', 'tensorflow.python.saved_model.model_utils.mode_keys', 'tensorflow.python.saved_model.model_utils.export_utils', 'tensorflow.python.saved_model.model_utils', 'tensorflow.python.keras.utils.mode_keys', 'tensorflow.python.keras.distribute.worker_training_state', 'urllib3.exceptions', 'urllib3.util.timeout', 'urllib3.util.connection', 'urllib3.util.util', 'urllib3.util.request', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.ssl_', 'urllib3.util.wait', 'urllib3.util', 'urllib3._base_connection', 'urllib3._collections', 'urllib3._version', 'urllib3.fields', 'urllib3.filepost', 'urllib3.http2', 'urllib3.http2.probe', 'urllib3.util.ssl_match_hostname', 'urllib3.connection', 'urllib3.response', 'urllib3._request_methods', 'urllib3.util.proxy', 'urllib3.connectionpool', 'urllib3.poolmanager', 'urllib3', 'chardet.enums', 'chardet.charsetprober', 'chardet.charsetgroupprober', 'chardet.resultdict', 'chardet.codingstatemachinedict', 'chardet.codingstatemachine', 'chardet.escsm', 'chardet.escprober', 'chardet.latin1prober', 'chardet.macromanprober', 'chardet.big5freq', 'chardet.euckrfreq', 'chardet.euctwfreq', 'chardet.gb2312freq', 'chardet.jisfreq', 'chardet.johabfreq', 'chardet.chardistribution', 'chardet.mbcharsetprober', 'chardet.mbcssm', 'chardet.big5prober', 'chardet.cp949prober', 'chardet.jpcntx', 'chardet.eucjpprober', 'chardet.euckrprober', 'chardet.euctwprober', 'chardet.gb2312prober', 'chardet.johabprober', 'chardet.sjisprober', 'chardet.utf8prober', 'chardet.mbcsgroupprober', 'chardet.sbcharsetprober', 'chardet.hebrewprober', 'chardet.langbulgarianmodel', 'chardet.langgreekmodel', 'chardet.langhebrewmodel', 'chardet.langrussianmodel', 'chardet.langthaimodel', 'chardet.langturkishmodel', 'chardet.sbcsgroupprober', 'chardet.utf1632prober', 'chardet.universaldetector', 'chardet.version', 'chardet', 'http.cookiejar', 'http.cookies', 'requests.compat', 'requests.exceptions', 'charset_normalizer.constant', 'charset_normalizer.md__mypyc', '_multibytecodec', 'charset_normalizer.utils', 'charset_normalizer.md', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.api', 'charset_normalizer.legacy', 'charset_normalizer.version', 'charset_normalizer', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.util.util', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util', 'requests.packages.urllib3._base_connection', 'requests.packages.urllib3._collections', 'requests.packages.urllib3._version', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.http2', 'requests.packages.urllib3.http2.probe', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.response', 'requests.packages.urllib3._request_methods', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3', 'idna.idnadata', 'idna.intranges', 'idna.core', 'idna.package_data', 'idna', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.idna.core', 'requests.packages.idna.package_data', 'requests.packages.idna', 'requests.packages.chardet.enums', 'requests.packages.chardet.charsetprober', 'requests.packages.chardet.charsetgroupprober', 'requests.packages.chardet.resultdict', 'requests.packages.chardet.codingstatemachinedict', 'requests.packages.chardet.codingstatemachine', 'requests.packages.chardet.escsm', 'requests.packages.chardet.escprober', 'requests.packages.chardet.latin1prober', 'requests.packages.chardet.macromanprober', 'requests.packages.chardet.big5freq', 'requests.packages.chardet.euckrfreq', 'requests.packages.chardet.euctwfreq', 'requests.packages.chardet.gb2312freq', 'requests.packages.chardet.jisfreq', 'requests.packages.chardet.johabfreq', 'requests.packages.chardet.chardistribution', 'requests.packages.chardet.mbcharsetprober', 'requests.packages.chardet.mbcssm', 'requests.packages.chardet.big5prober', 'requests.packages.chardet.cp949prober', 'requests.packages.chardet.jpcntx', 'requests.packages.chardet.eucjpprober', 'requests.packages.chardet.euckrprober', 'requests.packages.chardet.euctwprober', 'requests.packages.chardet.gb2312prober', 'requests.packages.chardet.johabprober', 'requests.packages.chardet.sjisprober', 'requests.packages.chardet.utf8prober', 'requests.packages.chardet.mbcsgroupprober', 'requests.packages.chardet.sbcharsetprober', 'requests.packages.chardet.hebrewprober', 'requests.packages.chardet.langbulgarianmodel', 'requests.packages.chardet.langgreekmodel', 'requests.packages.chardet.langhebrewmodel', 'requests.packages.chardet.langrussianmodel', 'requests.packages.chardet.langthaimodel', 'requests.packages.chardet.langturkishmodel', 'requests.packages.chardet.sbcsgroupprober', 'requests.packages.chardet.utf1632prober', 'requests.packages.chardet.universaldetector', 'requests.packages.chardet.version', 'requests.packages.chardet', 'requests.packages', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.utils', 'requests.auth', 'stringprep', 'encodings.idna', 'requests.hooks', 'requests.status_codes', 'requests.models', 'urllib3.contrib', 'urllib3.contrib.socks', 'requests.adapters', 'requests.sessions', 'requests.api', 'requests', 'tensorflow.python.keras.callbacks', 'tensorflow.python.keras.engine.compile_utils', 'tensorflow.python.keras.saving.model_config', '_cython_3_0_11', 'h5py._errors', 'h5py.defs', 'h5py._objects', 'h5py.h5py_warnings', 'h5py.h5', 'h5py.version', 'h5py.utils', 'h5py.h5t', 'h5py.h5s', 'h5py.h5ac', 'h5py.h5p', 'h5py.h5r', 'h5py._proxy', 'h5py._conv', 'h5py.h5z', 'h5py.h5a', 'h5py.h5d', 'h5py.h5ds', 'h5py.h5g', 'h5py.h5i', 'h5py.h5o', 'h5py.h5f', 'h5py.h5fd', 'h5py.h5pl', 'h5py._hl', 'h5py._hl.compat', 'h5py._hl.base', 'h5py._hl.filters', 'h5py.h5l', 'h5py._selector', 'h5py._hl.selections', 'h5py._hl.selections2', 'h5py._hl.datatype', 'h5py._hl.vds', 'h5py._hl.dataset', 'h5py._hl.group', 'h5py._hl.files', 'h5py._hl.attrs', 'h5py', 'tensorflow.python.keras.saving.hdf5_format', 'tensorflow.python.keras.saving.saved_model.load_context', 'tensorflow.python.keras.saving.saved_model.save', 'tensorflow.python.keras.saving.save', 'tensorflow.python.keras.saving.saved_model.model_serialization', 'tensorflow.python.keras.engine.training', 'tensorflow.python.keras.saving.saved_model.network_serialization', 'tensorflow.python.keras.engine.functional', 'tensorflow.python.keras.engine.sequential', 'tensorflow.python.keras.engine.training_utils_v1', 'tensorflow.python.keras.distribute.distributed_training_utils_v1', 'scipy._lib._testutils', 'scipy._lib', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback_c', 'scipy._lib._ccallback', 'scipy', 'scipy.sparse._sputils', 'scipy.sparse._matrix', 'scipy.sparse._base', 'scipy.sparse._sparsetools', 'scipy._lib._util', 'scipy.sparse._data', 'scipy.sparse._index', 'scipy.sparse._compressed', 'scipy.sparse._csr', 'scipy.sparse._csc', '_cython_0_29_36', '_csparsetools', 'scipy.sparse._csparsetools', 'scipy.sparse._lil', 'scipy.sparse._dok', 'scipy.sparse._coo', 'scipy.sparse._dia', 'scipy.sparse._bsr', 'scipy.sparse._construct', 'scipy.sparse._extract', 'scipy.sparse._matrix_io', 'scipy.sparse.linalg._isolve._iterative', 'scipy.sparse.linalg._interface', 'scipy.sparse.linalg._isolve.utils', 'scipy._lib.decorator', 'scipy._lib._threadsafety', 'scipy.sparse.linalg._isolve.iterative', 'scipy.sparse.linalg._isolve.minres', 'scipy.linalg._fblas', 'scipy.linalg.blas', 'scipy.linalg._flapack', 'scipy.linalg.lapack', 'scipy.linalg._misc', 'scipy.linalg.cython_lapack', 'scipy.linalg._cythonized_array_utils', 'scipy.linalg._decomp', 'scipy.linalg._decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg._basic', 'scipy.linalg._decomp_lu_cython', 'scipy.linalg._decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg._decomp_cholesky', 'scipy.linalg._decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg._decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg.cython_blas', 'scipy.linalg._matfuncs_expm', 'scipy.linalg._matfuncs', 'scipy.linalg._special_matrices', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.linalg.decomp', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_lu', 'scipy.linalg.decomp_qr', 'scipy.linalg.decomp_svd', 'scipy.linalg.decomp_schur', 'scipy.linalg.basic', 'scipy.linalg.misc', 'scipy.linalg.special_matrices', 'scipy.linalg._flinalg', 'scipy.linalg._flinalg_py', 'scipy.linalg.flinalg', 'scipy.linalg.matfuncs', 'scipy.linalg', 'scipy.sparse.linalg._isolve._gcrotmk', 'scipy.sparse.linalg._isolve.lgmres', 'scipy.sparse.linalg._isolve.lsqr', 'scipy.sparse.linalg._isolve.lsmr', 'scipy.sparse.linalg._isolve.tfqmr', 'scipy.sparse.linalg._isolve', 'scipy.sparse.linalg._dsolve._superlu', 'scipy.sparse.linalg._dsolve.linsolve', 'scipy.sparse.linalg._dsolve._add_newdocs', 'scipy.sparse.linalg._dsolve', 'scipy.sparse.linalg._eigen.arpack._arpack', 'scipy.sparse.linalg._eigen.arpack.arpack', 'scipy.sparse.linalg._eigen.arpack', 'scipy.sparse.linalg._eigen.lobpcg.lobpcg', 'scipy.sparse.linalg._eigen.lobpcg', 'scipy.sparse.linalg._eigen._svds', 'scipy.sparse.linalg._eigen', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._matfuncs', 'scipy.sparse.linalg._norm', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.sparse.csgraph', 'scipy.sparse.base', 'scipy.sparse.bsr', 'scipy.sparse.compressed', 'scipy.sparse.construct', 'scipy.sparse.coo', 'scipy.sparse.csc', 'scipy.sparse.csr', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse.dok', 'scipy.sparse.extract', 'scipy.sparse.lil', 'scipy.sparse.sparsetools', 'scipy.sparse.sputils', 'scipy.sparse', 'tensorflow.python.keras.engine.training_arrays_v1', 'tensorflow.python.keras.engine.partial_batch_padding_handler', 'tensorflow.python.keras.engine.training_distributed_v1', 'tensorflow.python.keras.engine.training_eager_v1', 'tensorflow.python.keras.engine.training_generator_v1', 'tensorflow.python.keras.engine.training_v1', 'tensorflow.python.keras.models', 'tensorflow.python.keras', 'tensorflow.python.keras.legacy_tf_layers', 'tensorflow.python.keras.legacy_tf_layers.variable_scope_shim', 'tensorflow.python.keras.legacy_tf_layers.base', 'tensorflow.python.layers.base', 'tensorflow.python.training.checkpoint_utils', 'tensorflow.python.feature_column.feature_column', 'tensorflow.python.feature_column.feature_column_v2_types', 'tensorflow.python.feature_column.serialization', 'tensorflow.python.feature_column.feature_column_v2', 'tensorflow._api.v2.__internal__.feature_column', 'tensorflow._api.v2.__internal__.function', 'tensorflow._api.v2.__internal__.graph_util', 'tensorflow._api.v2.__internal__.mixed_precision', 'tensorflow._api.v2.__internal__.monitoring', 'tensorflow._api.v2.__internal__.nest', 'tensorflow._api.v2.__internal__.ops', 'tensorflow._api.v2.__internal__.saved_model.load', 'tensorflow._api.v2.__internal__.saved_model', 'tensorflow._api.v2.__internal__.smart_cond', 'tensorflow._api.v2.__internal__.test.combinations', 'tensorflow._api.v2.__internal__.test', 'tensorflow._api.v2.__internal__.tf2', 'tensorflow._api.v2.__internal__.tracking', 'tensorflow._api.v2.__internal__.train', 'tensorflow._api.v2.__internal__.types.data', 'tensorflow._api.v2.__internal__.types', 'tensorflow._api.v2.__internal__', 'tensorflow._api.v2.__operators__', 'tensorflow.python.ops.gen_audio_ops', 'tensorflow._api.v2.audio', 'tensorflow._api.v2.autodiff', 'tensorflow._api.v2.autograph.experimental', 'tensorflow._api.v2.autograph', 'tensorflow._api.v2.bitwise', 'tensorflow.python.util.fast_module_type', 'tensorflow.tools.compatibility', 'tensorflow.tools.compatibility.renames_v2', 'tensorflow.tools.compatibility.all_renames_v2', 'tensorflow.python.util.module_wrapper', 'tensorflow._api.v2.compat.v1.__internal__.types.data', 'tensorflow._api.v2.compat.v1.__internal__.types', 'tensorflow._api.v2.compat.v1.__internal__', 'tensorflow.python.platform.app', 'tensorflow._api.v2.compat.v1.app', 'tensorflow._api.v2.compat.v1.audio', 'tensorflow._api.v2.compat.v1.autograph.experimental', 'tensorflow._api.v2.compat.v1.autograph', 'tensorflow._api.v2.compat.v1.bitwise', 'tensorflow._api.v2.compat.v1.config.experimental', 'tensorflow._api.v2.compat.v1.config.optimizer', 'tensorflow._api.v2.compat.v1.config.threading', 'tensorflow._api.v2.compat.v1.config', 'tensorflow._api.v2.compat.v1.data.experimental.service', 'tensorflow._api.v2.compat.v1.data.experimental', 'tensorflow._api.v2.compat.v1.data', 'tensorflow.python.debug.lib', 'tensorflow.python.debug.lib.debug_graphs', 'tensorflow.python.debug.lib.debug_data', 'tensorflow.python.debug.lib.debug_gradients', 'tensorflow.python.debug.lib.debug_utils', 'tensorflow.python.debug.wrappers', 'tensorflow.python.debug.wrappers.framework', 'tensorflow.python.debug.wrappers.dumping_wrapper', 'tensorflow.python.debug.lib.common', 'tensorflow.python.debug.wrappers.grpc_wrapper', 'tensorflow.python.debug.cli', 'tensorflow.python.debug.cli.debugger_cli_common', 'tensorflow.python.debug.cli.cli_config', 'tensorflow.python.debug.cli.command_parser', 'tensorflow.python.debug.cli.tensor_format', 'tensorflow.python.debug.cli.cli_shared', 'tensorflow.python.debug.cli.evaluator', 'tensorflow.python.debug.cli.ui_factory', 'tensorflow.python.debug.lib.profiling', 'tensorflow.python.debug.lib.source_utils', 'tensorflow.python.debug.cli.analyzer_cli', 'tensorflow.python.debug.cli.profile_analyzer_cli', 'tensorflow.python.debug.wrappers.local_cli_wrapper', 'tensorflow.python.debug.wrappers.hooks', 'tensorflow.python.debug', 'tensorflow.core.protobuf.debug_event_pb2', 'tensorflow.python.client._pywrap_debug_events_writer', 'tensorflow.python.debug.lib.debug_events_writer', 'tensorflow.python.debug.lib.op_callbacks_common', 'tensorflow.python.ops.gen_debug_ops', 'tensorflow.python.debug.lib.dumping_callback', 'tensorflow._api.v2.compat.v1.debugging.experimental', 'tensorflow.python.debug.lib.check_numerics_callback', 'tensorflow._api.v2.compat.v1.debugging', 'tensorflow._api.v2.compat.v1.distribute.cluster_resolver', 'tensorflow._api.v2.compat.v1.distribute.experimental', 'tensorflow._api.v2.compat.v1.distribute', 'tensorflow.python.ops.distributions.kullback_leibler', 'tensorflow.python.ops.distributions.util', 'tensorflow.python.ops.distributions.distribution', 'tensorflow.python.ops.distributions.bernoulli', 'tensorflow.python.ops.distributions.beta', 'tensorflow.python.ops.distributions.categorical', 'tensorflow.python.ops.distributions.dirichlet', 'tensorflow.python.ops.distributions.dirichlet_multinomial', 'tensorflow.python.ops.distributions.gamma', 'tensorflow.python.ops.distributions.exponential', 'tensorflow.python.ops.distributions.special_math', 'tensorflow.python.ops.distributions.laplace', 'tensorflow.python.ops.distributions.multinomial', 'tensorflow.python.ops.distributions.normal', 'tensorflow.python.ops.distributions.student_t', 'tensorflow.python.ops.distributions.uniform', 'tensorflow.python.ops.distributions.distributions', 'tensorflow.python.ops.distributions', 'tensorflow._api.v2.compat.v1.distributions', 'tensorflow._api.v2.compat.v1.dtypes.experimental', 'tensorflow._api.v2.compat.v1.dtypes', 'tensorflow._api.v2.compat.v1.errors', 'tensorflow._api.v2.compat.v1.experimental.extension_type', 'tensorflow.python.framework._pywrap_python_op_gen', 'tensorflow.python.framework.load_library', 'tensorflow._api.v2.compat.v1.experimental', 'tensorflow.python.feature_column.sequence_feature_column', 'tensorflow._api.v2.compat.v1.feature_column', 'tensorflow._api.v2.compat.v1.gfile', 'tensorflow._api.v2.compat.v1.graph_util', 'tensorflow.python.ops.random_crop_ops', 'tensorflow._api.v2.compat.v1.image', 'tensorflow._api.v2.compat.v1.initializers', 'tensorflow._api.v2.compat.v1.io.gfile', 'tensorflow.python.layers.utils', 'tensorflow.python.training.input', 'tensorflow._api.v2.compat.v1.io', 'tensorflow._api.v2.compat.v1.layers', 'tensorflow.python.ops.linalg.sparse.conjugate_gradient', 'tensorflow._api.v2.compat.v1.linalg.experimental', 'tensorflow.python.ops.linalg.linear_operator_util', 'tensorflow.python.ops.linalg.property_hint_util', 'tensorflow.python.ops.linalg.slicing', 'tensorflow.python.ops.linalg.linear_operator', 'tensorflow.python.ops.linalg.linear_operator_adjoint', 'tensorflow.python.ops.linalg.linear_operator_block_diag', 'tensorflow.python.ops.linalg.linear_operator_lower_triangular', 'tensorflow.python.ops.linalg.linear_operator_diag', 'tensorflow.python.ops.linalg.linear_operator_full_matrix', 'tensorflow.python.ops.linalg.linear_operator_identity', 'tensorflow.python.ops.linalg.linear_operator_addition', 'tensorflow.python.ops.linalg.linear_operator_block_lower_triangular', 'tensorflow.python.ops.linalg.linear_operator_circulant', 'tensorflow.python.ops.linalg.linear_operator_composition', 'tensorflow.python.ops.linalg.linear_operator_householder', 'tensorflow.python.ops.linalg.linear_operator_inversion', 'tensorflow.python.ops.linalg.linear_operator_kronecker', 'tensorflow.python.ops.linalg.linear_operator_low_rank_update', 'tensorflow.python.ops.linalg.linear_operator_permutation', 'tensorflow.python.ops.linalg.linear_operator_toeplitz', 'tensorflow.python.ops.linalg.linear_operator_tridiag', 'tensorflow.python.ops.linalg.linear_operator_zeros', 'tensorflow._api.v2.compat.v1.linalg', 'tensorflow.lite', 'tensorflow.lite.python', 'tensorflow.lite.toco', 'tensorflow.compiler.mlir', 'tensorflow.compiler.mlir.lite', 'tensorflow.compiler.mlir.lite.debug', 'tensorflow.compiler.mlir.lite.debug.debug_options_pb2', 'tensorflow.compiler.mlir.quantization', 'tensorflow.compiler.mlir.quantization.stablehlo', 'tensorflow.compiler.mlir.quantization.stablehlo.quantization_config_pb2', 'tensorflow.compiler.mlir.quantization.stablehlo.quantization_options_pb2', 'tensorflow.lite.toco.types_pb2', 'tensorflow.lite.toco.toco_flags_pb2', 'tensorflow.lite.python.lite_constants', 'tensorflow._api.v2.compat.v1.lite.constants', 'tensorflow.lite.python.authoring', 'tensorflow.compiler.mlir.lite.python', 'tensorflow.compiler.mlir.lite.python._pywrap_converter_api', 'tensorflow.compiler.mlir.quantization.tensorflow', 'tensorflow.compiler.mlir.quantization.tensorflow.python', 'tensorflow.compiler.mlir.quantization.tensorflow.exported_model_pb2', 'tensorflow.compiler.mlir.quantization.tensorflow.quantization_options_pb2', 'tensorflow.compiler.mlir.quantization.tensorflow.calibrator', 'tensorflow.compiler.mlir.quantization.tensorflow.calibrator.calibration_statistics_pb2', 'tensorflow.compiler.mlir.quantization.tensorflow.calibrator.calibration_algorithm', 'tensorflow.compiler.mlir.quantization.tensorflow.python.pywrap_function_lib', 'tensorflow.compiler.mlir.quantization.tensorflow.python.representative_dataset', 'tensorflow.compiler.mlir.quantization.tensorflow.python.save_model', 'tensorflow.compiler.mlir.quantization.tensorflow.python.py_function_lib', 'tensorflow.compiler.mlir.lite.python.wrap_converter', 'flatbuffers.compat', 'flatbuffers.packer', 'flatbuffers.number_types', 'flatbuffers.encode', 'flatbuffers.builder', 'flatbuffers.table', 'flatbuffers._version', 'flatbuffers.util', 'flatbuffers', 'tensorflow.lite.python.conversion_metadata_schema_py_generated', 'tensorflow.lite.python.schema_py_generated', 'tensorflow.lite.python.schema_util', 'tensorflow.lite.python.tflite_keras_util', 'tensorflow.lite.python.op_hint', 'tensorflow.lite.tools', 'tensorflow.lite.tools.flatbuffer_utils', 'jax.version', 'jax._src', 'jaxlib.version', 'jaxlib', 'jaxlib.cpu_feature_guard', 'jaxlib.utils', 'jaxlib.xla_extension.ifrt_programs', 'jaxlib.xla_extension.profiler', 'jaxlib.xla_extension.ops', 'jaxlib.xla_extension.outfeed_receiver', 'jaxlib.xla_extension.pytree', 'jaxlib.xla_extension.jax_jit', 'jaxlib.xla_extension.pmap_lib', 'jaxlib.xla_extension.transfer_guard_lib', 'jaxlib.xla_extension.mlir', 'jaxlib.xla_extension.hlo_sharding_util', 'jaxlib.xla_extension.ifrt_proxy', 'jaxlib.xla_extension', 'jaxlib.xla_client', 'jaxlib.mlir', 'jaxlib.mlir._mlir_libs._mlir.ir', 'jaxlib.mlir._mlir_libs._mlir.rewrite', 'jaxlib.mlir._mlir_libs._mlir.passmanager', 'jaxlib.mlir._mlir_libs._mlir', 'jaxlib.mlir._mlir_libs', 'jaxlib.mlir.ir', 'jaxlib.mlir.dialects', 'jaxlib.mlir.dialects._ods_common', 'jaxlib.mlir.dialects._stablehlo_ops_gen', 'jaxlib.mlir._mlir_libs._stablehlo', 'jaxlib.mlir.dialects.stablehlo', 'jaxlib.cpu', 'jaxlib.cpu._lapack.svd', 'jaxlib.cpu._lapack.eig', 'jaxlib.cpu._lapack', 'jaxlib.hlo_helpers', 'jaxlib.lapack', 'jax_cuda12_plugin', 'jax_cuda12_plugin._versions', 'jaxlib.gpu_common_utils', 'jax_cuda12_plugin._blas', 'jax_cuda12_plugin._solver', 'jaxlib.gpu_solver', 'jax_cuda12_plugin._sparse', 'jaxlib.gpu_sparse', 'jax_cuda12_plugin._prng', 'jaxlib.gpu_prng', 'jax_cuda12_plugin._linalg', 'jaxlib.gpu_linalg', 'jax_cuda12_plugin._rnn', 'jaxlib.gpu_rnn', 'jax_cuda12_plugin._triton', 'jaxlib.gpu_triton', 'jaxlib.mosaic', 'jaxlib.mosaic.python', 'jaxlib.mosaic.python._tpu_gen', 'jaxlib.mlir._mlir_libs._tpu_ext', 'jaxlib.mosaic.python.tpu', 'jax._src.lib', 'jax._src.logging_config', 'jax._src.config', 'jax._src.hardware_utils', 'jax._src.cloud_tpu_init', 'jax._src.deprecations', 'jax._src.basearray', 'jax._src.typing', 'jax._src.util', 'jax._src.traceback_util', 'jax._src.dtypes', 'jax._src.effects', 'jax._src.compute_on', 'jax._src.errors', 'jax._src.tree_util', 'jax._src.linear_util', '_sysconfigdata__x86_64-linux-gnu', 'jax._src.source_info_util', 'jax._src.pretty_printer', 'jax._src.xla_metadata', 'jax._src.core', 'jax.core', 'jax._src.tree', 'jax.tree', 'jax.typing', 'jax._src.clusters.cluster', 'jax._src.clusters.ompi_cluster', 'jax._src.clusters.slurm_cluster', 'jax._src.clusters.mpi4py_cluster', 'jax._src.clusters.cloud_tpu_cluster', 'jax._src.clusters', 'jax._src.distributed', 'jax_plugins', 'jax._src.xla_bridge', 'jax._src.environment_info', 'jax._src.mesh', 'jaxlib.mlir.passmanager', 'jaxlib.mlir._mlir_libs.register_jax_dialects', 'jax._src.lib.mlir', 'jax._src.lazy_loader', 'jax._src.lib.mlir.dialects', 'jax._src.op_shardings', 'jax._src.sharding', 'jax._src.sharding_specs', 'jax._src.mesh_utils', 'jax._src.partition_spec', 'jax._src.sharding_impls', 'jax._src.layout', 'jax._src.interpreters', 'jax._src.ad_util', 'etils', 'jax._src.path', 'cloudpickle.cloudpickle', 'cloudpickle', 'socketserver', 'http.server', 'jax._src.profiler', 'jax._src.pickle_util', 'jax._src.abstract_arrays', 'jax._src.api_util', 'jax._src.state.indexing', 'jax._src.state.types', 'jax._src.state', 'jax._src.interpreters.partial_eval', 'jax._src.interpreters.xla', 'jaxlib.mlir.dialects._func_ops_gen', 'jaxlib.mlir.dialects.func', 'jax._src.interpreters.mlir', 'jax._src.stages', 'jax.tree_util', 'jax._src.interpreters.ad', 'jax._src.interpreters.batching', 'jax._src.cache_key', 'jax._src.monitoring', 'jax._src.compilation_cache_interface', 'filelock._error', 'filelock._api', 'filelock._util', 'filelock._soft', 'filelock._unix', 'filelock._windows', 'filelock.asyncio', 'filelock.version', 'filelock', 'jax._src.lru_cache', 'jax._src.compilation_cache', 'jax._src.compiler', 'jax._src.interpreters.pxla', 'jax._src.dispatch', 'jax._src.array', 'jax._src.lax', 'jax.sharding', 'jax._src.lax.utils', 'jax._src.lax.slicing', 'jaxlib.mlir.dialects._chlo_ops_gen', 'jaxlib.mlir._mlir_libs._chlo', 'jaxlib.mlir.dialects.chlo', 'jax._src.lax.lax', 'jax._src.state.primitives', 'jax._src.state.utils', 'jax._src.state.discharge', 'jax._src.pjit', 'jax._src.api', 'jax._src.lax.convolution', 'jax._src.ad_checkpoint', 'jax._src.custom_api_util', 'jax._src.custom_transpose', 'jax._src.custom_derivatives', 'jax._src.lax.other', 'jax._src.lax.windowed_reductions', 'jax.api_util', 'jax._src.lax.control_flow.common', 'jax._src.lax.control_flow.loops', 'jax._src.lax.control_flow.conditionals', 'jax._src.lax.control_flow.solves', 'jax._src.lax.control_flow', 'jax._src.callback', 'jax.interpreters', 'jax.interpreters.ad', 'jax.interpreters.batching', 'jax.interpreters.mlir', 'jax.interpreters.partial_eval', 'jax.interpreters.pxla', 'jax.interpreters.xla', 'jax.custom_derivatives', 'jax._src.lax.special', 'jax._src.lax.fft', 'jax._src.lax.parallel', 'jax._src.lax.ann', 'jax._src.extend', 'jax._src.extend.ffi', 'jax._src.numpy', 'jax.errors', 'jax._src.numpy.util', 'jax._src.numpy.reductions', 'jax._src.numpy.vectorize', 'jax._src.numpy.ufunc_api', 'jax._src.numpy.ufuncs', 'jax_cuda12_plugin.cuda_plugin_extension', 'jax._src.numpy.lax_numpy', 'jax._src.numpy.linalg', 'jax.dtypes', 'jax._src.numpy.fft', 'jax.numpy.fft', 'jax.numpy.linalg', 'jax._src.numpy.array_api_metadata', 'jax._src.numpy.index_tricks', 'jax._src.numpy.polynomial', 'jax._src.numpy.setops', 'jax._src.ops', 'jax._src.ops.scatter', 'jax._src.numpy.array_methods', 'jax.numpy', 'jax._src.lax.qdwh', 'jax._src.lax.stack', 'jax._src.lax.eigh', 'jax._src.lax.svd', 'jax._src.lax.linalg', 'jax.lax.linalg', 'jax.lax', 'jax._src.custom_batching', 'jax.custom_batching', 'jax.custom_transpose', 'jax.distributed', 'jax._src.debugging', 'jax._src.debugger.core', 'jax._src.debugger.cli_debugger', 'jax._src.debugger.colab_lib', 'pygments', 'jax._src.debugger.colab_debugger', 'jax._src.debugger.web_debugger', 'jax._src.debugger', 'jax.debug', 'jax._src.dlpack', 'jax.dlpack', 'jax._src.image', 'jax._src.image.scale', 'jax.image', 'jax.monitoring', 'jax._src.nn', 'jax._src.prng', 'jax._src.random', 'jax.random', 'jax._src.nn.initializers', 'jax.nn.initializers', 'jax._src.cudnn.fusion', 'jax._src.cudnn', 'jax._src.custom_partitioning', 'jax._src.cudnn.fused_attention_stablehlo', 'jax._src.ops.special', 'jax._src.nn.functions', 'jax.nn', 'jax.ops', 'jax.profiler', 'jax.scipy', 'jax.stages', 'jax.util', 'jax.experimental.x64_context', 'jax._src.earray', 'jax.experimental', 'jax.experimental.compilation_cache', 'jax.experimental.compilation_cache.compilation_cache', 'jax.lib.xla_bridge', 'jax.lib.xla_client', 'jax.lib.xla_extension', 'jax.lib', 'jax', 'tensorflow.lite.python.util', 'tensorflow.lite.python.metrics', 'tensorflow.lite.python.metrics.converter_error_data_pb2', 'tensorflow.lite.python.metrics.metrics_interface', 'tensorflow.lite.python.metrics.metrics', 'tensorflow.lite.python.convert_phase', 'tensorflow.lite.python.metrics.wrapper', 'tensorflow.lite.python.metrics._pywrap_tensorflow_lite_metrics_wrapper', 'tensorflow.lite.python.metrics.wrapper.metrics_wrapper', 'tensorflow.lite.toco.model_flags_pb2', 'tensorflow.python.platform.resource_loader', 'tensorflow.lite.python.convert', 'tensorflow.lite.experimental', 'tensorflow.lite.experimental.microfrontend', 'tensorflow.lite.experimental.microfrontend.python', 'tensorflow.lite.experimental.microfrontend.python.ops', 'tensorflow.lite.experimental.microfrontend.ops', 'tensorflow.lite.experimental.microfrontend.ops.gen_audio_microfrontend_op', '97d2165b493fecec79c65b5c6254dffd4e375528', 'tensorflow.lite.experimental.microfrontend.python.ops.audio_microfrontend_op', 'tensorflow.lite.profiling', 'tensorflow.lite.profiling.proto', 'tensorflow.lite.profiling.proto.profiling_info_pb2', 'tensorflow.lite.python.convert_saved_model', 'tensorflow.lite.python.interpreter_wrapper', 'tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper', 'tensorflow.lite.python.interpreter', 'tensorflow.lite.python.optimize', 'tensorflow.lite.python.optimize.calibrator', 'tensorflow.lite.tools.optimize', 'tensorflow.lite.tools.optimize.debugging', 'tensorflow.lite.tools.optimize.debugging.python', 'tensorflow.lite.tools.optimize.debugging.python.debugger', 'tensorflow.lite.python.lite', 'tensorflow.lite.python.authoring.authoring', 'tensorflow._api.v2.compat.v1.lite.experimental.authoring', 'tensorflow.lite.python.analyzer_wrapper', 'tensorflow.lite.python.analyzer_wrapper._pywrap_analyzer_wrapper', 'tensorflow.lite.python.analyzer', 'tensorflow._api.v2.compat.v1.lite.experimental', 'tensorflow._api.v2.compat.v1.lite', 'tensorflow._api.v2.compat.v1.logging', 'tensorflow._api.v2.compat.v1.lookup.experimental', 'tensorflow._api.v2.compat.v1.lookup', 'tensorflow._api.v2.compat.v1.losses', 'tensorflow._api.v2.compat.v1.manip', 'tensorflow._api.v2.compat.v1.math.special', 'tensorflow._api.v2.compat.v1.math', 'tensorflow.python.ops.metrics_impl', 'tensorflow._api.v2.compat.v1.metrics', 'tensorflow._api.v2.compat.v1.mixed_precision.experimental', 'tensorflow._api.v2.compat.v1.mixed_precision', 'tensorflow.python.compiler.mlir', 'tensorflow.python._pywrap_mlir', 'tensorflow.python.pywrap_mlir', 'tensorflow.python.compiler.mlir.mlir', 'tensorflow._api.v2.compat.v1.mlir.experimental', 'tensorflow._api.v2.compat.v1.mlir', 'tensorflow._api.v2.compat.v1.nest', 'tensorflow._api.v2.compat.v1.nn.experimental', 'tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl', 'tensorflow._api.v2.compat.v1.nn.rnn_cell', 'tensorflow.python.ops.rnn_cell_impl', 'tensorflow.python.ops.rnn', 'tensorflow._api.v2.compat.v1.nn', 'tensorflow.core.profiler', 'tensorflow.core.profiler.tfprof_options_pb2', 'tensorflow.core.profiler.tfprof_output_pb2', 'tensorflow.core.profiler.tfprof_log_pb2', 'tensorflow.python.profiler.internal.flops_registry', 'tensorflow.python.profiler.tfprof_logger', 'tensorflow.python.profiler.option_builder', 'tensorflow.python.util._pywrap_tfprof', 'tensorflow.python.profiler.model_analyzer', 'tensorflow.python.profiler.profiler', 'tensorflow._api.v2.compat.v1.profiler', 'tensorflow._api.v2.compat.v1.python_io', 'tensorflow.compiler.mlir.quantization.tensorflow.python.pywrap_quantize_model', 'tensorflow.compiler.mlir.quantization.tensorflow.python.quantize_model', 'tensorflow._api.v2.compat.v1.quantization.experimental', 'tensorflow._api.v2.compat.v1.quantization', 'tensorflow._api.v2.compat.v1.queue', 'tensorflow._api.v2.compat.v1.ragged', 'tensorflow.python.ops.gen_stateful_random_ops', 'tensorflow.python.ops.stateful_random_ops', 'tensorflow._api.v2.compat.v1.random.experimental', 'tensorflow._api.v2.compat.v1.random', 'tensorflow.python.ops.gen_boosted_trees_ops', 'tensorflow.python.ops.gen_clustering_ops', 'tensorflow.python.ops.gen_filesystem_ops', 'tensorflow.python.ops.gen_map_ops', 'tensorflow.python.ops.gen_sendrecv_ops', 'tensorflow.python.ops.gen_uniform_quant_ops', 'tensorflow.python.tpu.ops.gen_xla_ops', 'tensorflow.python.user_ops', 'tensorflow.python.user_ops.ops', 'tensorflow.python.user_ops.ops.gen_user_ops', 'tensorflow._api.v2.compat.v1.raw_ops', 'tensorflow._api.v2.compat.v1.resource_loader', 'tensorflow._api.v2.compat.v1.saved_model.builder', 'tensorflow._api.v2.compat.v1.saved_model.constants', 'tensorflow._api.v2.compat.v1.saved_model.experimental', 'tensorflow._api.v2.compat.v1.saved_model.loader', 'tensorflow.python.saved_model.main_op_impl', 'tensorflow._api.v2.compat.v1.saved_model.main_op', 'tensorflow._api.v2.compat.v1.saved_model.signature_constants', 'tensorflow.python.saved_model.method_name_updater', 'tensorflow._api.v2.compat.v1.saved_model.signature_def_utils', 'tensorflow._api.v2.compat.v1.saved_model.tag_constants', 'tensorflow._api.v2.compat.v1.saved_model.utils', 'tensorflow.python.saved_model.simple_save', 'tensorflow._api.v2.compat.v1.saved_model', 'tensorflow._api.v2.compat.v1.sets', 'tensorflow.python.ops.signal.dct_ops', 'fractions', 'tensorflow.python.ops.signal.util_ops', 'tensorflow.python.ops.signal.shape_ops', 'tensorflow.python.ops.signal.mel_ops', 'tensorflow.python.ops.signal.mfcc_ops', 'tensorflow.python.ops.signal.reconstruction_ops', 'tensorflow.python.ops.signal.window_ops', 'tensorflow.python.ops.signal.spectral_ops', 'tensorflow._api.v2.compat.v1.signal', 'tensorflow._api.v2.compat.v1.sparse', 'tensorflow._api.v2.compat.v1.spectral', 'tensorflow._api.v2.compat.v1.strings', 'tensorflow.python.proto_exports', 'tensorflow._api.v2.compat.v1.summary', 'tensorflow.python.platform.sysconfig', 'tensorflow._api.v2.compat.v1.sysconfig', 'tensorflow._api.v2.compat.v1.test.experimental', 'tensorflow._api.v2.compat.v1.test', 'tensorflow.core.tpu', 'tensorflow.core.tpu.kernels', 'tensorflow.core.tpu.kernels.sparse_core_layout_pb2', 'tensorflow.python.ops.init_ops_v2', 'tensorflow.python.tpu.tpu_embedding_v2_utils', 'tensorflow.python.tpu.tpu_embedding_base', 'tensorflow.python.tpu.tpu_embedding_v3_utils', 'tensorflow.python.tpu.tpu_embedding_for_serving', 'tensorflow.python.tpu.tpu_embedding_v1', 'tensorflow.python.tpu.tpu_embedding_v2', 'tensorflow.python.tpu._pywrap_sparse_core_layout', 'tensorflow.python.tpu.tpu_embedding_v3_checkpoint_adapter', 'tensorflow.python.tpu.tpu_embedding_v3', 'tensorflow._api.v2.compat.v1.tpu.experimental.embedding', 'tensorflow.python.feature_column.feature_column_lib', 'tensorflow.python.tpu.feature_column', 'tensorflow.python.tpu.feature_column_v2', 'tensorflow._api.v2.compat.v1.tpu.experimental', 'tensorflow.python.tpu.bfloat16', 'tensorflow.python.ops.losses.losses', 'tensorflow.python.tpu.tpu_optimizer', 'tensorflow._api.v2.compat.v1.tpu', 'tensorflow._api.v2.compat.v1.train.experimental', 'tensorflow._api.v2.compat.v1.train.queue_runner', 'tensorflow.python.keras.optimizer_v2.legacy_learning_rate_decay', 'tensorflow.python.training.adadelta', 'tensorflow.python.training.adagrad', 'tensorflow.python.training.adagrad_da', 'tensorflow.python.training.adam', 'tensorflow.python.training.basic_loops', 'tensorflow.python.training.ftrl', 'tensorflow.python.training.gradient_descent', 'tensorflow.python.training.momentum', 'tensorflow.python.training.proximal_adagrad', 'tensorflow.python.training.proximal_gradient_descent', 'tensorflow.python._pywrap_quantize_training', 'tensorflow.python.training.quantize_training', 'tensorflow.python.training.rmsprop', 'tensorflow.python.training.supervisor', 'tensorflow.python.training.sync_replicas_optimizer', 'tensorflow.python.training.warm_starting_util', 'tensorflow.core.example', 'tensorflow.core.example.feature_pb2', 'tensorflow.core.example.example_pb2', 'tensorflow.python.training.learning_rate_decay', 'tensorflow.python.training.training', 'tensorflow._api.v2.compat.v1.train', 'tensorflow._api.v2.compat.v1.types.experimental', 'tensorflow._api.v2.compat.v1.types', 'tensorflow.python.user_ops.user_ops', 'tensorflow._api.v2.compat.v1.user_ops', 'tensorflow._api.v2.compat.v1.version', 'tensorflow._api.v2.compat.v1.xla.experimental', 'tensorflow._api.v2.compat.v1.xla', 'tensorflow._api.v2.compat.v1.compat.v1', 'tensorflow._api.v2.compat.v2.__internal__.autograph', 'tensorflow._api.v2.compat.v2.__internal__.decorator', 'tensorflow._api.v2.compat.v2.__internal__.dispatch', 'tensorflow._api.v2.compat.v2.__internal__.distribute.combinations', 'tensorflow._api.v2.compat.v2.__internal__.distribute.interim', 'tensorflow._api.v2.compat.v2.__internal__.distribute.multi_process_runner', 'tensorflow._api.v2.compat.v2.__internal__.distribute', 'tensorflow._api.v2.compat.v2.__internal__.eager_context', 'tensorflow._api.v2.compat.v2.__internal__.feature_column', 'tensorflow._api.v2.compat.v2.__internal__.function', 'tensorflow._api.v2.compat.v2.__internal__.graph_util', 'tensorflow._api.v2.compat.v2.__internal__.mixed_precision', 'tensorflow._api.v2.compat.v2.__internal__.monitoring', 'tensorflow._api.v2.compat.v2.__internal__.nest', 'tensorflow._api.v2.compat.v2.__internal__.ops', 'tensorflow._api.v2.compat.v2.__internal__.saved_model.load', 'tensorflow._api.v2.compat.v2.__internal__.saved_model', 'tensorflow._api.v2.compat.v2.__internal__.smart_cond', 'tensorflow._api.v2.compat.v2.__internal__.test.combinations', 'tensorflow._api.v2.compat.v2.__internal__.test', 'tensorflow._api.v2.compat.v2.__internal__.tf2', 'tensorflow._api.v2.compat.v2.__internal__.tracking', 'tensorflow._api.v2.compat.v2.__internal__.train', 'tensorflow._api.v2.compat.v2.__internal__.types.data', 'tensorflow._api.v2.compat.v2.__internal__.types', 'tensorflow._api.v2.compat.v2.__internal__', 'tensorflow._api.v2.compat.v2.__operators__', 'tensorflow._api.v2.compat.v2.audio', 'tensorflow._api.v2.compat.v2.autodiff', 'tensorflow._api.v2.compat.v2.autograph.experimental', 'tensorflow._api.v2.compat.v2.autograph', 'tensorflow._api.v2.compat.v2.bitwise', 'tensorflow._api.v2.compat.v2.compat.v1', 'tensorflow._api.v2.compat.v2.config.experimental', 'tensorflow._api.v2.compat.v2.config.optimizer', 'tensorflow._api.v2.compat.v2.config.threading', 'tensorflow._api.v2.compat.v2.config', 'tensorflow._api.v2.compat.v2.data.experimental.service', 'tensorflow._api.v2.compat.v2.data.experimental', 'tensorflow._api.v2.compat.v2.data', 'tensorflow._api.v2.compat.v2.debugging.experimental', 'tensorflow._api.v2.compat.v2.debugging', 'tensorflow._api.v2.compat.v2.distribute.cluster_resolver', 'tensorflow._api.v2.compat.v2.distribute.coordinator', 'tensorflow._api.v2.compat.v2.distribute.experimental.coordinator', 'tensorflow._api.v2.compat.v2.distribute.experimental.partitioners', 'tensorflow.dtensor.python.tpu_util', 'tensorflow.dtensor.python.accelerator_util', 'tensorflow.dtensor.python.mesh_util', 'tensorflow.dtensor.python.d_variable', 'tensorflow.dtensor.python.input_util', 'tensorflow.python.distribute.experimental.dtensor_util', 'tensorflow.python.distribute.experimental.dtensor_strategy_extended', 'tensorflow.python.distribute.experimental.mirrored_strategy', 'tensorflow.python.distribute.experimental.multi_worker_mirrored_strategy', 'tensorflow.python.distribute.experimental', 'tensorflow.python.distribute.experimental.rpc', 'tensorflow.distribute', 'tensorflow.distribute.experimental', 'tensorflow.distribute.experimental.rpc', 'tensorflow.distribute.experimental.rpc.kernels', 'tensorflow.distribute.experimental.rpc.kernels.gen_rpc_ops', 'tensorflow.distribute.experimental.rpc.proto', 'tensorflow.distribute.experimental.rpc.proto.tf_rpc_service_pb2', 'tensorflow.python.distribute.experimental.rpc.rpc_ops', 'tensorflow._api.v2.compat.v2.distribute.experimental.rpc', 'tensorflow.python.distribute.failure_handling', 'tensorflow.core.distributed_runtime', 'tensorflow.core.distributed_runtime.preemption', 'tensorflow.core.distributed_runtime.preemption.gen_check_preemption_op', 'tensorflow.python.distribute.failure_handling.failure_handling_util', 'tensorflow.python.distribute.failure_handling.failure_handling', 'tensorflow.python.distribute.failure_handling.preemption_watcher', 'tensorflow._api.v2.compat.v2.distribute.experimental', 'tensorflow._api.v2.compat.v2.distribute', 'tensorflow._api.v2.compat.v2.dtypes.experimental', 'tensorflow._api.v2.compat.v2.dtypes', 'tensorflow._api.v2.compat.v2.errors', 'tensorflow.python.dlpack', 'tensorflow.python.dlpack.dlpack', 'tensorflow._api.v2.compat.v2.experimental.dlpack', 'tensorflow.dtensor.python.save_restore', 'tensorflow.dtensor.python.d_checkpoint', 'tensorflow._api.v2.compat.v2.experimental.dtensor', 'tensorflow._api.v2.compat.v2.experimental.extension_type', 'tensorflow.python.ops.numpy_ops.np_array_ops', 'tensorflow.python.ops.numpy_ops.np_random', 'tensorflow._api.v2.compat.v2.experimental.numpy.random', 'tensorflow.python.ops.numpy_ops.np_math_ops', 'tensorflow.python.ops.weak_tensor_ops', 'tensorflow.python.ops.numpy_ops.np_config', 'tensorflow._api.v2.compat.v2.experimental.numpy', 'tensorflow._api.v2.compat.v2.experimental.tensorrt', 'tensorflow._api.v2.compat.v2.experimental', 'tensorflow._api.v2.compat.v2.feature_column', 'tensorflow._api.v2.compat.v2.graph_util', 'tensorflow._api.v2.compat.v2.image', 'tensorflow._api.v2.compat.v2.io.gfile', 'tensorflow._api.v2.compat.v2.io', 'tensorflow._api.v2.compat.v2.linalg.experimental', 'tensorflow._api.v2.compat.v2.linalg', 'tensorflow._api.v2.compat.v2.lite.experimental.authoring', 'tensorflow._api.v2.compat.v2.lite.experimental', 'tensorflow._api.v2.compat.v2.lite', 'tensorflow._api.v2.compat.v2.lookup.experimental', 'tensorflow._api.v2.compat.v2.lookup', 'tensorflow._api.v2.compat.v2.math.special', 'tensorflow._api.v2.compat.v2.math', 'tensorflow._api.v2.compat.v2.mlir.experimental', 'tensorflow._api.v2.compat.v2.mlir', 'tensorflow._api.v2.compat.v2.nest', 'tensorflow._api.v2.compat.v2.nn.experimental', 'tensorflow._api.v2.compat.v2.nn', 'tensorflow.python.profiler.profiler_client', 'tensorflow._api.v2.compat.v2.profiler.experimental.client', 'tensorflow._api.v2.compat.v2.profiler.experimental.server', 'tensorflow._api.v2.compat.v2.profiler.experimental', 'tensorflow._api.v2.compat.v2.profiler', 'tensorflow._api.v2.compat.v2.quantization.experimental', 'tensorflow._api.v2.compat.v2.quantization', 'tensorflow._api.v2.compat.v2.queue', 'tensorflow._api.v2.compat.v2.ragged', 'tensorflow._api.v2.compat.v2.random.experimental', 'tensorflow._api.v2.compat.v2.random', 'tensorflow._api.v2.compat.v2.raw_ops', 'tensorflow._api.v2.compat.v2.saved_model.experimental', 'tensorflow._api.v2.compat.v2.saved_model', 'tensorflow._api.v2.compat.v2.sets', 'tensorflow._api.v2.compat.v2.signal', 'tensorflow._api.v2.compat.v2.sparse', 'tensorflow._api.v2.compat.v2.strings', 'tensorflow._api.v2.compat.v2.summary.experimental', 'tensorflow._api.v2.compat.v2.summary', 'tensorflow._api.v2.compat.v2.sysconfig', 'tensorflow._api.v2.compat.v2.test.experimental', 'tensorflow.python.ops.gradient_checker_v2', 'tensorflow._api.v2.compat.v2.test', 'tensorflow._api.v2.compat.v2.tpu.experimental.embedding', 'tensorflow._api.v2.compat.v2.tpu.experimental', 'tensorflow._api.v2.compat.v2.tpu', 'tensorflow._api.v2.compat.v2.train.experimental', 'tensorflow._api.v2.compat.v2.train', 'tensorflow._api.v2.compat.v2.types.experimental.distributed', 'tensorflow._api.v2.compat.v2.types.experimental', 'tensorflow._api.v2.compat.v2.types', 'tensorflow._api.v2.compat.v2.version', 'tensorflow._api.v2.compat.v2.xla.experimental', 'tensorflow._api.v2.compat.v2.xla', 'tensorflow._api.v2.compat.v2.compat.v2', 'tensorflow._api.v2.compat.v2.compat', 'tensorflow._api.v2.compat.v2', 'tensorflow._api.v2.compat.v1.compat.v2', 'tensorflow._api.v2.compat.v1.compat', 'tensorflow._api.v2.compat.v1', 'tensorflow._api.v2.compat', 'tensorflow._api.v2.config.experimental', 'tensorflow._api.v2.config.optimizer', 'tensorflow._api.v2.config.threading', 'tensorflow._api.v2.config', 'tensorflow._api.v2.data.experimental.service', 'tensorflow._api.v2.data.experimental', 'tensorflow._api.v2.data', 'tensorflow._api.v2.debugging.experimental', 'tensorflow._api.v2.debugging', 'tensorflow._api.v2.distribute.cluster_resolver', 'tensorflow._api.v2.distribute.coordinator', 'tensorflow._api.v2.distribute.experimental.coordinator', 'tensorflow._api.v2.distribute.experimental.partitioners', 'tensorflow._api.v2.distribute.experimental.rpc', 'tensorflow._api.v2.distribute.experimental', 'tensorflow._api.v2.distribute', 'tensorflow._api.v2.dtypes.experimental', 'tensorflow._api.v2.dtypes', 'tensorflow._api.v2.errors', 'tensorflow._api.v2.experimental.dlpack', 'tensorflow._api.v2.experimental.dtensor', 'tensorflow._api.v2.experimental.extension_type', 'tensorflow._api.v2.experimental.numpy.random', 'tensorflow._api.v2.experimental.numpy', 'tensorflow._api.v2.experimental.tensorrt', 'tensorflow._api.v2.experimental', 'tensorflow._api.v2.feature_column', 'tensorflow._api.v2.graph_util', 'tensorflow._api.v2.image', 'tensorflow._api.v2.io.gfile', 'tensorflow._api.v2.io', 'tensorflow._api.v2.linalg.experimental', 'tensorflow._api.v2.linalg', 'tensorflow._api.v2.lite.experimental.authoring', 'tensorflow._api.v2.lite.experimental', 'tensorflow._api.v2.lite', 'tensorflow._api.v2.lookup.experimental', 'tensorflow._api.v2.lookup', 'tensorflow._api.v2.math.special', 'tensorflow._api.v2.math', 'tensorflow._api.v2.mlir.experimental', 'tensorflow._api.v2.mlir', 'tensorflow._api.v2.nest', 'tensorflow._api.v2.nn.experimental', 'tensorflow._api.v2.nn', 'tensorflow._api.v2.profiler.experimental.client', 'tensorflow._api.v2.profiler.experimental.server', 'tensorflow._api.v2.profiler.experimental', 'tensorflow._api.v2.profiler', 'tensorflow._api.v2.quantization.experimental', 'tensorflow._api.v2.quantization', 'tensorflow._api.v2.queue', 'tensorflow._api.v2.ragged', 'tensorflow._api.v2.random.experimental', 'tensorflow._api.v2.random', 'tensorflow._api.v2.raw_ops', 'tensorflow._api.v2.saved_model.experimental', 'tensorflow._api.v2.saved_model', 'tensorflow._api.v2.sets', 'tensorflow._api.v2.signal', 'tensorflow._api.v2.sparse', 'tensorflow._api.v2.strings', 'tensorflow._api.v2.summary.experimental', 'tensorflow._api.v2.summary', 'tensorflow._api.v2.sysconfig', 'tensorflow._api.v2.test.experimental', 'tensorflow._api.v2.test', 'tensorflow._api.v2.tpu.experimental.embedding', 'tensorflow._api.v2.tpu.experimental', 'tensorflow._api.v2.tpu', 'tensorflow._api.v2.train.experimental', 'tensorflow._api.v2.train', 'tensorflow._api.v2.types.experimental.distributed', 'tensorflow._api.v2.types.experimental', 'tensorflow._api.v2.types', 'tensorflow._api.v2.version', 'tensorflow._api.v2.xla.experimental', 'tensorflow._api.v2.xla', 'namex.convert', 'namex.export', 'namex.generate', 'namex', 'keras.src.api_export', 'keras.src.backend.config', 'keras.src.backend.common.backend_utils', 'keras.src.backend.common.global_state', 'keras.src.backend.common.name_scope', 'keras.src.backend.common.stateless_scope', 'keras.src.utils.module_utils', 'optree._C', 'optree.accessor', 'optree.dataclasses', 'optree.typing', 'optree.utils', 'optree.registry', 'optree.ops', 'optree.functools', 'optree.integration', 'optree.version', 'optree', 'keras.src.tree.optree_impl', 'keras.src.tree.tree_api', 'keras.src.tree', 'keras.src.utils.io_utils', 'keras.src.utils.dataset_utils', 'keras.src.utils.audio_dataset_utils', 'keras.src.utils.progbar', 'keras.src.utils.file_utils', 'PIL._version', 'PIL', 'PIL.ExifTags', 'PIL._deprecate', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._typing', 'PIL._util', 'xml.parsers', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'xml.parsers.expat', 'defusedxml.common', 'defusedxml', 'xml.etree', 'xml.etree.ElementPath', '_elementtree', 'xml.etree.ElementTree', 'defusedxml.ElementTree', 'PIL._imaging', 'PIL.Image', 'keras.src.utils.image_utils', 'keras.src.utils.image_dataset_utils', 'pydotplus.parser', 'pydotplus.graphviz', 'pydotplus', 'keras.src.utils.model_visualization', 'keras.src.utils.numerical_utils', 'keras.src.utils.python_utils', 'keras.src.utils.rng_utils', 'keras.src.utils.sequence_utils', 'keras.src.utils.text_dataset_utils', 'keras.src.utils.timeseries_dataset_utils', 'keras.src.utils', 'keras.src.utils.naming', 'keras.src.backend.common.variables', 'keras.src.backend.common.dtypes', 'keras.src.random.random', 'keras.src.utils.jax_utils', 'keras.src.random.seed_generator', 'keras.src.random', 'keras.src.backend.common', 'keras.src.backend.common.keras_tensor', 'keras.src.backend.common.symbolic_scope', 'keras.src.backend.tensorflow.sparse', 'keras.src.backend.tensorflow.core', 'tensorflow.experimental', 'keras.src.backend.tensorflow.distribution_lib', 'keras.src.backend.tensorflow.image', 'keras.src.backend.tensorflow.linalg', 'keras.src.backend.tensorflow.math', 'keras.src.backend.tensorflow.nn', 'keras.src.backend.tensorflow.numpy', 'keras.src.backend.tensorflow.random', 'keras.src.backend.tensorflow.tensorboard', 'keras.src.backend.tensorflow.rnn', 'keras.src.backend.tensorflow', 'keras.src.backend', 'keras.src.dtype_policies.dtype_policy', 'keras.src.dtype_policies.dtype_policy_map', 'keras.src.dtype_policies', 'keras.src.ops.symbolic_arguments', 'keras.src.ops.node', 'keras.src.utils.traceback_utils', 'keras.src.ops.operation', 'keras.src.ops.operation_utils', 'keras.src.ops.image', 'keras.src.ops.core', 'keras.src.ops.linalg', 'keras.src.ops.math', 'keras.src.ops.nn', 'keras.src.ops.numpy', 'keras.src.ops', 'keras.src.activations.activations', 'keras.src.saving.object_registration', 'keras.src.legacy', 'keras.src.legacy.saving', 'keras.src.initializers.initializer', 'keras.src.saving.serialization_lib', 'keras.src.initializers.constant_initializers', 'keras.src.initializers.random_initializers', 'keras.src.initializers', 'keras.src.optimizers.schedules.learning_rate_schedule', 'keras.src.optimizers.schedules', 'keras.src.saving.keras_saveable', 'keras.src.utils.tracking', 'keras.src.optimizers.base_optimizer', 'keras.src.backend.tensorflow.trackable', 'keras.src.backend.tensorflow.optimizer', 'keras.src.optimizers.optimizer', 'keras.src.optimizers.adadelta', 'keras.src.optimizers.adafactor', 'keras.src.optimizers.adagrad', 'keras.src.optimizers.adam', 'keras.src.optimizers.adamax', 'keras.src.optimizers.adamw', 'keras.src.optimizers.ftrl', 'keras.src.optimizers.lion', 'keras.src.optimizers.loss_scale_optimizer', 'keras.src.optimizers.nadam', 'keras.src.optimizers.rmsprop', 'keras.src.optimizers.sgd', 'keras.src.optimizers', 'keras.src.legacy.saving.serialization', 'keras.src.legacy.saving.json_utils', 'keras.src.legacy.saving.saving_options', 'keras.src.constraints.constraints', 'keras.src.constraints', 'keras.src.regularizers.regularizers', 'keras.src.regularizers', 'keras.src.distribution.distribution_lib', 'keras.src.distribution', 'keras.src.layers.input_spec', 'keras.src.losses.loss', 'keras.src.losses.losses', 'keras.src.losses', 'keras.src.metrics.metric', 'keras.src.metrics.reduction_metrics', 'keras.src.metrics.accuracy_metrics', 'keras.src.metrics.metrics_utils', 'keras.src.metrics.confusion_metrics', 'keras.src.metrics.f_score_metrics', 'keras.src.metrics.hinge_metrics', 'keras.src.metrics.iou_metrics', 'keras.src.metrics.probabilistic_metrics', 'keras.src.metrics.regression_metrics', 'keras.src.metrics', 'rich._extension', 'rich', 'rich._null_file', 'rich.errors', 'colorsys', 'rich.color_triplet', 'rich.palette', 'rich._palettes', 'rich.repr', 'rich.terminal_theme', 'rich.color', 'rich.style', 'rich.default_styles', 'rich.theme', 'rich.themes', 'rich._emoji_codes', 'rich._emoji_replace', 'rich._export_format', 'rich._fileno', 'rich._loop', 'rich._pick', 'rich._cell_widths', 'rich.cells', 'rich._wrap', 'rich.segment', 'rich.jupyter', 'rich.protocol', 'rich.measure', 'rich.constrain', 'rich.align', 'rich.containers', 'rich.control', 'rich.emoji', 'rich.text', 'rich._log_render', 'rich.highlighter', 'rich.markup', 'rich.pager', 'attr._compat', 'attr._config', 'attr.exceptions', 'attr.setters', 'attr._make', 'attr.converters', 'attr.filters', 'attr.validators', 'attr._cmp', 'attr._funcs', 'attr._next_gen', 'attr._version_info', 'attr', 'rich.abc', 'rich.pretty', 'rich.region', 'rich.box', 'rich.padding', 'rich.panel', 'rich._ratio', 'rich.table', 'rich.scope', 'rich.screen', 'rich.styled', 'rich.console', 'keras.src.utils.dtype_utils', 'keras.src.utils.summary_utils', 'keras.src.utils.tf_utils', 'keras.src.backend.tensorflow.layer', 'keras.src.layers.layer', 'keras.src.layers.activations.elu', 'keras.src.layers.activations.leaky_relu', 'keras.src.layers.activations.prelu', 'keras.src.layers.activations.relu', 'keras.src.layers.activations.softmax', 'keras.src.layers.activations', 'keras.src.layers.activations.activation', 'keras.src.layers.attention', 'keras.src.layers.attention.attention', 'keras.src.layers.attention.additive_attention', 'keras.src.layers.core', 'keras.src.quantizers.quantizers', 'keras.src.quantizers', 'keras.src.layers.core.einsum_dense', 'keras.src.layers.regularization', 'keras.src.layers.regularization.dropout', 'keras.src.layers.attention.grouped_query_attention', 'keras.src.layers.attention.multi_head_attention', 'keras.src.layers.convolutional', 'keras.src.utils.argument_validation', 'keras.src.layers.convolutional.base_conv', 'keras.src.layers.convolutional.conv1d', 'keras.src.layers.convolutional.base_conv_transpose', 'keras.src.layers.convolutional.conv1d_transpose', 'keras.src.layers.convolutional.conv2d', 'keras.src.layers.convolutional.conv2d_transpose', 'keras.src.layers.convolutional.conv3d', 'keras.src.layers.convolutional.conv3d_transpose', 'keras.src.layers.convolutional.base_depthwise_conv', 'keras.src.layers.convolutional.depthwise_conv1d', 'keras.src.layers.convolutional.depthwise_conv2d', 'keras.src.layers.convolutional.base_separable_conv', 'keras.src.layers.convolutional.separable_conv1d', 'keras.src.layers.convolutional.separable_conv2d', 'keras.src.layers.core.dense', 'keras.src.layers.core.embedding', 'keras.src.layers.core.identity', 'keras.src.layers.core.input_layer', 'keras.src.layers.core.lambda_layer', 'keras.src.layers.core.masking', 'keras.src.layers.core.wrapper', 'keras.src.layers.merging', 'keras.src.layers.merging.base_merge', 'keras.src.layers.merging.add', 'keras.src.layers.merging.average', 'keras.src.layers.merging.concatenate', 'keras.src.layers.merging.dot', 'keras.src.layers.merging.maximum', 'keras.src.layers.merging.minimum', 'keras.src.layers.merging.multiply', 'keras.src.layers.merging.subtract', 'keras.src.layers.normalization', 'keras.src.layers.normalization.batch_normalization', 'keras.src.layers.normalization.group_normalization', 'keras.src.layers.normalization.layer_normalization', 'keras.src.layers.normalization.spectral_normalization', 'keras.src.layers.normalization.unit_normalization', 'keras.src.layers.pooling', 'keras.src.layers.pooling.base_pooling', 'keras.src.layers.pooling.average_pooling1d', 'keras.src.layers.pooling.average_pooling2d', 'keras.src.layers.pooling.average_pooling3d', 'keras.src.layers.pooling.base_global_pooling', 'keras.src.layers.pooling.global_average_pooling1d', 'keras.src.layers.pooling.global_average_pooling2d', 'keras.src.layers.pooling.global_average_pooling3d', 'keras.src.layers.pooling.global_max_pooling1d', 'keras.src.layers.pooling.global_max_pooling2d', 'keras.src.layers.pooling.global_max_pooling3d', 'keras.src.layers.pooling.max_pooling1d', 'keras.src.layers.pooling.max_pooling2d', 'keras.src.layers.pooling.max_pooling3d', 'keras.src.layers.preprocessing', 'keras.src.utils.backend_utils', 'keras.src.layers.preprocessing.tf_data_layer', 'keras.src.layers.preprocessing.audio_preprocessing', 'keras.src.layers.preprocessing.category_encoding', 'keras.src.layers.preprocessing.center_crop', 'keras.src.layers.preprocessing.discretization', 'keras.src.layers.preprocessing.hashed_crossing', 'keras.src.layers.preprocessing.hashing', 'keras.src.layers.preprocessing.index_lookup', 'keras.src.layers.preprocessing.integer_lookup', 'keras.src.layers.preprocessing.normalization', 'keras.src.layers.preprocessing.random_brightness', 'keras.src.layers.preprocessing.random_contrast', 'keras.src.layers.preprocessing.random_crop', 'keras.src.layers.preprocessing.random_flip', 'keras.src.layers.preprocessing.random_rotation', 'keras.src.layers.preprocessing.random_translation', 'keras.src.layers.preprocessing.random_zoom', 'keras.src.layers.preprocessing.rescaling', 'keras.src.layers.preprocessing.resizing', 'keras.src.layers.preprocessing.string_lookup', 'keras.src.layers.preprocessing.text_vectorization', 'keras.src.layers.regularization.activity_regularization', 'keras.src.layers.regularization.alpha_dropout', 'keras.src.layers.regularization.gaussian_dropout', 'keras.src.layers.regularization.gaussian_noise', 'keras.src.layers.regularization.spatial_dropout', 'keras.src.layers.reshaping', 'keras.src.layers.reshaping.cropping1d', 'keras.src.layers.reshaping.cropping2d', 'keras.src.layers.reshaping.cropping3d', 'keras.src.layers.reshaping.flatten', 'keras.src.layers.reshaping.permute', 'keras.src.layers.reshaping.repeat_vector', 'keras.src.layers.reshaping.reshape', 'keras.src.layers.reshaping.up_sampling1d', 'keras.src.layers.reshaping.up_sampling2d', 'keras.src.layers.reshaping.up_sampling3d', 'keras.src.layers.reshaping.zero_padding1d', 'keras.src.layers.reshaping.zero_padding2d', 'keras.src.layers.reshaping.zero_padding3d', 'keras.src.layers.rnn', 'keras.src.layers.rnn.bidirectional', 'keras.src.layers.rnn.dropout_rnn_cell', 'keras.src.layers.rnn.stacked_rnn_cells', 'keras.src.layers.rnn.rnn', 'keras.src.layers.rnn.conv_lstm', 'keras.src.layers.rnn.conv_lstm1d', 'keras.src.layers.rnn.conv_lstm2d', 'keras.src.layers.rnn.conv_lstm3d', 'keras.src.layers.rnn.gru', 'keras.src.layers.rnn.lstm', 'keras.src.layers.rnn.simple_rnn', 'keras.src.layers.rnn.time_distributed', 'keras.src.layers', 'keras.src.trainers', 'keras.src.trainers.compile_utils', 'keras.src.version', 'psutil._common', 'psutil._compat', 'psutil._psposix', 'psutil._psutil_linux', 'psutil._psutil_posix', 'resource', 'psutil._pslinux', 'psutil', 'huggingface_hub', 'keras.src.saving.saving_lib', 'keras.src.models.variable_mapping', 'keras.src.trainers.data_adapters.data_adapter_utils', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'pytz', 'dateutil._version', 'dateutil', 'pandas._typing', 'pandas.compat._constants', 'pandas.compat.compressors', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas.util._exceptions', 'pandas.util.version', 'pandas.compat._optional', 'zoneinfo._tzpath', 'zoneinfo._common', '_zoneinfo', 'zoneinfo', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.tz.tz', 'dateutil.tz', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.ccalendar', '_strptime', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config', 'pandas._config.localization', 'pandas._libs.tslibs.fields', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil._common', 'dateutil.relativedelta', 'pandas._libs.properties', 'pandas._libs.tslibs.offsets', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'dateutil.parser', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.tslibs', 'pandas._libs.ops_dispatch', 'pandas._libs.missing', 'pandas._libs.hashtable', 'pandas._libs.algos', 'pandas._libs.interval', 'pandas._libs', 'pandas.util._decorators', 'pandas.core', 'pandas.core.util', 'pandas._libs.lib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.base', 'pandas.core.dtypes.inference', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.common', 'pandas.core.util.hashing', 'pandas.util', 'pandas.compat.numpy', 'pyarrow._generated_version', '_cython_3_0_10', 'pyarrow.util', 'pyarrow.lib', 'pyarrow.ipc', 'pyarrow.types', 'pyarrow', 'pandas.compat.pyarrow', 'pandas.compat', 'pandas._libs.tslib', 'pandas.core.config_init', 'pandas.core.dtypes.missing', 'pandas.io', 'pandas.io._util', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.astype', 'pandas.core.dtypes.concat', 'pandas.core.array_algos', 'pandas.core.common', 'pandas.core.construction', 'pandas.core.array_algos.take', 'pandas.core.indexers.utils', 'pandas.core.indexers', 'pandas.core.algorithms', 'pandas.util._validators', 'pandas.core.roperator', 'pandas._libs.ops', 'pandas.core.computation', 'numexpr.interpreter', 'numexpr.expressions', 'numexpr.version', 'numexpr.utils', 'numexpr.necompiler', 'numexpr', 'pandas.core.computation.check', 'pandas.core.computation.expressions', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.array_ops', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.ops', 'pandas.core.arraylike', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.core.array_algos.quantile', 'pandas.core.sorting', 'pandas.core.arrays.base', 'pandas.core.strings', 'pandas.core.strings.base', 'pandas.tseries', 'pandas.tseries.frequencies', 'pyarrow._compute', 'pyarrow._compute_docstrings', 'pyarrow.vendored', 'pydoc', 'pyarrow.vendored.docscrape', 'pyarrow.compute', 'pandas.core.arrays.arrow._arrow_utils', 'pandas.core.arrays.arrow.dtype', 'pandas.core.arrays.arrow.array', 'pandas.core.arrays.arrow', 'pandas.core.array_algos.masked_accumulations', 'bottleneck.benchmark', 'bottleneck.benchmark.autotimeit', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck.slow', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'bottleneck', 'pandas.core.nanops', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arrays.masked', 'pandas.core.arrays.boolean', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.array_algos.transforms', 'pandas.core.arrays._mixins', 'pandas.core.base', 'pandas.core.strings.object_array', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.categorical', 'pandas.core.array_algos.datetimelike_accumulations', 'pandas.core.arrays.numeric', 'pandas.core.arrays.integer', 'pandas.core.arrays.datetimelike', 'pandas.core.arrays._ranges', 'pandas.tseries.offsets', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.floating', 'pandas.core.arrays.timedeltas', 'pandas.core.arrays.interval', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.arrays.sparse.array', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays', 'pandas.core.flags', 'pandas._libs.reduction', 'pandas.core.apply', 'pandas._libs.indexing', 'pandas.core.indexes', 'pandas._libs.index', 'pandas._libs.internals', 'pandas._libs.join', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.strings.accessor', 'pandas.core.indexes.base', 'pandas.core.indexes.extension', 'pandas.core.indexes.category', 'pandas.core.indexes.range', 'pandas.core.tools', 'pandas.core.tools.timedeltas', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.times', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.interval', 'pandas.core.indexes.period', 'pandas.core.indexes.api', 'pandas.core.indexing', 'pandas.core.sample', 'pandas.core.array_algos.replace', 'pandas._libs.writers', 'pandas.core.internals.blocks', 'pandas.core.internals.api', 'pandas.core.internals.base', 'pandas.core.internals.array_manager', 'pandas.core.internals.ops', 'pandas.core.internals.managers', 'pandas.core.internals.concat', 'pandas.core.internals', 'pandas.core.internals.construction', 'pandas.core.methods', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.shared_docs', 'pandas.io.common', 'pandas.io.formats.format', 'pandas.core.methods.describe', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas._libs.window.indexers', 'pandas.core.indexers.objects', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core._numba', 'pandas.core._numba.executor', 'pandas.core.window.rolling', 'pandas.core.window.ewm', 'pandas.core.window.expanding', 'pandas.core.window', 'pandas.core.generic', 'pandas.core.methods.selectn', 'pandas.core.reshape.util', 'pandas.core.tools.numeric', 'pandas.core.reshape.melt', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.arrays', 'pandas.core.tools.datetimes', 'pandas.io.formats.info', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.plotting', 'pandas.core.series', 'pandas.core.frame', 'pandas.core.groupby.base', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.categorical', 'pandas.core.groupby.grouper', 'pandas.core.groupby.ops', 'pandas.core.groupby.indexing', 'pandas.core.groupby.groupby', 'pandas.core.groupby.generic', 'pandas.core.groupby', 'pandas.core.api', 'pandas.tseries.api', 'pandas.core.computation.common', 'pandas.core.computation.align', 'pandas.core.computation.scope', 'pandas.core.computation.ops', 'pandas.core.computation.engines', 'pandas.core.computation.parsing', 'pandas.core.computation.expr', 'pandas.core.computation.eval', 'pandas.core.computation.api', 'pandas.core.reshape.encoding', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.tile', 'pandas.core.reshape.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.core.interchange', 'pandas.core.interchange.dataframe_protocol', 'pandas.core.dtypes.api', 'pandas.api.types', 'pandas.core.interchange.utils', 'pandas.core.interchange.from_dataframe', 'pandas.api.interchange', 'pandas.api', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._io', 'pandas._testing._warnings', 'pandas._libs.testing', 'pandas._testing.asserters', 'pandas._testing.compat', 'pandas._testing', 'pandas.testing', 'pandas.util._print_versions', 'pandas.io.clipboards', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers.base_parser', 'pandas.io.parsers.arrow_parser_wrapper', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.parsers.readers', 'pandas.io.parsers', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._base', 'pandas._libs.json', 'pandas.io.excel._odswriter', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.json._json', 'pandas.io.json', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.compat.pickle_compat', 'pandas.io.pickle', 'pandas.core.computation.pytables', 'pandas.io.pytables', 'pandas.io.sas.sasreader', 'pandas.io.sas', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.io.api', 'pandas.util._tester', 'pandas._version', 'pandas', 'keras.src.trainers.data_adapters.array_slicing', 'keras.src.trainers.data_adapters.data_adapter', 'keras.src.trainers.data_adapters.array_data_adapter', 'keras.src.trainers.data_adapters.py_dataset_adapter', 'keras.src.trainers.data_adapters.generator_data_adapter', 'keras.src.trainers.data_adapters.tf_dataset_adapter', 'keras.src.trainers.data_adapters.torch_data_loader_adapter', 'keras.src.trainers.data_adapters', 'keras.src.trainers.trainer', 'keras.src.callbacks.callback', 'keras.src.callbacks.backup_and_restore', 'keras.src.callbacks.history', 'keras.src.callbacks.progbar_logger', 'keras.src.callbacks.callback_list', 'keras.src.callbacks.csv_logger', 'keras.src.callbacks.early_stopping', 'keras.src.callbacks.lambda_callback', 'keras.src.callbacks.learning_rate_scheduler', 'keras.src.callbacks.model_checkpoint', 'keras.src.callbacks.reduce_lr_on_plateau', 'keras.src.callbacks.remote_monitor', 'keras.src.callbacks.swap_ema_weights', 'keras.src.callbacks.tensorboard', 'keras.src.callbacks.terminate_on_nan', 'keras.src.callbacks', 'keras.src.trainers.epoch_iterator', 'keras.src.backend.tensorflow.trainer', 'keras.src.models.model', 'keras.src.ops.function', 'keras.src.models.functional', 'keras.src.models.sequential', 'keras.src.models', 'keras.src.legacy.saving.saving_utils', 'keras.src.legacy.saving.legacy_h5_format', 'keras.src.saving.saving_api', 'keras.src.saving', 'keras.src.activations', 'keras.src.applications', 'keras.src.datasets.boston_housing', 'keras.src.datasets.california_housing', 'keras.src.datasets.cifar', 'keras.src.datasets.cifar10', 'keras.src.datasets.cifar100', 'keras.src.datasets.fashion_mnist', 'keras.src.datasets.imdb', 'keras.src.datasets.mnist', 'keras.src.datasets.reuters', 'keras.src.datasets', 'keras.src', 'keras.api.activations', 'keras.src.applications.imagenet_utils', 'keras.src.applications.convnext', 'keras.api.applications.convnext', 'keras.src.applications.densenet', 'keras.api.applications.densenet', 'keras.src.applications.efficientnet', 'keras.api.applications.efficientnet', 'keras.src.applications.efficientnet_v2', 'keras.api.applications.efficientnet_v2', 'keras.api.applications.imagenet_utils', 'keras.src.applications.inception_resnet_v2', 'keras.api.applications.inception_resnet_v2', 'keras.src.applications.inception_v3', 'keras.api.applications.inception_v3', 'keras.src.applications.mobilenet', 'keras.api.applications.mobilenet', 'keras.src.applications.mobilenet_v2', 'keras.api.applications.mobilenet_v2', 'keras.src.applications.mobilenet_v3', 'keras.api.applications.mobilenet_v3', 'keras.src.applications.nasnet', 'keras.api.applications.nasnet', 'keras.src.applications.resnet', 'keras.api.applications.resnet', 'keras.api.applications.resnet50', 'keras.src.applications.resnet_v2', 'keras.api.applications.resnet_v2', 'keras.src.applications.vgg16', 'keras.api.applications.vgg16', 'keras.src.applications.vgg19', 'keras.api.applications.vgg19', 'keras.src.applications.xception', 'keras.api.applications.xception', 'keras.api.applications', 'keras.api.backend', 'keras.api.callbacks', 'keras.api.config', 'keras.api.constraints', 'keras.api.datasets.boston_housing', 'keras.api.datasets.california_housing', 'keras.api.datasets.cifar10', 'keras.api.datasets.cifar100', 'keras.api.datasets.fashion_mnist', 'keras.api.datasets.imdb', 'keras.api.datasets.mnist', 'keras.api.datasets.reuters', 'keras.api.datasets', 'keras.api.distribution', 'keras.api.dtype_policies', 'keras.src.export.export_lib', 'keras.src.export', 'keras.api.export', 'keras.api.initializers', 'keras.src.utils.jax_layer', 'keras.src.utils.torch_utils', 'keras.api.layers', 'keras.api.legacy.saving', 'keras.api.legacy', 'keras.api.losses', 'keras.api.metrics', 'keras.api.mixed_precision', 'keras.src.models.cloning', 'keras.api.models', 'keras.api.ops.image', 'keras.api.ops.linalg', 'keras.api.ops.nn', 'keras.api.ops.numpy', 'keras.api.ops', 'keras.api.optimizers.legacy', 'keras.api.optimizers.schedules', 'keras.src.optimizers.lamb', 'keras.api.optimizers', 'keras.api.preprocessing.image', 'keras.api.preprocessing.sequence', 'keras.api.preprocessing', 'keras.api.quantizers', 'keras.api.random', 'keras.api.regularizers', 'keras.api.saving', 'keras.api.tree', 'keras.api.utils.legacy', 'keras.src.layers.preprocessing.feature_space', 'keras.api.utils', 'keras.src.backend.exports', 'keras.api', 'keras', 'tensorflow', 'torch.utils.tensorboard._embedding', 'torch.utils.tensorboard._onnx_graph', 'torch.utils.tensorboard._proto_graph', 'torch.utils.tensorboard._pytorch_graph', 'google.protobuf.struct_pb2', 'torch.utils.tensorboard.summary', 'torch.utils.tensorboard.writer', 'torch.utils.tensorboard', 'librosa.version', 'joblib.hashing', 'joblib.backports', 'joblib.disk', 'joblib.logger', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.numpy_pickle', 'joblib._store_backends', 'joblib.func_inspect', 'joblib.memory', 'joblib._multiprocessing_helpers', 'joblib.externals', 'joblib.externals.loky._base', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.process', 'multiprocessing.queues', 'concurrent.futures.process', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky', 'joblib._utils', 'joblib.externals.loky.backend.spawn', 'joblib.externals.loky.backend.resource_tracker', 'joblib._memmapping_reducer', 'joblib.pool', 'joblib.executor', 'joblib._parallel_backends', 'joblib.parallel', 'joblib._cloudpickle_wrapper', 'joblib', 'decorator', 'librosa._cache', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy._lib.doccer', 'scipy.ndimage._ni_docstrings', 'scipy.ndimage._filters', 'scipy.ndimage._fourier', 'scipy.special._sf_error', 'scipy.special._ufuncs_cxx', 'scipy.special._ufuncs', 'scipy.special._specfun', 'scipy.special._comb', 'scipy.special._basic', 'scipy.special._logsumexp', 'scipy.special._orthogonal', 'scipy.special._spfun_stats', 'scipy.special._ellip_harm_2', 'scipy.special._ellip_harm', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.special._add_newdocs', 'scipy.special.add_newdocs', 'scipy.special.basic', 'scipy.special.orthogonal', 'scipy.special.specfun', 'scipy.special.sf_error', 'scipy.special.spfun_stats', 'scipy.special', 'scipy.ndimage._interpolation', '_ni_label', 'scipy.ndimage._ni_label', 'scipy.ndimage._morphology', 'scipy.ndimage._measurements', 'scipy.ndimage.filters', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage.morphology', 'scipy.ndimage', 'numba._version', 'numba.misc', 'numba.misc.init_utils', 'numba.core', 'yaml.error', 'yaml.tokens', 'yaml.events', 'yaml.nodes', 'yaml.reader', 'yaml.scanner', 'yaml.parser', 'yaml.composer', 'yaml.constructor', 'yaml.resolver', 'yaml.loader', 'yaml.emitter', 'yaml.serializer', 'yaml.representer', 'yaml.dumper', 'yaml._yaml', 'yaml.cyaml', 'yaml', 'llvmlite._version', 'llvmlite', 'llvmlite.binding.common', 'llvmlite.utils', 'llvmlite.binding.ffi', 'llvmlite.binding.dylib', 'llvmlite.binding.targets', 'llvmlite.binding.object_file', 'llvmlite.binding.executionengine', 'llvmlite.binding.initfini', 'llvmlite.binding.linker', 'llvmlite.binding.typeref', 'llvmlite.binding.value', 'llvmlite.binding.context', 'llvmlite.binding.module', 'llvmlite.binding.options', 'llvmlite.binding.passmanagers', 'llvmlite.binding.transforms', 'llvmlite.binding.analysis', 'llvmlite.binding.orcjit', 'llvmlite.binding', 'numba.core.config', 'numba.core.utils', 'numba.core.types.abstract', 'numba.core.errors', 'numba.core.types.common', 'numba.core.typeconv.castgraph', 'numba.core.typeconv', 'numba.core.consts', 'numba.core.ir', 'numba.core.types.misc', 'numba.core.types.containers', 'numba.core.types.functions', 'numba.core.types.iterators', 'llvmlite.ir._utils', 'llvmlite.ir.types', 'llvmlite.ir.values', 'llvmlite.ir.context', 'llvmlite.ir.module', 'llvmlite.ir.instructions', 'llvmlite.ir.builder', 'llvmlite.ir.transforms', 'llvmlite.ir', 'numba.core.types.npytypes', 'numba.np', 'numba.np.npdatetime_helpers', 'numba.core.types.scalars', 'numba.core.types.function_type', 'numba.core.types', 'numba.core.typeconv._typeconv', 'numba.core.typeconv.typeconv', 'numba.core.typeconv.rules', 'numba.core.targetconfig', 'numba.core.cpu_options', 'numba.core.typing.templates', 'numba.core.datamodel.manager', 'numba.core.datamodel.packer', 'numba.core.datamodel.registry', 'numba.core.datamodel.models', 'numba.core.datamodel', 'numba.core.debuginfo', 'numba.core.cgutils', 'numba.np.numpy_support', 'numba.core.typing.typeof', 'numba.core.typing.context', 'numba.core.typing', 'numba.core.typing.asnumbatype', 'numba.misc.special', 'numba.stencils', 'numba.core.imputils', 'numba._helperlib', 'numba.core.itanium_mangler', 'numba.core.funcdesc', 'numba.core.generators', 'numba.core.removerefctpass', 'numba._dynfunc', 'numba.core.environment', 'numba.core.controlflow', 'numba.core.analysis', 'numba.misc.firstlinefinder', 'numba.core.lowering', 'numba.cloudpickle.cloudpickle', 'numba.cloudpickle', 'numba.core.serialize', 'numba.core.pythonapi', 'numba.core.extending', 'numba.core.transforms', 'numba.core.postproc', 'numba.core.rewrites.registry', 'numba.core.rewrites.static_getitem', 'numba.core.rewrites.static_raise', 'numba.core.rewrites.static_binop', 'numba.core.rewrites.ir_print', 'numba.core.rewrites', 'numba.core.ir_utils', 'numba.core.descriptors', 'numba._devicearray', 'numba._dispatcher', 'numba.core.tracing', 'numba.core.byteflow', 'numba.core.unsafe', 'numba.core.unsafe.eh', 'numba.cpython', 'numba.cpython.unsafe', 'numba.cpython.unsafe.tuple', 'numba.core.interpreter', 'numba.core.bytecode', 'numba.core.event', 'numba.core.compiler_lock', 'numba.core.typeinfer', 'numba.stencils.stencilparfor', 'numba.core.typing.npydecl', 'numba.parfors.array_analysis', 'numba.parfors.parfor', 'numba.core.sigutils', 'numba.parfors.parfor_lowering_utils', 'numba.parfors.parfor_lowering', 'numba.parfors', 'numba.core.typing.builtins', 'numba.extending', 'numba.cpython.builtins', 'numba.core.base', 'numba.core.callconv', 'numba.core.callwrapper', 'numba.core.llvm_bindings', 'numba.core.runtime.nrtdynmod', 'numba.core.runtime._nrt_python', 'numba.core.runtime.nrt', 'numba.core.runtime', 'numba.core.runtime.nrtopt', 'numba.misc.inspection', 'numba.misc.llvm_pass_timings', 'numba.core.codegen', 'numba.core.intrinsics', 'numba.core.externals', 'numba.core.fastmathpass', 'numba.core.options', 'numba.core.entrypoints', 'numba.np.ufunc_db', 'numba.core.cpu', 'numba.core.compiler_machinery', 'numba.core.ssa', 'numba.core.untyped_passes', 'numba.core.annotations', 'numba.core.annotations.type_annotations', 'numba.core.typed_passes', 'numba.core.pylowering', 'numba.core.object_mode_passes', 'numba.core.compiler', 'numba.misc.appdirs', 'numba.core.caching', 'numba.core.dispatcher', 'numba.core.registry', 'numba.stencils.stencil', 'numba.core.decorators', 'numba.np.ufunc._internal', 'numba.np.ufunc.wrappers', 'numba.core.target_extension', 'numba.np.ufunc.sigparse', 'numba.np.ufunc.ufuncbuilder', 'numba.np.ufunc.parallel', 'numba.np.ufunc.ufunc_base', 'numba.np.ufunc.dufunc', 'numba.np.ufunc.gufunc', 'numba.np.ufunc.decorators', 'numba.np.ufunc.array_exprs', 'numba.np.ufunc', 'numba.experimental.jitclass.decorators', 'numba.experimental.jitclass._box', 'numba.experimental.jitclass.boxing', 'numba.experimental.jitclass.overloads', 'numba.experimental.jitclass', 'numba.experimental', 'numba.core.withcontexts', 'numba.typed', 'numba', 'librosa.util.exceptions', 'librosa.util.deprecation', 'librosa.util.decorators', 'librosa.util.utils', 'plistlib', 'platformdirs.api', 'platformdirs.version', 'platformdirs.unix', 'platformdirs', 'pkg_resources', 'pooch.hashes', 'pooch.utils', 'ftplib', 'pooch.downloaders', 'pooch.core', 'pooch.processors', 'pooch._version', 'pooch', 'librosa.util.files', 'librosa.util.matching', 'scipy.optimize._minpack2', 'scipy.optimize._linesearch', 'scipy.optimize._group_columns', 'scipy.optimize._numdiff', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._differentiable_functions', 'scipy.optimize._optimize', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion_ncg', 'scipy._lib.messagestream', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trlib', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trustregion_exact', 'numpy.testing._private', 'numpy.linalg.lapack_lite', 'numpy.testing._private.utils', 'numpy.testing._private.extbuild', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'numpy.testing', 'scipy.optimize._constraints', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._trustregion_constr', 'scipy.optimize._lbfgsb', 'scipy.optimize._lbfgsb_py', '_moduleTNC', 'scipy.optimize._moduleTNC', 'scipy.optimize._tnc', 'scipy.optimize._cobyla', 'scipy.optimize._cobyla_py', 'scipy.optimize._slsqp', 'scipy.optimize._slsqp_py', 'scipy.optimize._minimize', 'scipy.optimize._minpack', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.bvls', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq', 'scipy.optimize._minpack_py', 'scipy.optimize._spectral', 'scipy.optimize._nonlin', 'scipy.optimize._root', 'scipy.optimize._zeros', 'scipy.optimize._zeros_py', 'scipy.optimize._root_scalar', 'scipy.optimize.__nnls', 'scipy.optimize._nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._highs', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._linprog_highs', 'scipy.linalg._interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg.interpolative', 'scipy.optimize._remove_redundancy', 'scipy.optimize._linprog_util', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_simplex', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_rs', 'scipy.optimize._linprog_doc', 'scipy.optimize._linprog', 'scipy.optimize._lsap', 'scipy.optimize._differentialevolution', 'scipy.spatial._ckdtree', 'scipy.spatial._kdtree', 'scipy.spatial._qhull', 'scipy.spatial._voronoi', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._plotutils', 'scipy.spatial._procrustes', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.spatial._distance_pybind', 'scipy.spatial.distance', 'scipy.spatial._geometric_slerp', 'scipy.spatial.ckdtree', 'scipy.spatial.kdtree', 'scipy.spatial.qhull', 'scipy.constants._codata', 'scipy.constants._constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.constants', 'scipy.spatial.transform._rotation_groups', 'scipy.spatial.transform._rotation', 'scipy.spatial.transform._rotation_spline', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform', 'scipy.spatial', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib._vertex', 'scipy.optimize._shgo_lib._complex', 'scipy.optimize._shgo', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.optimize._direct', 'scipy.optimize._direct_py', 'scipy.optimize._milp', 'scipy.optimize.cobyla', 'scipy.optimize.lbfgsb', 'scipy.optimize.linesearch', 'scipy.optimize.minpack', 'scipy.optimize.minpack2', 'scipy.optimize.moduleTNC', 'scipy.optimize.nonlin', 'scipy.optimize.optimize', 'scipy.optimize.slsqp', 'scipy.optimize.tnc', 'scipy.optimize.zeros', 'scipy.optimize', 'librosa.util._nnls', 'librosa.util', 'librosa.core.notation', 'librosa.core.convert', 'ctypes.util', '_soundfile', '_soundfile_data', 'soundfile', 'audioread.exceptions', 'audioread.base', 'audioread.ffdec', 'audioread.version', 'audioread', 'scipy.signal._sigtools', 'scipy._lib._uarray._uarray', 'scipy._lib._uarray._backend', 'scipy._lib._uarray', 'scipy._lib.uarray', 'scipy.fft._basic', 'scipy.fft._realtransforms', 'scipy.fft._fftlog', 'scipy.fft._fftlog_multimethods', 'scipy.fft._pocketfft.pypocketfft', 'scipy.fft._pocketfft.helper', 'scipy.fft._pocketfft.basic', 'scipy.fft._pocketfft.realtransforms', 'scipy.fft._pocketfft', 'scipy.fft._helper', 'scipy.fft._backend', 'scipy.fft', 'scipy.signal.windows._windows', 'scipy.signal.windows.windows', 'scipy.signal.windows', 'scipy.signal._waveforms', 'scipy.signal._max_len_seq_inner', 'scipy.signal._max_len_seq', 'scipy.signal._upfirdn_apply', 'scipy.signal._upfirdn', 'scipy.signal._spline', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._bspl', 'scipy.interpolate._bsplines', 'scipy.interpolate._fitpack_py', 'scipy.interpolate._polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.interpnd', 'scipy.interpolate._interpolate', 'scipy.interpolate._fitpack2', 'scipy.interpolate._rbf', 'scipy.interpolate._rbfinterp_pythran', 'scipy.interpolate._rbfinterp', 'scipy.interpolate._cubic', 'scipy.interpolate._ndgriddata', 'scipy.interpolate._pade', 'scipy.interpolate._rgi_cython', 'scipy.interpolate._rgi', 'scipy.interpolate.fitpack', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpolate', 'scipy.interpolate.ndgriddata', 'scipy.interpolate.polyint', 'scipy.interpolate.rbf', 'scipy.interpolate', 'scipy.signal._bsplines', 'scipy.signal._filter_design', 'scipy.signal._fir_filter_design', 'scipy.integrate._quadrature', 'scipy.integrate._odepack', 'scipy.integrate._odepack_py', 'scipy.integrate._quadpack', 'scipy.integrate._quadpack_py', 'scipy.integrate._vode', 'scipy.integrate._dop', 'scipy.integrate._lsoda', 'scipy.integrate._ode', 'scipy.integrate._bvp', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp', 'scipy.integrate._quad_vec', 'scipy.integrate.dop', 'scipy.integrate.lsoda', 'scipy.integrate.vode', 'scipy.integrate.odepack', 'scipy.integrate.quadpack', 'scipy.integrate', 'scipy.signal._lti_conversion', 'scipy.signal._ltisys', 'scipy.signal._arraytools', 'scipy.signal._sosfilt', 'scipy.signal._signaltools', 'scipy.signal._savitzky_golay', 'scipy.signal._spectral', 'scipy.signal._spectral_py', 'scipy.signal._wavelets', 'scipy.stats._warnings_errors', 'scipy.stats._distr_params', 'scipy._lib._finite_differences', 'scipy.stats._constants', 'scipy.stats._censored_data', 'scipy.stats._distn_infrastructure', 'scipy.special.cython_special', 'scipy.stats._stats', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats.beta_ufunc', 'scipy.stats._boost.beta_ufunc', 'scipy.stats.binom_ufunc', 'scipy.stats._boost.binom_ufunc', 'scipy.stats.nbinom_ufunc', 'scipy.stats._boost.nbinom_ufunc', 'scipy.stats.hypergeom_ufunc', 'scipy.stats._boost.hypergeom_ufunc', 'scipy.stats.ncf_ufunc', 'scipy.stats._boost.ncf_ufunc', 'scipy.stats.ncx2_ufunc', 'scipy.stats._boost.ncx2_ufunc', 'scipy.stats.nct_ufunc', 'scipy.stats._boost.nct_ufunc', 'scipy.stats.skewnorm_ufunc', 'scipy.stats._boost.skewnorm_ufunc', 'scipy.stats.invgauss_ufunc', 'scipy.stats._boost.invgauss_ufunc', 'scipy.stats._boost', 'scipy.stats._continuous_distns', 'scipy.stats._biasedurn', 'scipy.stats._discrete_distns', 'scipy.stats._levy_stable.levyst', 'scipy.stats._levy_stable', 'scipy.stats._entropy', 'scipy.stats.distributions', 'scipy._lib._bunch', 'scipy.stats._stats_pythran', 'scipy.stats._stats_mstats_common', 'scipy.stats._mstats_basic', 'scipy.stats._common', 'scipy.stats._hypotests', 'scipy._lib._docscrape', 'scipy.stats._axis_nan_policy', 'scipy.stats._resampling', 'scipy.stats._binomtest', 'scipy.stats._stats_py', 'scipy.stats._variation', 'scipy.stats._statlib', 'scipy.stats._fit', 'scipy.stats._relative_risk', 'scipy.stats._crosstab', 'scipy.stats._odds_ratio', 'scipy.stats.contingency', 'scipy.stats._morestats', 'scipy.stats._sobol', 'scipy.stats._qmc_cy', 'scipy.stats._qmc', 'scipy.stats._multicomp', 'scipy.stats._binned_statistic', 'scipy.stats._mvn', 'scipy.stats._kde', 'scipy.stats._mstats_extras', 'scipy.stats.mstats', 'scipy.stats.qmc', 'scipy.stats._covariance', 'scipy.stats._rcont.rcont', 'scipy.stats._rcont', 'scipy.stats._qmvnt', 'scipy.stats._multivariate', 'scipy.stats._rvs_sampling', 'scipy.stats._page_trend_test', 'scipy.stats._mannwhitneyu', 'scipy.stats._sensitivity_analysis', 'scipy.stats._survival', 'scipy.stats.biasedurn', 'scipy.stats.kde', 'scipy.stats.morestats', 'scipy.stats.mstats_basic', 'scipy.stats.mstats_extras', 'scipy.stats.mvn', 'scipy.stats.statlib', 'scipy.stats.stats', 'scipy.stats', 'scipy.signal._peak_finding_utils', 'scipy.signal._peak_finding', 'scipy.signal._czt', 'scipy.signal.bsplines', 'scipy.signal.filter_design', 'scipy.signal.fir_filter_design', 'scipy.signal.lti_conversion', 'scipy.signal.ltisys', 'scipy.signal.spectral', 'scipy.signal.signaltools', 'scipy.signal.waveforms', 'scipy.signal.wavelets', 'scipy.signal.spline', 'scipy.signal', 'resampy.version', 'resampy.filters', 'numba.misc.quicksort', 'numba.misc.mergesort', 'numba.cpython.slicing', 'numba.np.arrayobj', 'numba.np.npdatetime', 'numba.np.math', 'numba.cpython.unsafe.numbers', 'numba.cpython.mathimpl', 'numba.np.math.cmathimpl', 'numba.np.math.mathimpl', 'numba.np.math.numbers', 'numba.np.npyfuncs', 'numba.np.npyimpl', 'resampy.interpn', 'resampy.core', 'resampy', 'librosa.core.fft', 'encodings.cp437', 'librosa.core.audio', 'librosa.filters', 'librosa.core.spectrum', 'librosa.sequence', 'librosa.core.pitch', 'librosa.core.constantq', 'librosa.core.harmonic', 'librosa.core', 'librosa.feature.utils', 'scipy.fftpack._helper', 'scipy.fftpack._basic', 'scipy.fftpack.convolve', 'scipy.fftpack._pseudo_diffs', 'scipy.fftpack._realtransforms', 'scipy.fftpack.basic', 'scipy.fftpack.helper', 'scipy.fftpack.pseudo_diffs', 'scipy.fftpack.realtransforms', 'scipy.fftpack', 'librosa.feature.spectral', 'librosa.feature.rhythm', 'librosa.feature.inverse', 'librosa.feature', 'librosa.onset', 'librosa.beat', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build._check_build', 'sklearn.__check_build', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.utils.deprecation', 'sklearn.exceptions', 'threadpoolctl', 'sklearn.externals', 'sklearn.externals._packaging', 'sklearn.externals._packaging._structures', 'sklearn.externals._packaging.version', 'sklearn.utils.fixes', 'sklearn.utils._estimator_html_repr', 'sklearn.utils.validation', 'sklearn.utils', 'sklearn.utils._tags', 'sklearn.base', 'sklearn.utils._openmp_helpers', 'sklearn.utils._show_versions', 'sklearn', '_cython_0_29_26', 'sklearn.decomposition._cdnmf_fast', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', 'sklearn.utils.extmath', 'sklearn.decomposition._nmf', 'sklearn.decomposition._base', 'sklearn.utils._arpack', 'sklearn.decomposition._pca', 'sklearn.decomposition._incremental_pca', 'sklearn.preprocessing._function_transformer', 'sklearn.utils.sparsefuncs', 'sklearn.utils._mask', 'sklearn.utils._encode', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._data', 'sklearn.utils.multiclass', 'sklearn.preprocessing._label', 'sklearn.preprocessing._discretization', 'sklearn.utils.stats', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._polynomial', 'sklearn.preprocessing', 'sklearn.metrics._base', 'sklearn.metrics._ranking', 'sklearn.metrics._classification', 'sklearn.utils._typedefs', 'sklearn.utils._readonly_array_wrapper', 'sklearn.metrics._dist_metrics', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.pairwise', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics.cluster', 'sklearn._loss', 'sklearn._loss.glm_distribution', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.det_curve', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.metrics', 'sklearn.decomposition._kernel_pca', 'sklearn.utils._random', 'sklearn.utils._seq_dataset', 'sklearn.linear_model._base', 'sklearn.linear_model._bayes', 'sklearn.utils._cython_blas', 'sklearn.utils.arrayfuncs', 'sklearn.model_selection._split', 'sklearn.utils.metaestimators', 'sklearn.model_selection._validation', 'sklearn.utils.random', 'sklearn.model_selection._search', 'sklearn.model_selection', 'sklearn.linear_model._least_angle', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._coordinate_descent', 'sklearn.utils.optimize', 'sklearn.linear_model._glm.link', 'sklearn.linear_model._glm.glm', 'sklearn.linear_model._glm', 'sklearn.linear_model._huber', 'sklearn.utils._weight_vector', 'sklearn.linear_model._sgd_fast', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._sag', 'sklearn.linear_model._ridge', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._base', 'sklearn.svm._classes', 'sklearn.svm._bounds', 'sklearn.svm', 'sklearn.linear_model._logistic', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._quantile', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.linear_model', 'sklearn.decomposition._dict_learning', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._online_lda_fast', 'sklearn.decomposition._lda', 'sklearn.decomposition', 'sklearn.neighbors._partition_nodes', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._distance_metric', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._graph', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.neighbors', 'sklearn.manifold._locally_linear', 'sklearn.utils.graph', 'sklearn.manifold._isomap', 'sklearn._isotonic', 'sklearn.isotonic', 'sklearn.manifold._mds', 'sklearn.manifold._spectral_embedding', 'sklearn.manifold._utils', 'sklearn.tree._utils', 'sklearn.tree._tree', 'sklearn.tree._splitter', 'sklearn.tree._criterion', 'sklearn.tree._classes', 'sklearn.tree._reingold_tilford', 'sklearn.tree._export', 'sklearn.tree', 'sklearn.neighbors._quad_tree', 'sklearn.manifold._barnes_hut_tsne', 'sklearn.manifold._t_sne', 'sklearn.manifold', 'sklearn.cluster._k_means_common', 'sklearn.cluster._k_means_minibatch', 'sklearn.cluster._k_means_lloyd', 'sklearn.cluster._k_means_elkan', 'sklearn.cluster._kmeans', 'sklearn.cluster._spectral', 'sklearn.cluster._mean_shift', 'sklearn.cluster._affinity_propagation', 'sklearn.utils._fast_dict', 'sklearn.cluster._hierarchical_fast', 'sklearn.cluster._feature_agglomeration', 'sklearn.cluster._agglomerative', 'sklearn.cluster._dbscan_inner', 'sklearn.cluster._dbscan', 'sklearn.cluster._optics', 'sklearn.cluster._bicluster', 'sklearn.cluster._birch', 'sklearn.cluster', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction._stop_words', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction', 'librosa.segment', 'librosa.decompose', 'librosa.effects', 'librosa', 'commons', 'scipy.io.matlab._byteordercodes', 'scipy.io.matlab._miobase', 'scipy.io.matlab._mio_utils', 'scipy.io.matlab._mio4', 'scipy.io.matlab._streams', 'scipy.io.matlab._mio5_params', 'scipy.io.matlab._mio5_utils', 'scipy.io.matlab._mio5', 'scipy.io.matlab._mio', 'scipy.io.matlab.mio', 'scipy.io.matlab.mio5', 'scipy.io.matlab.mio5_params', 'scipy.io.matlab.mio4', 'scipy.io.matlab.byteordercodes', 'scipy.io.matlab.miobase', 'scipy.io.matlab.mio_utils', 'scipy.io.matlab.streams', 'scipy.io.matlab.mio5_utils', 'scipy.io.matlab', 'scipy.io._netcdf', 'scipy.io._fortran', 'scipy.io._mmio', 'scipy.io._idl', 'scipy.io._harwell_boeing._fortran_format_parser', 'scipy.io._harwell_boeing.hb', 'scipy.io._harwell_boeing', 'scipy.io.arff._arffread', 'scipy.io.arff.arffread', 'scipy.io.arff', 'scipy.io.harwell_boeing', 'scipy.io.idl', 'scipy.io.mmio', 'scipy.io.netcdf', 'scipy.io.wavfile', 'scipy.io', 'regex._regex', 'regex._regex_core', 'regex.regex', 'regex', 'utils', 'torchaudio._internal', 'torchaudio._internal.module_utils', 'torchaudio._extension.utils', 'torchaudio.lib', 'torchaudio.lib._torchaudio', 'torchaudio._extension', 'torio._extension.utils', 'torio._extension', 'torio.io._streaming_media_decoder', 'torio.io._streaming_media_encoder', 'torio.io', 'torio.utils.ffmpeg_utils', 'torio.utils', 'torio', 'torchaudio.io._effector', 'torchaudio.io._playback', 'torchaudio.io', 'torchaudio._backend.common', 'torchaudio._backend.soundfile_backend', 'torchaudio._backend.backend', 'torchaudio._backend.ffmpeg', 'torchaudio._backend.soundfile', 'torchaudio._backend.sox', 'torchaudio._backend.utils', 'torio.lib', 'torio.lib._torio_ffmpeg4', 'torchaudio._backend', 'torchaudio.compliance.kaldi', 'torchaudio.compliance', 'torchaudio.datasets.utils', 'torchaudio.datasets.cmuarctic', 'torchaudio.datasets.cmudict', 'torchaudio.datasets.commonvoice', 'torchaudio.datasets.dr_vctk', 'torchaudio.datasets.fluentcommands', 'torchaudio.datasets.gtzan', 'torchaudio.datasets.iemocap', 'torchaudio.datasets.librispeech', 'torchaudio.datasets.librilight_limited', 'torchaudio.datasets.librimix', 'torchaudio.datasets.librispeech_biasing', 'torchaudio.datasets.libritts', 'torchaudio.datasets.ljspeech', 'torchaudio.datasets.musdb_hq', 'torchaudio.datasets.quesst14', 'torchaudio.datasets.snips', 'torchaudio.datasets.speechcommands', 'torchaudio.datasets.tedlium', 'torchaudio.datasets.vctk', 'torchaudio.datasets.voxceleb1', 'torchaudio.datasets.yesno', 'torchaudio.datasets', 'torchaudio.functional._alignment', 'torchaudio.functional.filtering', 'torchaudio.functional.functional', 'torchaudio.functional', 'torchaudio.kaldi_io', 'torchaudio.models._hdemucs', 'torchaudio.models.conformer', 'torchaudio.models.conv_tasnet', 'torchaudio.models.deepspeech', 'torchaudio.models.emformer', 'torchaudio.models.rnnt', 'torchaudio.models.rnnt_decoder', 'torchaudio.models.squim.objective', 'torchaudio.models.squim.subjective', 'torchaudio.models.squim', 'torchaudio.models.tacotron2', 'torchaudio.models.wav2letter', 'torchaudio.models.wav2vec2.wavlm_attention', 'torchaudio.models.wav2vec2.components', 'torchaudio.models.wav2vec2.model', 'torchaudio.models.wav2vec2.utils.import_fairseq', 'torchaudio.models.wav2vec2.utils.import_huggingface', 'torchaudio.models.wav2vec2.utils', 'torchaudio.models.wav2vec2', 'torchaudio.models.wavernn', 'torchaudio.models', 'torchaudio.pipelines._source_separation_pipeline', 'torchaudio.pipelines._squim_pipeline', 'torchaudio.transforms._multi_channel', 'torchaudio.transforms._transforms', 'torchaudio.transforms', 'torchaudio.pipelines._tts.utils', 'torchaudio.pipelines._tts.interface', 'torchaudio.pipelines._tts.impl', 'torchaudio.pipelines._tts', 'torchaudio.pipelines._wav2vec2', 'torchaudio.pipelines._wav2vec2.aligner', 'torchaudio.pipelines._wav2vec2.utils', 'torchaudio.pipelines._wav2vec2.impl', 'torchaudio.pipelines.rnnt_pipeline', 'torchaudio.pipelines', 'torchaudio.utils.sox_utils', 'torchaudio.utils.download', 'torchaudio.utils', 'torchaudio.sox_effects.sox_effects', 'torchaudio.sox_effects', 'torchaudio.backend.common', 'torchaudio.backend.no_backend', 'torchaudio.backend.soundfile_backend', 'torchaudio.backend.sox_io_backend', 'torchaudio.backend', 'torchaudio.version', 'torchaudio', 'mel_processing', 'unidecode', 'tqdm.autonotebook', 'tqdm.asyncio', 'tqdm.auto', 'pyopenjtalk.version', 'pyopenjtalk.htsengine', '_cython_0_29_34', 'pyopenjtalk.openjtalk', 'pyopenjtalk.utils', 'pyopenjtalk', 'text.japanese', 'jamo.jamo', 'jamo', 'ko_pron.data', 'ko_pron.ko_pron', 'ko_pron', 'text.korean', 'pypinyin.compat', 'pypinyin.pinyin_dict', 'pypinyin.phrases_dict', 'pypinyin.constants', 'pypinyin.contrib', 'pypinyin.contrib.uv', 'pypinyin.style', 'pypinyin.style._tone_rule', 'pypinyin.contrib._tone_rule', 'pypinyin.contrib.neutral_tone', 'pypinyin.phonetic_symbol', 'pypinyin.style._constants', 'pypinyin.standard', 'pypinyin.style._utils', 'pypinyin.style.tone', 'pypinyin.style._tone_convert', 'pypinyin.contrib.tone_convert', 'pypinyin.contrib.tone_sandhi', 'pypinyin.seg', 'pypinyin.seg.mmseg', 'pypinyin.seg.simpleseg', 'pypinyin.utils', 'pypinyin.style.initials', 'pypinyin.style.finals', 'pypinyin.style.bopomofo', 'pypinyin.style.cyrillic', 'pypinyin.style.wadegiles', 'pypinyin.style.others', 'pypinyin.converter', 'pypinyin.core', 'pypinyin', 'jieba._compat', 'jieba.finalseg.prob_start', 'jieba.finalseg.prob_trans', 'jieba.finalseg.prob_emit', 'jieba.finalseg', 'jieba', 'proces.conf', 'proces.preprocess', 'proces.util', 'proces.data', 'proces.data.province_city', 'proces.util.data', 'proces.masking', 'proces', 'cn2an.conf', 'cn2an.an2cn', 'cn2an.cn2an', 'cn2an.transform', 'cn2an', 'text.mandarin', 'indic_transliteration', 'toml.tz', 'toml.decoder', 'toml.encoder', 'toml', 'indic_transliteration.sanscript.schemes', 'indic_transliteration.sanscript.schemes.roman', 'indic_transliteration.sanscript.schemes.brahmic', 'indic_transliteration.sanscript', 'text.sanskrit', 'typeguard._config', 'typeguard._exceptions', 'typeguard._memo', 'typeguard._utils', 'typeguard._checkers', 'typeguard._suppression', 'typeguard._functions', 'typeguard._transformer', 'typeguard._decorators', 'typeguard._importhook', 'typeguard', 'inflect.compat', 'inflect.compat.py38', 'inflect', 'eng_to_ipa.syllables', 'eng_to_ipa.stress', 'eng_to_ipa.transcribe', 'eng_to_ipa.rhymes', '_sqlite3', 'sqlite3.dbapi2', 'sqlite3', 'eng_to_ipa.transcriber', 'eng_to_ipa', 'text.english', 'num_thai', 'num_thai.thainumbers', 'text.thai', 'text.cleaners', 'text.symbols', 'text', 'data_utils', 'transforms', 'modules', 'attentions', 'monotonic_align.monotonic_align', 'monotonic_align.core', 'monotonic_align.monotonic_align.core', 'monotonic_align', 'models', 'losses', '_lsprof', 'profile', 'cProfile', 'pstats', 'torch._dynamo.config', 'torch._dynamo.distributed', 'torch._functorch.config', 'torch.fx.experimental._config', 'torch.fx.experimental.recording', 'torch.utils._sympy', 'mpmath.usertools', 'mpmath.libmp.backend', 'mpmath.libmp.libintmath', 'mpmath.libmp.libmpf', 'mpmath.libmp.libelefun', 'mpmath.libmp.libmpc', 'mpmath.libmp.gammazeta', 'mpmath.libmp.libhyper', 'mpmath.libmp.libmpi', 'mpmath.libmp', 'mpmath.functions.functions', 'mpmath.functions.factorials', 'mpmath.functions.hypergeometric', 'mpmath.functions.expintegrals', 'mpmath.functions.bessel', 'mpmath.functions.orthogonal', 'mpmath.functions.theta', 'mpmath.functions.elliptic', 'mpmath.functions.signals', 'mpmath.functions.zeta', 'mpmath.functions.rszeta', 'mpmath.functions.zetazeros', 'mpmath.functions.qfunctions', 'mpmath.functions', 'mpmath.calculus.calculus', 'mpmath.calculus.approximation', 'mpmath.calculus.differentiation', 'mpmath.calculus.extrapolation', 'mpmath.calculus.polynomials', 'mpmath.calculus', 'mpmath.calculus.quadrature', 'mpmath.calculus.inverselaplace', 'mpmath.calculus.optimization', 'mpmath.calculus.odes', 'mpmath.matrices.eigen', 'mpmath.matrices.eigen_symmetric', 'mpmath.matrices', 'mpmath.matrices.matrices', 'mpmath.matrices.calculus', 'mpmath.matrices.linalg', 'mpmath.identification', 'mpmath.visualization', 'mpmath.ctx_base', 'mpmath.math2', 'mpmath.function_docs', 'mpmath.ctx_fp', 'mpmath.rational', 'mpmath.ctx_mp_python', 'mpmath.ctx_mp', 'mpmath.ctx_iv', 'mpmath', 'sympy.release', 'sympy.utilities.enumerative', 'sympy.utilities.misc', 'sympy.utilities.exceptions', 'sympy.utilities.decorator', 'sympy.utilities.iterables', 'sympy.external.importtools', 'sympy.external', 'sympy.utilities.lambdify', 'sympy.utilities.timeutils', 'sympy.utilities', 'sympy.core.random', 'sympy.core.cache', 'sympy.core.parameters', 'sympy.core.logic', 'sympy.core.facts', 'sympy.core.assumptions_generated', 'sympy.core.assumptions', 'sympy.core.sorting', 'sympy.multipledispatch.utils', 'sympy.multipledispatch.conflict', 'sympy.multipledispatch.dispatcher', 'sympy.multipledispatch.core', 'sympy.multipledispatch', 'sympy.core.kind', 'sympy.core._print_helpers', 'sympy.core.core', 'sympy.core.singleton', 'sympy.core.traversal', 'sympy.core.basic', 'sympy.core.sympify', 'sympy.external.pythonmpq', 'sympy.external.ntheory', 'sympy.external.gmpy', 'sympy.core.evalf', 'sympy.core.decorators', 'sympy.core.intfunc', 'sympy.core.operations', 'sympy.core.containers', 'sympy.core.add', 'sympy.core.rules', 'sympy.logic.boolalg', 'sympy.logic.inference', 'sympy.logic', 'sympy.core.symbol', 'sympy.core.function', 'sympy.core.relational', 'sympy.core.power', 'sympy.core.numbers', 'sympy.core.mul', 'sympy.core.coreerrors', 'sympy.core.exprtools', 'sympy.core.mod', 'sympy.core.expr', 'sympy.core.multidimensional', 'sympy.core', 'sympy.utilities.source', 'sympy.assumptions.assume', 'sympy.assumptions.cnf', 'sympy.assumptions.ask_generated', 'sympy.assumptions.ask', 'sympy.assumptions.refine', 'sympy.assumptions.relation.binrel', 'sympy.assumptions.relation', 'sympy.assumptions', 'sympy.polys.polyerrors', 'sympy.polys.polyoptions', 'sympy.polys.domains.domainelement', 'sympy.polys.orderings', 'sympy.polys.domains.modularinteger', 'sympy.polys.polyutils', 'sympy.polys.domains.domain', 'sympy.polys.domains.ring', 'sympy.polys.domains.field', 'sympy.polys.domains.simpledomain', 'sympy.polys.polyconfig', 'sympy.polys.galoistools', 'sympy.polys.domains.pythonrational', 'sympy.polys.domains.groundtypes', 'sympy.polys.domains.finitefield', 'sympy.polys.domains.characteristiczero', 'sympy.polys.domains.integerring', 'sympy.polys.domains.rationalfield', 'sympy.polys.monomials', 'sympy.polys.densebasic', 'sympy.polys.densearith', 'sympy.polys.densetools', 'sympy.polys.euclidtools', 'sympy.polys.sqfreetools', 'sympy.polys.factortools', 'sympy.polys.rootisolation', 'sympy.polys.polyclasses', 'sympy.polys.domains.algebraicfield', 'sympy.polys.domains.gaussiandomains', 'sympy.polys.domains.mpelements', 'sympy.polys.domains.realfield', 'sympy.polys.domains.complexfield', 'sympy.polys.domains.compositedomain', 'sympy.polys.domains.polynomialring', 'sympy.polys.domains.fractionfield', 'sympy.polys.domains.expressiondomain', 'sympy.polys.domains.expressionrawdomain', 'sympy.polys.domains.pythonintegerring', 'sympy.polys.domains.pythonfinitefield', 'sympy.polys.domains.gmpyintegerring', 'sympy.polys.domains.gmpyfinitefield', 'sympy.polys.domains.pythonrationalfield', 'sympy.polys.domains.gmpyrationalfield', 'sympy.polys.domains', 'sympy.polys.constructor', 'sympy.polys.fglmtools', 'sympy.polys.groebnertools', 'sympy.polys.rationaltools', 'sympy.polys.polytools', 'sympy.ntheory.primetest', 'sympy.ntheory.generate', 'sympy.ntheory.digits', 'sympy.ntheory.ecm', 'sympy.ntheory.factor_', 'sympy.ntheory.modular', 'sympy.utilities.memoization', 'sympy.ntheory.residue_ntheory', 'sympy.ntheory.partitions_', 'sympy.ntheory.multinomial', 'sympy.ntheory.continued_fraction', 'sympy.ntheory.egyptian_fraction', 'sympy.ntheory.qs', 'sympy.ntheory', 'sympy.polys.compatibility', 'sympy.polys.heuristicgcd', 'sympy.printing.conventions', 'sympy.printing.precedence', 'sympy.printing.printer', 'sympy.printing.str', 'sympy.core.alphabets', 'sympy.printing.pretty.pretty_symbology', 'sympy.printing.pretty.stringpict', 'sympy.printing.pretty.pretty', 'sympy.printing.pretty', 'sympy.printing.latex', 'sympy.printing.mathml', 'sympy.printing.repr', 'sympy.printing.python', 'sympy.functions.combinatorial', 'sympy.functions.combinatorial.factorials', 'sympy.functions.elementary', 'sympy.functions.elementary.miscellaneous', 'sympy.functions.elementary.piecewise', 'sympy.functions.elementary.complexes', 'sympy.functions.elementary.exponential', 'sympy.polys.appellseqs', 'sympy.functions.combinatorial.numbers', 'sympy.functions.elementary.integers', 'sympy.functions.elementary._trigonometric_special', 'sympy.functions.elementary.trigonometric', 'sympy.functions.elementary.hyperbolic', 'sympy.functions.special', 'sympy.functions.special.hyper', 'sympy.functions.special.error_functions', 'sympy.functions.special.zeta_functions', 'sympy.functions.special.gamma_functions', 'sympy.functions.special.tensor_functions', 'sympy.polys.polyquinticconst', 'sympy.polys.polyroots', 'sympy.functions.special.delta_functions', 'sympy.functions.special.singularity_functions', 'sympy.sets.sets', 'sympy.sets.fancysets', 'sympy.sets.contains', 'sympy.sets.conditionset', 'sympy.sets.ordinals', 'sympy.sets.powerset', 'sympy.sets.handlers', 'sympy.sets.handlers.comparison', 'sympy.sets', 'sympy.functions.special.bsplines', 'sympy.polys.orthopolys', 'sympy.functions.special.bessel', 'sympy.functions.special.polynomials', 'sympy.functions.special.spherical_harmonics', 'sympy.functions.special.elliptic_integrals', 'sympy.functions.special.beta_functions', 'sympy.functions.special.mathieu_functions', 'sympy.functions', 'sympy.printing.codeprinter', 'sympy.printing.pycode', 'sympy.assumptions.relation.equality', 'sympy.printing.smtlib', 'sympy.printing.glsl', 'sympy.printing.rcode', 'sympy.printing.jscode', 'sympy.printing.julia', 'sympy.printing.mathematica', 'sympy.printing.octave', 'sympy.printing.rust', 'sympy.utilities.mathml', 'sympy.printing.gtk', 'sympy.printing.preview', 'sympy.printing.tree', 'sympy.printing.tableform', 'sympy.printing.dot', 'sympy.printing.maple', 'sympy.printing', 'sympy.printing.defaults', 'sympy.utilities.magic', 'sympy.polys.rings', 'sympy.polys.specialpolys', 'sympy.polys.polyfuncs', 'sympy.polys.ring_series', 'sympy.polys.rootoftools', 'sympy.polys.numberfields.minpoly', 'sympy.polys.numberfields.subfield', 'sympy.polys.matrices.exceptions', 'sympy.polys.matrices.domainscalar', 'sympy.polys.matrices._typing', 'sympy.polys.matrices.dense', 'sympy.polys.matrices.lll', 'sympy.polys.matrices.sdm', 'sympy.polys.matrices.dfm', 'sympy.polys.matrices.ddm', 'sympy.polys.matrices.rref', 'sympy.polys.matrices.domainmatrix', 'sympy.polys.matrices', 'sympy.printing.numpy', 'sympy.printing.lambdarepr', 'sympy.polys.numberfields.utilities', 'sympy.polys.matrices.normalforms', 'sympy.polys.numberfields.exceptions', 'sympy.polys.numberfields.modules', 'sympy.polys.numberfields.basis', 'sympy.polys.numberfields.primes', 'sympy.polys.numberfields.galois_resolvents', 'sympy.polys.numberfields.galoisgroups', 'sympy.polys.numberfields', 'sympy.matrices.exceptions', 'sympy.matrices.kind', 'sympy.matrices.utilities', 'sympy.matrices.determinant', 'sympy.matrices.decompositions', 'sympy.tensor.indexed', 'sympy.tensor.index_methods', 'sympy.tensor.functions', 'sympy.tensor.array.ndim_array', 'sympy.tensor.array.mutable_ndim_array', 'sympy.tensor.array.dense_ndim_array', 'sympy.tensor.array.sparse_ndim_array', 'sympy.tensor.array.arrayop', 'sympy.tensor.array.array_comprehension', 'sympy.tensor.array', 'sympy.tensor', 'sympy.matrices.reductions', 'sympy.polys.agca.ideals', 'sympy.polys.agca.modules', 'sympy.polys.agca.homomorphisms', 'sympy.polys.agca', 'sympy.polys.agca.extensions', 'sympy.polys.matrices.eigen', 'sympy.matrices.eigen', 'sympy.matrices.solvers', 'sympy.matrices.inverse', 'sympy.matrices.subspaces', 'sympy.matrices.graph', 'sympy.matrices.matrixbase', 'sympy.matrices.repmatrix', 'sympy.matrices.dense', 'sympy.matrices.sparse', 'sympy.matrices.sparsetools', 'sympy.strategies.util', 'sympy.strategies.rl', 'sympy.strategies.core', 'sympy.strategies.traverse', 'sympy.strategies.tools', 'sympy.strategies.branch.core', 'sympy.strategies.branch.traverse', 'sympy.strategies.branch.tools', 'sympy.strategies.branch', 'sympy.strategies', 'sympy.matrices.expressions._shape', 'sympy.matrices.expressions.special', 'sympy.matrices.expressions.matpow', 'sympy.matrices.expressions.inverse', 'sympy.matrices.expressions.transpose', 'sympy.matrices.expressions.permutation', 'sympy.matrices.expressions.matmul', 'sympy.matrices.expressions.matadd', 'sympy.matrices.expressions.determinant', 'sympy.matrices.expressions.matexpr', 'sympy.matrices.expressions.slice', 'sympy.matrices.expressions.trace', 'sympy.matrices.expressions.blockmatrix', 'sympy.matrices.expressions.companion', 'sympy.matrices.expressions.funcmatrix', 'sympy.matrices.expressions.adjoint', 'sympy.matrices.expressions.hadamard', 'sympy.matrices.expressions.diagonal', 'sympy.matrices.expressions.dotproduct', 'sympy.matrices.expressions.kronecker', 'sympy.matrices.expressions.sets', 'sympy.matrices.expressions', 'sympy.matrices.immutable', 'sympy.matrices', 'sympy.polys.partfrac', 'sympy.polys.fields', 'sympy.polys', 'sympy.series.order', 'sympy.calculus.euler', 'sympy.calculus.singularities', 'sympy.calculus.finite_diff', 'sympy.calculus.accumulationbounds', 'sympy.calculus.util', 'sympy.calculus', 'sympy.series.gruntz', 'sympy.series.limits', 'sympy.series.series', 'sympy.series.approximants', 'sympy.series.residues', 'sympy.series.sequences', 'sympy.series.series_class', 'sympy.series.fourier', 'sympy.discrete.transforms', 'sympy.discrete.convolutions', 'sympy.discrete', 'sympy.series.formal', 'sympy.series.limitseq', 'sympy.series', 'sympy.concrete.expr_with_limits', 'sympy.concrete.expr_with_intlimits', 'sympy.concrete.gosper', 'sympy.integrals.rationaltools', 'sympy.integrals.deltafunctions', 'sympy.integrals.meijerint', 'sympy.integrals.trigonometry', 'sympy.integrals.integrals', 'sympy.polys.domainmatrix', 'sympy.polys.solvers', 'sympy.polys.matrices.linsolve', 'sympy.integrals.laplace', 'sympy.integrals.transforms', 'sympy.integrals.singularityfunctions', 'sympy.integrals', 'sympy.concrete.summations', 'sympy.concrete.products', 'sympy.concrete', 'sympy.simplify.gammasimp', 'sympy.simplify.combsimp', 'sympy.simplify.cse_opts', 'sympy.simplify.powsimp', 'sympy.simplify.hyperexpand', 'sympy.simplify.sqrtdenest', 'sympy.simplify.radsimp', 'sympy.simplify.cse_main', 'sympy.strategies.tree', 'sympy.simplify.trigsimp', 'sympy.simplify.simplify', 'sympy.simplify.fu', 'sympy.simplify.epathtools', 'sympy.simplify.ratsimp', 'sympy.simplify', 'sympy.solvers.polysys', 'sympy.solvers.bivariate', 'sympy.solvers.solvers', 'sympy.solvers.solveset', 'sympy.solvers.diophantine.diophantine', 'sympy.solvers.diophantine', 'sympy.solvers.recurr', 'sympy.solvers.deutils', 'sympy.solvers.ode.riccati', 'sympy.solvers.ode.hypergeometric', 'sympy.solvers.ode.subscheck', 'sympy.solvers.ode.nonhomogeneous', 'sympy.solvers.pde', 'sympy.solvers.ode.lie_group', 'sympy.solvers.ode.single', 'sympy.solvers.ode.ode', 'sympy.solvers.ode.systems', 'sympy.solvers.ode', 'sympy.solvers.inequalities', 'sympy.solvers.decompogen', 'sympy.solvers.simplex', 'sympy.solvers', 'sympy.geometry.exceptions', 'sympy.sets.handlers.intersection', 'sympy.sets.handlers.union', 'sympy.geometry.entity', 'sympy.geometry.point', 'sympy.geometry.util', 'sympy.geometry.line', 'sympy.geometry.plane', 'sympy.geometry.polygon', 'sympy.geometry.ellipse', 'sympy.geometry.curve', 'sympy.geometry.parabola', 'sympy.geometry', 'sympy.parsing.sympy_parser', 'sympy.parsing', 'sympy.algebras.quaternion', 'sympy.algebras', 'sympy.plotting.backends', 'sympy.plotting.utils', 'sympy.plotting.intervalmath.interval_membership', 'sympy.plotting.intervalmath.interval_arithmetic', 'sympy.plotting.intervalmath.lib_interval', 'sympy.plotting.intervalmath', 'sympy.plotting.series', 'sympy.plotting.backends.base_backend', 'sympy.plotting.backends.matplotlibbackend.matplotlib', 'sympy.plotting.backends.matplotlibbackend', 'sympy.plotting.textplot', 'sympy.plotting.backends.textbackend.text', 'sympy.plotting.backends.textbackend', 'sympy.plotting.plotgrid', 'sympy.plotting.plot', 'sympy.plotting.plot_implicit', 'sympy.plotting.pygletplot', 'sympy.plotting', 'sympy.interactive.printing', 'sympy.interactive.session', 'sympy.interactive.traversal', 'sympy.interactive', 'sympy', 'torch.utils._sympy.numbers', 'torch.utils._sympy.functions', 'torch.utils._sympy.solve', 'torch.utils._sympy.interp', 'torch.utils._sympy.value_ranges', 'torch.utils._sympy.singleton_int', 'torch.utils._sympy.symbol', 'torch.fx.experimental.symbolic_shapes', 'torch.utils._triton', 'torch._numpy._casting_dicts', 'torch._numpy._dtypes_impl', 'torch._numpy._util', 'torch._numpy._dtypes', 'torch._numpy._normalizations', 'torch._numpy.fft', 'torch._numpy.linalg', 'torch._numpy.random', 'torch._numpy._funcs_impl', 'torch._numpy._reductions_impl', 'torch._numpy._funcs', 'torch._numpy._getlimits', 'torch._numpy._binary_ufuncs_impl', 'torch._numpy._unary_ufuncs_impl', 'torch._numpy._ufuncs', 'torch._numpy._ndarray', 'torch._numpy', 'triton.backends.driver', 'triton.backends.compiler', 'triton._C', 'triton._C.libtriton.ir', 'triton._C.libtriton.passes', 'triton._C.libtriton.passes.analysis', 'triton._C.libtriton.passes.common', 'triton._C.libtriton.passes.convert', 'triton._C.libtriton.passes.ttir', 'triton._C.libtriton.passes.ttgpuir', 'triton._C.libtriton.passes.llvmir', 'triton._C.libtriton.interpreter', 'triton._C.libtriton.llvm', 'triton._C.libtriton.nvidia', 'triton._C.libtriton.nvidia.passes', 'triton._C.libtriton.nvidia.passes.ttgpuir', 'triton._C.libtriton.nvidia.passes.ttnvgpuir', 'triton._C.libtriton.amd', 'triton._C.libtriton.amd.passes', 'triton._C.libtriton.amd.passes.ttgpuir', 'triton._C.libtriton', 'triton.runtime.build', 'triton.runtime.cache', 'triton.backends', 'triton.runtime.driver', 'triton.runtime.jit', 'triton.language.semantic', 'triton.language.core', 'triton.language.math', 'triton.language.extra.cuda.libdevice', 'triton.language.extra.cuda.utils', 'triton.language.extra.cuda', 'triton.language.extra.hip.libdevice', 'triton.language.extra.hip', 'triton.language.extra', 'triton.language.standard', 'triton.language.random', 'triton.language', 'triton.testing', 'triton.errors', 'triton.runtime.errors', 'triton.runtime.autotuner', 'triton.runtime', 'triton.compiler.errors', 'triton.compiler.code_generator', 'triton.compiler.compiler', 'triton.compiler', 'triton.tools', 'triton', 'torch._dynamo.utils', 'torch._dynamo.exc', 'torch._inductor.test_operators', 'torch._dynamo.bytecode_analysis', 'torch._dynamo.bytecode_transformation', 'torch._dynamo.resume_execution', 'torch._dynamo.current_scope_id', 'torch._dynamo.source', 'torch._dynamo.variables.base', 'torch.utils._device', 'torch._dynamo.mutation_guard', 'torch._functorch._aot_autograd.functional_utils', 'torch.testing._internal', 'torch.testing._internal.logging_tensor', 'torch.utils.checkpoint', 'torch._dynamo.external_utils', 'torch._dynamo.backends', 'torch._dynamo.backends.registry', 'torch._dynamo.code_context', 'torch._dynamo.types', 'torch._dynamo.hooks', 'torch._dynamo.eval_frame', 'torch._dynamo.guards', 'torch._dynamo.replay_record', 'torch._dynamo.variables.constant', 'torch._dynamo.device_interface', 'torch._dynamo.polyfills', 'torch.distributed._composable_state', 'torch.distributed._composable.contract', 'torch.distributed._composable.checkpoint_activation', 'torch.distributed.algorithms._checkpoint', 'torch.distributed.algorithms._checkpoint.checkpoint_wrapper', 'torch.distributed.fsdp.api', 'torch.distributed.fsdp._common_utils', 'torch.testing._internal.distributed', 'torch.testing._internal.distributed.fake_pg', 'torch.distributed._shard.common_op_utils', 'torch.distributed._shard.op_registry_utils', 'torch.distributed._shard.metadata', 'torch.distributed._shard.sharded_tensor.metadata', 'torch.distributed._shard.sharding_spec._internals', 'torch.distributed._shard.sharding_spec.api', 'torch.distributed._shard._utils', 'torch.distributed._shard.sharded_tensor.shard', 'torch.distributed._shard.sharded_tensor.utils', 'torch.distributed._shard.sharding_spec.chunk_sharding_spec', 'torch.distributed._shard.sharding_spec', 'torch.distributed.nn.functional', 'torch.distributed.nn.api', 'torch.distributed.nn.jit', 'torch.distributed.nn.jit.templates', 'torch.distributed.nn.jit.templates.remote_module_template', 'torch.distributed.nn.jit.instantiator', '_remote_module_non_scriptable', 'torch.distributed.nn.api.remote_module', 'torch.distributed.nn', 'torch.distributed._shard.sharded_tensor.reshard', 'torch.distributed._shard.sharded_tensor.api', 'torch.distributed._shard.sharded_tensor._ops.misc_ops', 'torch.distributed._shard.sharded_tensor._ops._common', 'torch.distributed._shard.sharded_tensor._ops.tensor_ops', 'torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops', 'torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops._common', 'torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.embedding', 'torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.embedding_bag', 'torch.distributed._shard.sharded_tensor._ops.binary_cmp', 'torch.distributed._shard.sharded_tensor._ops.init', 'torch.distributed._shard.sharded_tensor._ops', 'torch.distributed._shard.sharded_tensor', 'torch.distributed._shard.sharder', 'torch.distributed._shard.sharding_plan.api', 'torch.distributed._shard.sharding_plan', 'torch.distributed._shard.api', 'torch.distributed._shard', 'torch.distributed._functional_collectives_impl', 'torch.utils._cxx_pytree', 'torch.distributed._functional_collectives', 'torch.distributed.tensor._collective_utils', 'torch.distributed.tensor.placement_types', 'torch.distributed.tensor._dtensor_spec', 'torch.distributed.tensor._op_schema', 'torch.distributed.tensor._random', 'torch.distributed.tensor.device_mesh', 'torch.distributed.tensor._redistribute', 'torch.distributed.tensor._utils', 'torch.distributed.tensor._sharding_prop', 'torch.distributed.tensor._tp_conv', 'torch.distributed.tensor._dispatch', 'torch.distributed.tensor._api', 'torch.distributed.tensor._ops.utils', 'torch.distributed.tensor._ops._conv_ops', 'torch.distributed.tensor._ops._embedding_ops', 'torch.distributed.tensor._ops._experimental_ops', 'torch.distributed.tensor._ops._math_ops', 'torch.distributed.tensor._ops._einsum_strategy', 'torch.distributed.tensor._ops._matrix_ops', 'torch.distributed.tensor._ops._pointwise_ops', 'torch.distributed.tensor._ops._random_ops', 'torch.distributed.tensor._ops._common_rules', 'torch.distributed.tensor._ops._tensor_ops', 'torch.distributed.tensor._ops._view_ops', 'torch.distributed.tensor._ops', 'torch.distributed.tensor', 'torch.distributed.fsdp._shard_utils', 'torch.distributed.fsdp._fsdp_extensions', 'torch.distributed.fsdp._flat_param', 'torch.distributed.fsdp._traversal_utils', 'torch.distributed.algorithms._comm_hooks.default_hooks', 'torch.distributed.algorithms._comm_hooks', 'torch.distributed.fsdp._dynamo_utils', 'torch.distributed.fsdp._exec_order_utils', 'torch.distributed.fsdp._limiter_utils', 'torch.distributed.fsdp.wrap', 'torch.distributed.tensor.parallel._utils', 'torch.distributed.tensor.parallel.style', 'torch.distributed.tensor.parallel.api', 'torch.distributed.tensor.parallel.loss', 'torch.distributed.tensor.parallel', 'torch.distributed.tensor.parallel._data_parallel_utils', 'torch.distributed.tensor.parallel.fsdp', 'torch.distributed.fsdp._init_utils', 'torch.distributed.fsdp._runtime_utils', 'torch.distributed.fsdp._wrap_utils', 'torch.distributed._state_dict_utils', 'torch.distributed.fsdp._debug_utils', 'torch.distributed.fsdp._optim_utils', 'torch.distributed.fsdp._unshard_param_utils', 'torch.distributed.fsdp._state_dict_utils', 'torch.distributed.fsdp.fully_sharded_data_parallel', 'torch.distributed.fsdp', 'torch.distributed._composable.fully_shard', 'torch.distributed._composable.replicate', 'torch.distributed._composable', 'torch.distributed._composable.fsdp._fsdp_api', 'torch._dynamo.compiled_autograd', 'torch.distributed._composable.fsdp._fsdp_common', 'torch.distributed._composable.fsdp._fsdp_param', 'torch.distributed._composable.fsdp._fsdp_collectives', 'torch.distributed._composable.fsdp._fsdp_param_group', 'torch.distributed._composable.fsdp._fsdp_state', 'torch.distributed._composable.fsdp._fsdp_init', 'torch.distributed._composable.fsdp.fully_shard', 'torch.distributed._composable.fsdp', 'torch._higher_order_ops.triton_kernel_wrap', 'torch._dynamo.variables.functions', 'torch._dynamo.create_parameter_op', 'torch._dynamo.variables.dicts', 'torch._dynamo.variables.user_defined', 'torch._dynamo.variables.ctx_manager', 'torch._dynamo.variables.iter', 'torch._dynamo.variables.lists', 'torch._dynamo._trace_wrapped_higher_order_op', 'torch._dynamo.variables.tensor', 'torch._dynamo.variables.builtin', 'torch._dynamo.variables.distributed', 'torch.onnx._exporter_states', 'torch.onnx._internal', 'torch._prims.context', 'torch._prims.executor', 'torch.fx.passes.fake_tensor_prop', 'torch.onnx._internal.onnxruntime', 'torch.onnx.errors', 'torch.onnx._type_utils', 'torch.onnx._constants', 'torch.onnx._deprecation', 'torch.onnx._globals', 'torch.onnx._internal.registration', 'torch.onnx._internal.jit_utils', 'torch.onnx.symbolic_helper', 'torch.onnx._internal.diagnostics.infra.sarif._property_bag', 'torch.onnx._internal.diagnostics.infra.sarif._address', 'torch.onnx._internal.diagnostics.infra.sarif._multiformat_message_string', 'torch.onnx._internal.diagnostics.infra.sarif._artifact_content', 'torch.onnx._internal.diagnostics.infra.sarif._message', 'torch.onnx._internal.diagnostics.infra.sarif._artifact_location', 'torch.onnx._internal.diagnostics.infra.sarif._artifact', 'torch.onnx._internal.diagnostics.infra.sarif._region', 'torch.onnx._internal.diagnostics.infra.sarif._replacement', 'torch.onnx._internal.diagnostics.infra.sarif._artifact_change', 'torch.onnx._internal.diagnostics.infra.sarif._rectangle', 'torch.onnx._internal.diagnostics.infra.sarif._attachment', 'torch.onnx._internal.diagnostics.infra.sarif._location_relationship', 'torch.onnx._internal.diagnostics.infra.sarif._logical_location', 'torch.onnx._internal.diagnostics.infra.sarif._physical_location', 'torch.onnx._internal.diagnostics.infra.sarif._location', 'torch.onnx._internal.diagnostics.infra.sarif._tool_component_reference', 'torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_reference', 'torch.onnx._internal.diagnostics.infra.sarif._stack_frame', 'torch.onnx._internal.diagnostics.infra.sarif._stack', 'torch.onnx._internal.diagnostics.infra.sarif._web_request', 'torch.onnx._internal.diagnostics.infra.sarif._web_response', 'torch.onnx._internal.diagnostics.infra.sarif._thread_flow_location', 'torch.onnx._internal.diagnostics.infra.sarif._thread_flow', 'torch.onnx._internal.diagnostics.infra.sarif._code_flow', 'torch.onnx._internal.diagnostics.infra.sarif._reporting_configuration', 'torch.onnx._internal.diagnostics.infra.sarif._configuration_override', 'torch.onnx._internal.diagnostics.infra.sarif._exception', 'torch.onnx._internal.diagnostics.infra.sarif._notification', 'torch.onnx._internal.diagnostics.infra.sarif._invocation', 'torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_relationship', 'torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor', 'torch.onnx._internal.diagnostics.infra.sarif._translation_metadata', 'torch.onnx._internal.diagnostics.infra.sarif._tool_component', 'torch.onnx._internal.diagnostics.infra.sarif._tool', 'torch.onnx._internal.diagnostics.infra.sarif._conversion', 'torch.onnx._internal.diagnostics.infra.sarif._edge', 'torch.onnx._internal.diagnostics.infra.sarif._edge_traversal', 'torch.onnx._internal.diagnostics.infra.sarif._node', 'torch.onnx._internal.diagnostics.infra.sarif._graph', 'torch.onnx._internal.diagnostics.infra.sarif._fix', 'torch.onnx._internal.diagnostics.infra.sarif._graph_traversal', 'torch.onnx._internal.diagnostics.infra.sarif._result_provenance', 'torch.onnx._internal.diagnostics.infra.sarif._suppression', 'torch.onnx._internal.diagnostics.infra.sarif._result', 'torch.onnx._internal.diagnostics.infra.sarif._external_properties', 'torch.onnx._internal.diagnostics.infra.sarif._external_property_file_reference', 'torch.onnx._internal.diagnostics.infra.sarif._external_property_file_references', 'torch.onnx._internal.diagnostics.infra.sarif._run_automation_details', 'torch.onnx._internal.diagnostics.infra.sarif._special_locations', 'torch.onnx._internal.diagnostics.infra.sarif._version_control_details', 'torch.onnx._internal.diagnostics.infra.sarif._run', 'torch.onnx._internal.diagnostics.infra.sarif._sarif_log', 'torch.onnx._internal.diagnostics.infra.sarif', 'torch.onnx._internal.diagnostics.infra.formatter', 'torch.onnx._internal.diagnostics.infra._infra', 'torch.onnx._internal.diagnostics.infra.utils', 'torch.onnx._internal.diagnostics.infra.sarif.version', 'torch.onnx._internal.diagnostics.infra.context', 'torch.onnx._internal.diagnostics.infra', 'torch.onnx._internal.diagnostics._diagnostic', 'torch.onnx._internal.diagnostics._rules', 'torch.onnx._internal.diagnostics', 'torch.onnx._internal.onnx_proto_utils', 'torch.onnx.utils', 'torch.onnx.symbolic_opset9', 'torch.onnx.symbolic_caffe2', 'torch.onnx.symbolic_opset7', 'torch.onnx.symbolic_opset8', 'torch.onnx.symbolic_opset10', 'torch.onnx.symbolic_opset11', 'torch.onnx.symbolic_opset12', 'torch.onnx.symbolic_opset13', 'torch.onnx.symbolic_opset14', 'torch.onnx.symbolic_opset15', 'torch.onnx.symbolic_opset16', 'torch.onnx.symbolic_opset17', 'torch.onnx.symbolic_opset18', 'torch.onnx.symbolic_opset19', 'torch.onnx.symbolic_opset20', 'torch.onnx._internal.io_adapter', 'torch.onnx._internal.fx.patcher', 'torch.onnx._internal.fx.serialization', 'torch.onnx._internal.fx', 'torch.onnx._internal.fx.registration', 'torch.onnx._internal.fx.decomposition_table', 'torch.onnx._internal._exporter_legacy', 'torch.onnx', 'torch.onnx.operators', 'torch._dynamo.variables.lazy', 'torch._dynamo.variables.higher_order_ops', 'torch._dynamo.variables.misc', 'torch._dynamo.variables.nn_module', 'torch._dynamo.variables.optimizer', 'torch._dynamo.variables.sdpa', 'torch._dynamo.variables.torch_function', 'torch._dynamo.codegen', 'torch._dynamo.variables.torch', 'torch._dynamo.variables', 'torch._dynamo.trace_rules', 'torch._dynamo.cache_size', 'torch._dynamo.logging', 'torch._dynamo.funcname_cache', 'torch._dynamo.side_effects', 'torch._dynamo.variables.script_object', 'torch._dynamo.variables.builder', 'torch._dynamo.output_graph', 'torch._dynamo.symbolic_convert', 'torch._dynamo.convert_frame', 'torch._dynamo.callback', 'torch._dynamo.comptime', 'torch._dynamo.decorators', 'torch._functorch.make_functional', 'torch._functorch.deprecated', 'torch._decomp.decompositions_for_rng', 'torch.fx.passes.graph_transform_observer', 'torch._inductor.runtime', 'torch._inductor.runtime.runtime_utils', 'torch._inductor.utils', 'torch._inductor.exc', 'torch._inductor.metrics', 'torch._inductor.codegen', 'torch._inductor.codegen.cuda', 'torch._inductor.codegen.cuda.cuda_env', 'torch._inductor.codegen.rocm', 'torch._inductor.codegen.rocm.compile_command', 'torch._inductor.cpu_vec_isa', 'torch._inductor.cpp_builder', 'torch._inductor.cudagraph_utils', 'torch._inductor.runtime.compile_tasks', 'torch._inductor.codecache', 'torch._functorch._aot_autograd.schemas', 'torch._functorch._aot_autograd.subclass_utils', 'torch._functorch._aot_autograd.collect_metadata_analysis', 'torch._functorch._aot_autograd.input_output_analysis', 'torch._functorch._aot_autograd.logging_utils', 'torch._functorch._aot_autograd.traced_function_transforms', 'torch._functorch._aot_autograd.runtime_wrappers', 'torch._functorch._aot_autograd.autograd_cache', 'torch._functorch._aot_autograd.dispatch_and_compile_graph', 'torch._functorch._aot_autograd.jit_compile_runtime_wrappers', 'torch._inductor.inductor_prims', 'torch._functorch.compile_utils', 'torch._functorch.partitioners', 'torch._functorch.aot_autograd', 'torch._higher_order_ops.map', 'torch.nested._internal', 'torch.nested._internal.nested_tensor', 'torch._dynamo.polyfills.builtins', 'torch._dynamo.polyfills.functools', 'torch._dynamo.polyfills.itertools', 'torch._dynamo.polyfills.os', 'torch._dynamo.polyfills.sys', 'torch._dynamo.polyfills.loader', 'torch._dynamo', 'multiprocessing.popen_fork', 'multiprocessing.popen_spawn_posix', 'matplotlib', 'distutils.version', 'matplotlib.cbook.deprecation', 'matplotlib.cbook', 'matplotlib._animation_data', 'matplotlib.animation', 'matplotlib.fontconfig_pattern', 'matplotlib.docstring', 'matplotlib._color_data', 'matplotlib.colors', 'cycler', 'matplotlib.rcsetup', 'matplotlib._version', 'matplotlib.ft2font', 'kiwisolver.exceptions', 'kiwisolver._cext', 'kiwisolver', 'encodings.ascii']\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to ././OUTPUT_MODEL/G_0.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to ././OUTPUT_MODEL/D_0.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to /content/drive/MyDrive/G_0.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 1 to /content/drive/MyDrive/D_0.pth\n",
            "  1% 1/73 [00:45<54:57, 45.79s/it]/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=hps.train.fp16_run):\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=False):\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:216: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=hps.train.fp16_run):\n",
            "/content/VITS-fast-fine-tuning/finetune_speaker_v2.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=False):\n",
            " 14% 10/73 [01:01<02:17,  2.19s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [14%]\n",
            "INFO:OUTPUT_MODEL:[2.4423513412475586, 2.532528877258301, 9.068230628967285, 22.797460556030273, 1.6220364570617676, 6.1803154945373535, 10, 0.0002]\n",
            " 27% 20/73 [01:15<01:14,  1.41s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [27%]\n",
            "INFO:OUTPUT_MODEL:[2.566892623901367, 2.583225727081299, 6.544242858886719, 19.55372428894043, 1.3146674633026123, 4.661925315856934, 20, 0.0002]\n",
            " 41% 30/73 [01:30<01:01,  1.43s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [41%]\n",
            "INFO:OUTPUT_MODEL:[2.2335920333862305, 2.734574794769287, 8.320602416992188, 21.772384643554688, 1.2071789503097534, 4.277213096618652, 30, 0.0002]\n",
            " 55% 40/73 [01:44<00:43,  1.31s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [55%]\n",
            "INFO:OUTPUT_MODEL:[2.513421058654785, 2.5286285877227783, 11.514431953430176, 22.006593704223633, 1.467468023300171, 3.656576156616211, 40, 0.0002]\n",
            " 68% 50/73 [01:58<00:34,  1.49s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [68%]\n",
            "INFO:OUTPUT_MODEL:[2.4541687965393066, 2.6618471145629883, 8.234686851501465, 21.97758674621582, 0.35295045375823975, 3.5136873722076416, 50, 0.0002]\n",
            " 82% 60/73 [02:10<00:15,  1.16s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [82%]\n",
            "INFO:OUTPUT_MODEL:[2.235591411590576, 2.840785026550293, 9.673470497131348, 23.520044326782227, 1.155023455619812, 3.3973851203918457, 60, 0.0002]\n",
            " 96% 70/73 [02:23<00:03,  1.16s/it]INFO:OUTPUT_MODEL:Train Epoch: 1 [96%]\n",
            "INFO:OUTPUT_MODEL:[2.425201892852783, 2.2338616847991943, 8.959160804748535, 18.618471145629883, 1.5533709526062012, 3.0449140071868896, 70, 0.0002]\n",
            "100% 73/73 [02:30<00:00,  2.07s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 1\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 02:52:22.441426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:52:22.474190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:52:22.485223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:52:23.908294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:52:31.825869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:52:31.845303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:52:31.851123: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:52:32.915608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            " 10% 7/73 [00:28<01:47,  1.63s/it]INFO:OUTPUT_MODEL:Train Epoch: 2 [10%]\n",
            "INFO:OUTPUT_MODEL:[2.56424880027771, 2.4386329650878906, 9.605339050292969, 19.820236206054688, 1.5931103229522705, 2.6436195373535156, 80, 0.000199975]\n",
            " 23% 17/73 [00:38<00:55,  1.00it/s]INFO:OUTPUT_MODEL:Train Epoch: 2 [23%]\n",
            "INFO:OUTPUT_MODEL:[2.573270320892334, 2.3861560821533203, 8.850862503051758, 17.539949417114258, 1.619448184967041, 2.7610840797424316, 90, 0.000199975]\n",
            " 37% 27/73 [00:48<00:37,  1.24it/s]INFO:OUTPUT_MODEL:Train Epoch: 2 [37%]\n",
            "INFO:OUTPUT_MODEL:[2.349167823791504, 2.676819324493408, 11.934282302856445, 20.700580596923828, 1.406099796295166, 2.963812828063965, 100, 0.000199975]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to ././OUTPUT_MODEL/G_100.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to ././OUTPUT_MODEL/D_100.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_0.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_0.pth\n",
            "remove ././OUTPUT_MODEL/G_0.pth\n",
            "remove ././OUTPUT_MODEL/D_0.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to /content/drive/MyDrive/G_100.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 2 to /content/drive/MyDrive/D_100.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_0.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_0.pth\n",
            "remove /content/drive/MyDrive/G_0.pth\n",
            "remove /content/drive/MyDrive/D_0.pth\n",
            " 51% 37/73 [01:11<00:37,  1.05s/it]INFO:OUTPUT_MODEL:Train Epoch: 2 [51%]\n",
            "INFO:OUTPUT_MODEL:[2.4014036655426025, 2.2834200859069824, 7.904186725616455, 19.84353256225586, 1.441211462020874, 2.5912415981292725, 110, 0.000199975]\n",
            " 64% 47/73 [01:23<00:21,  1.21it/s]INFO:OUTPUT_MODEL:Train Epoch: 2 [64%]\n",
            "INFO:OUTPUT_MODEL:[2.348578453063965, 2.5259995460510254, 6.000957012176514, 21.522165298461914, 1.2861065864562988, 3.005124092102051, 120, 0.000199975]\n",
            " 78% 57/73 [01:32<00:14,  1.10it/s]INFO:OUTPUT_MODEL:Train Epoch: 2 [78%]\n",
            "INFO:OUTPUT_MODEL:[2.595978260040283, 2.562134265899658, 8.253101348876953, 18.622392654418945, 1.4392330646514893, 2.679760217666626, 130, 0.000199975]\n",
            " 92% 67/73 [01:43<00:05,  1.15it/s]INFO:OUTPUT_MODEL:Train Epoch: 2 [92%]\n",
            "INFO:OUTPUT_MODEL:[2.5684053897857666, 2.4794774055480957, 10.043510437011719, 21.512741088867188, 1.4231839179992676, 2.7621395587921143, 140, 0.000199975]\n",
            "100% 73/73 [01:52<00:00,  1.54s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 2\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 02:54:15.426191: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:54:15.459192: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:54:15.469131: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:54:17.428657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:54:25.619539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:54:25.638710: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:54:25.644649: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:54:26.715498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  5% 4/73 [00:27<04:36,  4.01s/it]INFO:OUTPUT_MODEL:Train Epoch: 3 [5%]\n",
            "INFO:OUTPUT_MODEL:[2.5622613430023193, 1.9922953844070435, 5.1690778732299805, 19.6279296875, 1.4759947061538696, 2.497230052947998, 150, 0.000199950003125]\n",
            " 19% 14/73 [00:35<00:56,  1.04it/s]INFO:OUTPUT_MODEL:Train Epoch: 3 [19%]\n",
            "INFO:OUTPUT_MODEL:[2.1582860946655273, 2.6948437690734863, 6.816317081451416, 20.535978317260742, 1.0716018676757812, 3.1958532333374023, 160, 0.000199950003125]\n",
            " 33% 24/73 [00:46<00:45,  1.08it/s]INFO:OUTPUT_MODEL:Train Epoch: 3 [33%]\n",
            "INFO:OUTPUT_MODEL:[2.6591873168945312, 2.437971353530884, 9.116057395935059, 21.17504119873047, 0.674466609954834, 3.1789965629577637, 170, 0.000199950003125]\n",
            " 47% 34/73 [00:54<00:28,  1.39it/s]INFO:OUTPUT_MODEL:Train Epoch: 3 [47%]\n",
            "INFO:OUTPUT_MODEL:[2.434352397918701, 2.58559513092041, 10.830658912658691, 22.89617347717285, 1.4640028476715088, 3.0910933017730713, 180, 0.000199950003125]\n",
            " 60% 44/73 [01:05<00:29,  1.01s/it]INFO:OUTPUT_MODEL:Train Epoch: 3 [60%]\n",
            "INFO:OUTPUT_MODEL:[2.4695422649383545, 2.546823024749756, 8.439112663269043, 20.089792251586914, 1.4486509561538696, 2.477684497833252, 190, 0.000199950003125]\n",
            " 74% 54/73 [01:13<00:15,  1.24it/s]INFO:OUTPUT_MODEL:Train Epoch: 3 [74%]\n",
            "INFO:OUTPUT_MODEL:[2.5136594772338867, 2.458908796310425, 8.50439453125, 18.491233825683594, 1.3432095050811768, 2.683624505996704, 200, 0.000199950003125]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to ././OUTPUT_MODEL/G_200.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to ././OUTPUT_MODEL/D_200.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_100.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_100.pth\n",
            "remove ././OUTPUT_MODEL/G_100.pth\n",
            "remove ././OUTPUT_MODEL/D_100.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to /content/drive/MyDrive/G_200.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 3 to /content/drive/MyDrive/D_200.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_100.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_100.pth\n",
            "remove /content/drive/MyDrive/G_100.pth\n",
            "remove /content/drive/MyDrive/D_100.pth\n",
            " 88% 64/73 [01:44<00:14,  1.56s/it]INFO:OUTPUT_MODEL:Train Epoch: 3 [88%]\n",
            "INFO:OUTPUT_MODEL:[2.4151923656463623, 2.4293508529663086, 9.03428840637207, 20.812183380126953, 1.4255903959274292, 2.6155645847320557, 210, 0.000199950003125]\n",
            "100% 73/73 [01:54<00:00,  1.56s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 3\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 02:56:09.006537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:56:09.040449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:56:09.051192: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:56:10.718087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:56:19.214957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:56:19.234308: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:56:19.240044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:56:20.292158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  1% 1/73 [00:22<26:48, 22.34s/it]INFO:OUTPUT_MODEL:Train Epoch: 4 [1%]\n",
            "INFO:OUTPUT_MODEL:[2.3624107837677, 2.217395067214966, 6.641323566436768, 20.523340225219727, 1.278746485710144, 3.0158236026763916, 220, 0.00019992500937460937]\n",
            " 15% 11/73 [00:31<01:00,  1.02it/s]INFO:OUTPUT_MODEL:Train Epoch: 4 [15%]\n",
            "INFO:OUTPUT_MODEL:[2.4633383750915527, 2.545713186264038, 9.677128791809082, 18.389253616333008, 1.496381163597107, 2.757071018218994, 230, 0.00019992500937460937]\n",
            " 29% 21/73 [00:41<00:51,  1.02it/s]INFO:OUTPUT_MODEL:Train Epoch: 4 [29%]\n",
            "INFO:OUTPUT_MODEL:[2.1628429889678955, 2.5619146823883057, 6.98474645614624, 20.674583435058594, 1.3291680812835693, 2.3822412490844727, 240, 0.00019992500937460937]\n",
            " 42% 31/73 [00:50<00:31,  1.33it/s]INFO:OUTPUT_MODEL:Train Epoch: 4 [42%]\n",
            "INFO:OUTPUT_MODEL:[2.162222385406494, 2.8766565322875977, 7.655365467071533, 20.157007217407227, -0.6341818571090698, 2.8389768600463867, 250, 0.00019992500937460937]\n",
            " 56% 41/73 [01:00<00:32,  1.02s/it]INFO:OUTPUT_MODEL:Train Epoch: 4 [56%]\n",
            "INFO:OUTPUT_MODEL:[2.2750048637390137, 2.719982147216797, 7.201564311981201, 21.593246459960938, 1.1645281314849854, 2.9867024421691895, 260, 0.00019992500937460937]\n",
            " 70% 51/73 [01:11<00:20,  1.08it/s]INFO:OUTPUT_MODEL:Train Epoch: 4 [70%]\n",
            "INFO:OUTPUT_MODEL:[2.2170193195343018, 2.6959879398345947, 10.28996753692627, 18.188745498657227, 1.417428970336914, 2.355707883834839, 270, 0.00019992500937460937]\n",
            " 84% 61/73 [01:20<00:10,  1.14it/s]INFO:OUTPUT_MODEL:Train Epoch: 4 [84%]\n",
            "INFO:OUTPUT_MODEL:[2.3738036155700684, 2.586434841156006, 7.271072864532471, 21.29823112487793, 1.2036893367767334, 2.8766489028930664, 280, 0.00019992500937460937]\n",
            " 97% 71/73 [01:31<00:01,  1.13it/s]INFO:OUTPUT_MODEL:Train Epoch: 4 [97%]\n",
            "INFO:OUTPUT_MODEL:[2.506469488143921, 2.466233968734741, 8.581480979919434, 18.978805541992188, 1.388906478881836, 2.5333259105682373, 290, 0.00019992500937460937]\n",
            "100% 73/73 [01:35<00:00,  1.31s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 4\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 02:57:43.385921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:57:43.406698: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:57:43.412760: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:57:44.742708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:57:54.886694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:57:54.906096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:57:54.912271: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:57:55.986684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            " 11% 8/73 [00:28<01:43,  1.59s/it]INFO:OUTPUT_MODEL:Train Epoch: 5 [11%]\n",
            "INFO:OUTPUT_MODEL:[2.23462176322937, 2.7488629817962646, 9.534481048583984, 21.995317459106445, 1.1697531938552856, 2.876931667327881, 300, 0.00019990001874843754]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to ././OUTPUT_MODEL/G_300.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to ././OUTPUT_MODEL/D_300.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_200.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_200.pth\n",
            "remove ././OUTPUT_MODEL/G_200.pth\n",
            "remove ././OUTPUT_MODEL/D_200.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to /content/drive/MyDrive/G_300.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 5 to /content/drive/MyDrive/D_300.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_200.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_200.pth\n",
            "remove /content/drive/MyDrive/G_200.pth\n",
            "remove /content/drive/MyDrive/D_200.pth\n",
            " 25% 18/73 [00:55<01:20,  1.47s/it]INFO:OUTPUT_MODEL:Train Epoch: 5 [25%]\n",
            "INFO:OUTPUT_MODEL:[2.3021130561828613, 2.639721632003784, 7.470988750457764, 24.202425003051758, 1.0806751251220703, 2.9945833683013916, 310, 0.00019990001874843754]\n",
            " 38% 28/73 [01:03<00:35,  1.26it/s]INFO:OUTPUT_MODEL:Train Epoch: 5 [38%]\n",
            "INFO:OUTPUT_MODEL:[2.4493050575256348, 2.4757726192474365, 8.420806884765625, 20.94124984741211, 1.2487045526504517, 2.9597253799438477, 320, 0.00019990001874843754]\n",
            " 52% 38/73 [01:14<00:31,  1.10it/s]INFO:OUTPUT_MODEL:Train Epoch: 5 [52%]\n",
            "INFO:OUTPUT_MODEL:[2.412156581878662, 2.2061970233917236, 7.248133182525635, 15.239724159240723, 1.3217718601226807, 2.4747369289398193, 330, 0.00019990001874843754]\n",
            " 66% 48/73 [01:22<00:18,  1.35it/s]INFO:OUTPUT_MODEL:Train Epoch: 5 [66%]\n",
            "INFO:OUTPUT_MODEL:[2.5635838508605957, 2.6021034717559814, 6.659955978393555, 20.83141326904297, 1.363059639930725, 2.308943033218384, 340, 0.00019990001874843754]\n",
            " 79% 58/73 [01:33<00:14,  1.00it/s]INFO:OUTPUT_MODEL:Train Epoch: 5 [79%]\n",
            "INFO:OUTPUT_MODEL:[2.2803311347961426, 2.7138173580169678, 7.691093444824219, 22.80592155456543, 1.0188438892364502, 2.7183890342712402, 350, 0.00019990001874843754]\n",
            " 93% 68/73 [01:42<00:04,  1.19it/s]INFO:OUTPUT_MODEL:Train Epoch: 5 [93%]\n",
            "INFO:OUTPUT_MODEL:[2.464503526687622, 2.3311848640441895, 10.09439754486084, 19.034753799438477, 1.51444673538208, 2.1589624881744385, 360, 0.00019990001874843754]\n",
            "100% 73/73 [01:51<00:00,  1.52s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 5\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 02:59:34.688213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:59:34.709496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:59:34.715562: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:59:35.814423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 02:59:43.287112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 02:59:43.320037: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 02:59:43.330627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 02:59:44.860798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  7% 5/73 [00:24<02:53,  2.55s/it]INFO:OUTPUT_MODEL:Train Epoch: 6 [7%]\n",
            "INFO:OUTPUT_MODEL:[2.222378730773926, 2.408903121948242, 7.812282562255859, 21.5823974609375, 0.9305391311645508, 2.8816843032836914, 370, 0.00019987503124609398]\n",
            " 21% 15/73 [00:35<01:06,  1.15s/it]INFO:OUTPUT_MODEL:Train Epoch: 6 [21%]\n",
            "INFO:OUTPUT_MODEL:[2.3997228145599365, 2.523723602294922, 11.784055709838867, 21.130903244018555, 1.469747543334961, 2.89449405670166, 380, 0.00019987503124609398]\n",
            " 34% 25/73 [00:46<00:43,  1.10it/s]INFO:OUTPUT_MODEL:Train Epoch: 6 [34%]\n",
            "INFO:OUTPUT_MODEL:[2.0970356464385986, 2.884735107421875, 9.721237182617188, 21.38176918029785, 1.4109385013580322, 2.6270344257354736, 390, 0.00019987503124609398]\n",
            " 48% 35/73 [00:54<00:27,  1.39it/s]INFO:OUTPUT_MODEL:Train Epoch: 6 [48%]\n",
            "INFO:OUTPUT_MODEL:[2.4040780067443848, 2.1600496768951416, 6.445477485656738, 18.842166900634766, 1.304673671722412, 2.3718173503875732, 400, 0.00019987503124609398]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to ././OUTPUT_MODEL/G_400.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to ././OUTPUT_MODEL/D_400.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_300.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_300.pth\n",
            "remove ././OUTPUT_MODEL/G_300.pth\n",
            "remove ././OUTPUT_MODEL/D_300.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to /content/drive/MyDrive/G_400.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 6 to /content/drive/MyDrive/D_400.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_300.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_300.pth\n",
            "remove /content/drive/MyDrive/G_300.pth\n",
            "remove /content/drive/MyDrive/D_300.pth\n",
            " 62% 45/73 [01:12<00:28,  1.00s/it]INFO:OUTPUT_MODEL:Train Epoch: 6 [62%]\n",
            "INFO:OUTPUT_MODEL:[2.3465113639831543, 2.577155590057373, 7.741257667541504, 19.385372161865234, 1.4958851337432861, 2.460045337677002, 410, 0.00019987503124609398]\n",
            " 75% 55/73 [01:25<00:15,  1.14it/s]INFO:OUTPUT_MODEL:Train Epoch: 6 [75%]\n",
            "INFO:OUTPUT_MODEL:[2.2586421966552734, 2.673597574234009, 7.9681572914123535, 21.56780242919922, 1.1584937572479248, 2.870863437652588, 420, 0.00019987503124609398]\n",
            " 89% 65/73 [01:35<00:07,  1.05it/s]INFO:OUTPUT_MODEL:Train Epoch: 6 [89%]\n",
            "INFO:OUTPUT_MODEL:[2.0436906814575195, 3.1436638832092285, 12.984613418579102, 22.560789108276367, 1.4001569747924805, 2.5568273067474365, 430, 0.00019987503124609398]\n",
            "100% 73/73 [01:46<00:00,  1.46s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 6\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:01:21.067828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:01:21.087657: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:01:21.093638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:01:22.224758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:01:32.206056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:01:32.238838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:01:32.248718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:01:33.901219: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  3% 2/73 [00:22<10:56,  9.25s/it]INFO:OUTPUT_MODEL:Train Epoch: 7 [3%]\n",
            "INFO:OUTPUT_MODEL:[2.361827850341797, 2.5699269771575928, 7.363861083984375, 20.21657371520996, 1.1884243488311768, 2.0744845867156982, 440, 0.0001998500468671882]\n",
            " 16% 12/73 [00:32<01:10,  1.16s/it]INFO:OUTPUT_MODEL:Train Epoch: 7 [16%]\n",
            "INFO:OUTPUT_MODEL:[2.356126308441162, 2.393587112426758, 9.684069633483887, 20.22722816467285, 1.3125145435333252, 2.336541175842285, 450, 0.0001998500468671882]\n",
            " 30% 22/73 [00:42<00:40,  1.25it/s]INFO:OUTPUT_MODEL:Train Epoch: 7 [30%]\n",
            "INFO:OUTPUT_MODEL:[2.0558719635009766, 3.0876545906066895, 7.65294075012207, 22.72023582458496, 1.1055394411087036, 2.5314009189605713, 460, 0.0001998500468671882]\n",
            " 44% 32/73 [00:51<00:39,  1.05it/s]INFO:OUTPUT_MODEL:Train Epoch: 7 [44%]\n",
            "INFO:OUTPUT_MODEL:[2.045171022415161, 3.006824493408203, 8.420477867126465, 20.86484718322754, 1.2257766723632812, 2.995908498764038, 470, 0.0001998500468671882]\n",
            " 58% 42/73 [01:01<00:24,  1.25it/s]INFO:OUTPUT_MODEL:Train Epoch: 7 [58%]\n",
            "INFO:OUTPUT_MODEL:[2.225714683532715, 2.7878599166870117, 9.307132720947266, 21.07138442993164, 1.27137291431427, 2.8813974857330322, 480, 0.0001998500468671882]\n",
            " 71% 52/73 [01:10<00:20,  1.02it/s]INFO:OUTPUT_MODEL:Train Epoch: 7 [71%]\n",
            "INFO:OUTPUT_MODEL:[2.3115806579589844, 2.4620559215545654, 8.490802764892578, 20.0224609375, 1.3967416286468506, 2.2971184253692627, 490, 0.0001998500468671882]\n",
            " 85% 62/73 [01:20<00:08,  1.24it/s]INFO:OUTPUT_MODEL:Train Epoch: 7 [85%]\n",
            "INFO:OUTPUT_MODEL:[2.538818359375, 2.7431905269622803, 10.774240493774414, 20.91116714477539, 1.4340938329696655, 2.656109094619751, 500, 0.0001998500468671882]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to ././OUTPUT_MODEL/G_500.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to ././OUTPUT_MODEL/D_500.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_400.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_400.pth\n",
            "remove ././OUTPUT_MODEL/G_400.pth\n",
            "remove ././OUTPUT_MODEL/D_400.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to /content/drive/MyDrive/G_500.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 7 to /content/drive/MyDrive/D_500.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_400.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_400.pth\n",
            "remove /content/drive/MyDrive/G_400.pth\n",
            "remove /content/drive/MyDrive/D_400.pth\n",
            " 99% 72/73 [01:53<00:01,  1.41s/it]INFO:OUTPUT_MODEL:Train Epoch: 7 [99%]\n",
            "INFO:OUTPUT_MODEL:[2.40338134765625, 2.6279008388519287, 6.081145286560059, 18.469322204589844, 1.3608803749084473, 2.3902502059936523, 510, 0.0001998500468671882]\n",
            "100% 73/73 [01:58<00:00,  1.62s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 7\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:03:19.233366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:03:19.253389: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:03:19.259584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:03:20.343111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:03:28.538448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:03:28.573393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:03:28.583177: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:03:30.216320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            " 12% 9/73 [00:27<01:13,  1.15s/it]INFO:OUTPUT_MODEL:Train Epoch: 8 [12%]\n",
            "INFO:OUTPUT_MODEL:[2.0496373176574707, 2.732177734375, 8.078639030456543, 20.85405921936035, 1.0778156518936157, 2.4029414653778076, 520, 0.00019982506561132978]\n",
            " 26% 19/73 [00:39<00:51,  1.05it/s]INFO:OUTPUT_MODEL:Train Epoch: 8 [26%]\n",
            "INFO:OUTPUT_MODEL:[2.616663694381714, 2.1962475776672363, 7.740131855010986, 18.30655860900879, 1.455985188484192, 2.3342175483703613, 530, 0.00019982506561132978]\n",
            " 40% 29/73 [00:47<00:33,  1.31it/s]INFO:OUTPUT_MODEL:Train Epoch: 8 [40%]\n",
            "INFO:OUTPUT_MODEL:[2.3758275508880615, 2.6201441287994385, 8.824308395385742, 20.450605392456055, 1.1512409448623657, 2.4711995124816895, 540, 0.00019982506561132978]\n",
            " 53% 39/73 [00:58<00:35,  1.04s/it]INFO:OUTPUT_MODEL:Train Epoch: 8 [53%]\n",
            "INFO:OUTPUT_MODEL:[2.3085880279541016, 2.7701971530914307, 10.81480598449707, 20.022478103637695, 1.357405185699463, 2.3737611770629883, 550, 0.00019982506561132978]\n",
            " 67% 49/73 [01:06<00:17,  1.36it/s]INFO:OUTPUT_MODEL:Train Epoch: 8 [67%]\n",
            "INFO:OUTPUT_MODEL:[2.3898348808288574, 2.4984960556030273, 7.922326564788818, 18.684770584106445, 1.3707375526428223, 2.5589911937713623, 560, 0.00019982506561132978]\n",
            " 81% 59/73 [01:17<00:14,  1.06s/it]INFO:OUTPUT_MODEL:Train Epoch: 8 [81%]\n",
            "INFO:OUTPUT_MODEL:[2.383225679397583, 2.480278491973877, 9.132015228271484, 19.387632369995117, 1.4535975456237793, 2.253450632095337, 570, 0.00019982506561132978]\n",
            " 95% 69/73 [01:26<00:03,  1.16it/s]INFO:OUTPUT_MODEL:Train Epoch: 8 [95%]\n",
            "INFO:OUTPUT_MODEL:[2.2264068126678467, 2.7163305282592773, 8.242572784423828, 22.263090133666992, 1.1015808582305908, 2.7478294372558594, 580, 0.00019982506561132978]\n",
            "100% 73/73 [01:33<00:00,  1.28s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 8\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:04:53.274526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:04:53.294056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:04:53.300038: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:04:54.402269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:05:01.638323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:05:01.658207: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:05:01.664031: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:05:02.926367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  8% 6/73 [00:26<02:10,  1.95s/it]INFO:OUTPUT_MODEL:Train Epoch: 9 [8%]\n",
            "INFO:OUTPUT_MODEL:[2.218210220336914, 2.7442026138305664, 9.802580833435059, 21.463388442993164, 1.3983464241027832, 2.6716458797454834, 590, 0.00019980008747812837]\n",
            " 22% 16/73 [00:35<00:54,  1.04it/s]INFO:OUTPUT_MODEL:Train Epoch: 9 [22%]\n",
            "INFO:OUTPUT_MODEL:[2.3762269020080566, 2.72411847114563, 10.306279182434082, 20.10684585571289, 1.4377400875091553, 2.2464706897735596, 600, 0.00019980008747812837]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to ././OUTPUT_MODEL/G_600.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to ././OUTPUT_MODEL/D_600.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_500.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_500.pth\n",
            "remove ././OUTPUT_MODEL/G_500.pth\n",
            "remove ././OUTPUT_MODEL/D_500.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to /content/drive/MyDrive/G_600.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 9 to /content/drive/MyDrive/D_600.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_500.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_500.pth\n",
            "remove /content/drive/MyDrive/G_500.pth\n",
            "remove /content/drive/MyDrive/D_500.pth\n",
            " 36% 26/73 [01:05<01:22,  1.76s/it]INFO:OUTPUT_MODEL:Train Epoch: 9 [36%]\n",
            "INFO:OUTPUT_MODEL:[2.420001745223999, 2.4137003421783447, 7.377649307250977, 18.87416648864746, 1.4713947772979736, 2.095841646194458, 610, 0.00019980008747812837]\n",
            " 49% 36/73 [01:14<00:31,  1.17it/s]INFO:OUTPUT_MODEL:Train Epoch: 9 [49%]\n",
            "INFO:OUTPUT_MODEL:[2.5646095275878906, 2.3771588802337646, 7.457683563232422, 20.863758087158203, 1.1692100763320923, 2.4928112030029297, 620, 0.00019980008747812837]\n",
            " 63% 46/73 [01:24<00:22,  1.22it/s]INFO:OUTPUT_MODEL:Train Epoch: 9 [63%]\n",
            "INFO:OUTPUT_MODEL:[2.487513303756714, 2.319463014602661, 9.696124076843262, 19.868860244750977, 1.535053014755249, 2.3696095943450928, 630, 0.00019980008747812837]\n",
            " 77% 56/73 [01:32<00:14,  1.15it/s]INFO:OUTPUT_MODEL:Train Epoch: 9 [77%]\n",
            "INFO:OUTPUT_MODEL:[2.339682102203369, 2.655996322631836, 8.070252418518066, 20.842323303222656, 1.2346394062042236, 2.3576574325561523, 640, 0.00019980008747812837]\n",
            " 90% 66/73 [01:43<00:06,  1.12it/s]INFO:OUTPUT_MODEL:Train Epoch: 9 [90%]\n",
            "INFO:OUTPUT_MODEL:[2.528202533721924, 2.119652032852173, 7.2513861656188965, 19.264265060424805, 1.469027042388916, 2.465763568878174, 650, 0.00019980008747812837]\n",
            "100% 73/73 [01:51<00:00,  1.53s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 9\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:06:45.685693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:06:45.716622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:06:45.726331: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:06:47.390347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:06:55.572285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:06:55.592151: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:06:55.598112: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:06:56.680895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  4% 3/73 [00:24<06:48,  5.83s/it]INFO:OUTPUT_MODEL:Train Epoch: 10 [4%]\n",
            "INFO:OUTPUT_MODEL:[2.394402503967285, 2.5149495601654053, 9.6531982421875, 19.27310562133789, 1.2561026811599731, 1.9636610746383667, 660, 0.0001997751124671936]\n",
            " 18% 13/73 [00:33<00:56,  1.05it/s]INFO:OUTPUT_MODEL:Train Epoch: 10 [18%]\n",
            "INFO:OUTPUT_MODEL:[2.2937746047973633, 2.5223023891448975, 9.669249534606934, 19.047645568847656, 1.2994407415390015, 2.0569591522216797, 670, 0.0001997751124671936]\n",
            " 32% 23/73 [00:43<00:48,  1.03it/s]INFO:OUTPUT_MODEL:Train Epoch: 10 [32%]\n",
            "INFO:OUTPUT_MODEL:[2.50108003616333, 2.744856357574463, 11.782204627990723, 20.030275344848633, 1.4683482646942139, 2.7743983268737793, 680, 0.0001997751124671936]\n",
            " 45% 33/73 [00:52<00:29,  1.38it/s]INFO:OUTPUT_MODEL:Train Epoch: 10 [45%]\n",
            "INFO:OUTPUT_MODEL:[2.105498790740967, 2.931657075881958, 7.634963512420654, 20.746408462524414, 1.223214864730835, 2.3875725269317627, 690, 0.0001997751124671936]\n",
            " 59% 43/73 [01:01<00:29,  1.02it/s]INFO:OUTPUT_MODEL:Train Epoch: 10 [59%]\n",
            "INFO:OUTPUT_MODEL:[2.5355637073516846, 2.7155466079711914, 8.679856300354004, 19.33750343322754, 1.372347116470337, 2.433281183242798, 700, 0.0001997751124671936]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to ././OUTPUT_MODEL/G_700.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to ././OUTPUT_MODEL/D_700.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_600.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_600.pth\n",
            "remove ././OUTPUT_MODEL/G_600.pth\n",
            "remove ././OUTPUT_MODEL/D_600.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to /content/drive/MyDrive/G_700.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 10 to /content/drive/MyDrive/D_700.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_600.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_600.pth\n",
            "remove /content/drive/MyDrive/G_600.pth\n",
            "remove /content/drive/MyDrive/D_600.pth\n",
            " 73% 53/73 [01:31<00:29,  1.50s/it]INFO:OUTPUT_MODEL:Train Epoch: 10 [73%]\n",
            "INFO:OUTPUT_MODEL:[2.2993640899658203, 2.4171462059020996, 8.319184303283691, 21.99903106689453, 1.228393316268921, 2.4695465564727783, 710, 0.0001997751124671936]\n",
            " 86% 63/73 [01:40<00:09,  1.01it/s]INFO:OUTPUT_MODEL:Train Epoch: 10 [86%]\n",
            "INFO:OUTPUT_MODEL:[2.2127556800842285, 2.5613210201263428, 7.682405471801758, 20.2470645904541, 1.3320140838623047, 2.4919018745422363, 720, 0.0001997751124671936]\n",
            "100% 73/73 [01:52<00:00,  1.54s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 10\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:08:37.593832: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:08:37.614147: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:08:37.620194: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:08:38.713060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:08:49.110300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:08:49.130533: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:08:49.136402: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:08:50.217111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "INFO:OUTPUT_MODEL:Train Epoch: 11 [0%]\n",
            "INFO:OUTPUT_MODEL:[2.4051220417022705, 2.6476922035217285, 9.129287719726562, 18.78299903869629, 1.4230314493179321, 2.490205764770508, 730, 0.00019975014057813518]\n",
            " 14% 10/73 [00:34<01:13,  1.17s/it]INFO:OUTPUT_MODEL:Train Epoch: 11 [14%]\n",
            "INFO:OUTPUT_MODEL:[2.400407314300537, 2.811079502105713, 8.0388822555542, 21.246349334716797, 1.5516159534454346, 2.5878632068634033, 740, 0.00019975014057813518]\n",
            " 27% 20/73 [00:43<00:47,  1.11it/s]INFO:OUTPUT_MODEL:Train Epoch: 11 [27%]\n",
            "INFO:OUTPUT_MODEL:[2.3281004428863525, 2.679208278656006, 9.885431289672852, 21.934589385986328, 1.7630701065063477, 2.1282358169555664, 750, 0.00019975014057813518]\n",
            " 41% 30/73 [00:54<00:37,  1.15it/s]INFO:OUTPUT_MODEL:Train Epoch: 11 [41%]\n",
            "INFO:OUTPUT_MODEL:[2.2851500511169434, 2.799415111541748, 8.668905258178711, 20.177902221679688, 0.9838508367538452, 2.18753719329834, 760, 0.00019975014057813518]\n",
            " 55% 40/73 [01:02<00:27,  1.22it/s]INFO:OUTPUT_MODEL:Train Epoch: 11 [55%]\n",
            "INFO:OUTPUT_MODEL:[2.3413007259368896, 2.5476458072662354, 8.802319526672363, 19.476919174194336, 1.3943003416061401, 2.699549674987793, 770, 0.00019975014057813518]\n",
            " 68% 50/73 [01:13<00:21,  1.06it/s]INFO:OUTPUT_MODEL:Train Epoch: 11 [68%]\n",
            "INFO:OUTPUT_MODEL:[2.3020567893981934, 2.562730312347412, 8.707606315612793, 21.323028564453125, 1.5157997608184814, 2.6406924724578857, 780, 0.00019975014057813518]\n",
            " 82% 60/73 [01:21<00:10,  1.22it/s]INFO:OUTPUT_MODEL:Train Epoch: 11 [82%]\n",
            "INFO:OUTPUT_MODEL:[2.0130510330200195, 2.748656749725342, 8.77987003326416, 22.004838943481445, 1.158362865447998, 2.6905391216278076, 790, 0.00019975014057813518]\n",
            " 96% 70/73 [01:33<00:02,  1.03it/s]INFO:OUTPUT_MODEL:Train Epoch: 11 [96%]\n",
            "INFO:OUTPUT_MODEL:[2.378934144973755, 2.6769497394561768, 10.993202209472656, 19.731433868408203, 1.4528599977493286, 2.2856523990631104, 800, 0.00019975014057813518]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to ././OUTPUT_MODEL/G_800.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to ././OUTPUT_MODEL/D_800.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_700.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_700.pth\n",
            "remove ././OUTPUT_MODEL/G_700.pth\n",
            "remove ././OUTPUT_MODEL/D_700.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to /content/drive/MyDrive/G_800.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 11 to /content/drive/MyDrive/D_800.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_700.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_700.pth\n",
            "remove /content/drive/MyDrive/G_700.pth\n",
            "remove /content/drive/MyDrive/D_700.pth\n",
            "100% 73/73 [02:08<00:00,  1.76s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 11\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:10:46.392828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:10:46.425898: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:10:46.437057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:10:50.336367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:10:59.519037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:10:59.538919: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:10:59.544951: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:11:00.632550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            " 10% 7/73 [00:30<02:04,  1.89s/it]INFO:OUTPUT_MODEL:Train Epoch: 12 [10%]\n",
            "INFO:OUTPUT_MODEL:[2.4634013175964355, 2.5892534255981445, 10.51306438446045, 20.5320987701416, 1.5066043138504028, 2.2279045581817627, 810, 0.00019972517181056292]\n",
            " 23% 17/73 [00:39<00:47,  1.17it/s]INFO:OUTPUT_MODEL:Train Epoch: 12 [23%]\n",
            "INFO:OUTPUT_MODEL:[2.7631490230560303, 2.3792669773101807, 8.255438804626465, 18.087984085083008, 1.4920761585235596, 2.0671474933624268, 820, 0.00019972517181056292]\n",
            " 37% 27/73 [00:49<00:46,  1.02s/it]INFO:OUTPUT_MODEL:Train Epoch: 12 [37%]\n",
            "INFO:OUTPUT_MODEL:[2.3779897689819336, 2.4781088829040527, 10.494020462036133, 19.082578659057617, 1.3499648571014404, 2.2011451721191406, 830, 0.00019972517181056292]\n",
            " 51% 37/73 [00:57<00:26,  1.36it/s]INFO:OUTPUT_MODEL:Train Epoch: 12 [51%]\n",
            "INFO:OUTPUT_MODEL:[2.501966953277588, 2.370098352432251, 8.01506233215332, 19.27984619140625, 1.4023323059082031, 2.3455467224121094, 840, 0.00019972517181056292]\n",
            " 64% 47/73 [01:07<00:26,  1.02s/it]INFO:OUTPUT_MODEL:Train Epoch: 12 [64%]\n",
            "INFO:OUTPUT_MODEL:[2.55609393119812, 2.4217283725738525, 5.388813018798828, 20.125490188598633, 1.2771711349487305, 2.3247861862182617, 850, 0.00019972517181056292]\n",
            " 78% 57/73 [01:19<00:17,  1.06s/it]INFO:OUTPUT_MODEL:Train Epoch: 12 [78%]\n",
            "INFO:OUTPUT_MODEL:[2.650322914123535, 2.3804104328155518, 6.738406181335449, 17.00710678100586, 1.3879358768463135, 2.3827192783355713, 860, 0.00019972517181056292]\n",
            " 92% 67/73 [01:28<00:05,  1.10it/s]INFO:OUTPUT_MODEL:Train Epoch: 12 [92%]\n",
            "INFO:OUTPUT_MODEL:[2.3471882343292236, 2.4776926040649414, 9.225281715393066, 19.43229103088379, 1.3621150255203247, 2.2798357009887695, 870, 0.00019972517181056292]\n",
            "100% 73/73 [01:38<00:00,  1.34s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 12\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:12:24.270974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:12:24.291189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:12:24.297471: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:12:25.414536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:12:33.304205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:12:33.336012: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:12:33.345630: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:12:34.951658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  5% 4/73 [00:23<04:06,  3.58s/it]INFO:OUTPUT_MODEL:Train Epoch: 13 [5%]\n",
            "INFO:OUTPUT_MODEL:[2.4159228801727295, 2.2808279991149902, 6.4552321434021, 19.047645568847656, 1.4258034229278564, 2.037968158721924, 880, 0.0001997002061640866]\n",
            " 19% 14/73 [00:33<01:05,  1.12s/it]INFO:OUTPUT_MODEL:Train Epoch: 13 [19%]\n",
            "INFO:OUTPUT_MODEL:[2.2960824966430664, 2.6101503372192383, 7.2741899490356445, 20.44554901123047, 1.0442795753479004, 2.6037819385528564, 890, 0.0001997002061640866]\n",
            " 33% 24/73 [00:43<00:39,  1.23it/s]INFO:OUTPUT_MODEL:Train Epoch: 13 [33%]\n",
            "INFO:OUTPUT_MODEL:[2.4113712310791016, 2.7614874839782715, 9.88633918762207, 21.1455135345459, 0.8579668998718262, 2.555415630340576, 900, 0.0001997002061640866]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to ././OUTPUT_MODEL/G_900.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to ././OUTPUT_MODEL/D_900.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_800.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_800.pth\n",
            "remove ././OUTPUT_MODEL/G_800.pth\n",
            "remove ././OUTPUT_MODEL/D_800.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to /content/drive/MyDrive/G_900.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 13 to /content/drive/MyDrive/D_900.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_800.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_800.pth\n",
            "remove /content/drive/MyDrive/G_800.pth\n",
            "remove /content/drive/MyDrive/D_800.pth\n",
            " 47% 34/73 [01:12<01:01,  1.58s/it]INFO:OUTPUT_MODEL:Train Epoch: 13 [47%]\n",
            "INFO:OUTPUT_MODEL:[2.2125468254089355, 2.6949429512023926, 11.54183578491211, 21.209012985229492, 1.501396656036377, 2.334627389907837, 910, 0.0001997002061640866]\n",
            " 60% 44/73 [01:21<00:22,  1.28it/s]INFO:OUTPUT_MODEL:Train Epoch: 13 [60%]\n",
            "INFO:OUTPUT_MODEL:[2.398203134536743, 2.2245991230010986, 7.495525360107422, 18.48246192932129, 1.4447436332702637, 2.012545585632324, 920, 0.0001997002061640866]\n",
            " 74% 54/73 [01:30<00:18,  1.02it/s]INFO:OUTPUT_MODEL:Train Epoch: 13 [74%]\n",
            "INFO:OUTPUT_MODEL:[2.3248634338378906, 2.752977132797241, 9.13670539855957, 19.40683364868164, 1.3345811367034912, 2.394818067550659, 930, 0.0001997002061640866]\n",
            " 88% 64/73 [01:40<00:07,  1.20it/s]INFO:OUTPUT_MODEL:Train Epoch: 13 [88%]\n",
            "INFO:OUTPUT_MODEL:[2.4130125045776367, 2.341496229171753, 9.2042236328125, 19.18348503112793, 1.4143978357315063, 2.353043556213379, 940, 0.0001997002061640866]\n",
            "100% 73/73 [01:52<00:00,  1.54s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 13\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:14:16.672190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:14:16.692695: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:14:16.698653: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:14:17.845280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:14:25.177113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:14:25.208999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:14:25.218723: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:14:26.781996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  1% 1/73 [00:21<26:21, 21.96s/it]INFO:OUTPUT_MODEL:Train Epoch: 14 [1%]\n",
            "INFO:OUTPUT_MODEL:[2.101217746734619, 2.7833547592163086, 7.8458099365234375, 21.176057815551758, 1.2514543533325195, 2.591146469116211, 950, 0.00019967524363831608]\n",
            " 15% 11/73 [00:29<00:58,  1.07it/s]INFO:OUTPUT_MODEL:Train Epoch: 14 [15%]\n",
            "INFO:OUTPUT_MODEL:[2.3420310020446777, 2.749497890472412, 11.024762153625488, 21.272871017456055, 1.4683424234390259, 2.271986484527588, 960, 0.00019967524363831608]\n",
            " 29% 21/73 [00:42<01:07,  1.31s/it]INFO:OUTPUT_MODEL:Train Epoch: 14 [29%]\n",
            "INFO:OUTPUT_MODEL:[2.3678855895996094, 2.6612677574157715, 7.329809665679932, 19.81450843811035, 1.3056219816207886, 2.149045467376709, 970, 0.00019967524363831608]\n",
            " 42% 31/73 [00:51<00:31,  1.33it/s]INFO:OUTPUT_MODEL:Train Epoch: 14 [42%]\n",
            "INFO:OUTPUT_MODEL:[2.36769437789917, 2.499040126800537, 7.516242980957031, 19.66604232788086, -0.3079897463321686, 2.682265281677246, 980, 0.00019967524363831608]\n",
            " 56% 41/73 [01:01<00:33,  1.05s/it]INFO:OUTPUT_MODEL:Train Epoch: 14 [56%]\n",
            "INFO:OUTPUT_MODEL:[2.2950022220611572, 2.5908007621765137, 6.6635003089904785, 18.712373733520508, 1.1840307712554932, 2.0926690101623535, 990, 0.00019967524363831608]\n",
            " 70% 51/73 [01:09<00:16,  1.34it/s]INFO:OUTPUT_MODEL:Train Epoch: 14 [70%]\n",
            "INFO:OUTPUT_MODEL:[2.3705859184265137, 2.870251417160034, 11.49631404876709, 21.494096755981445, 1.393880844116211, 2.211181640625, 1000, 0.00019967524363831608]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to ././OUTPUT_MODEL/G_1000.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to ././OUTPUT_MODEL/D_1000.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_900.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_900.pth\n",
            "remove ././OUTPUT_MODEL/G_900.pth\n",
            "remove ././OUTPUT_MODEL/D_900.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to /content/drive/MyDrive/G_1000.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 14 to /content/drive/MyDrive/D_1000.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_900.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_900.pth\n",
            "remove /content/drive/MyDrive/G_900.pth\n",
            "remove /content/drive/MyDrive/D_900.pth\n",
            " 84% 61/73 [01:35<00:20,  1.74s/it]INFO:OUTPUT_MODEL:Train Epoch: 14 [84%]\n",
            "INFO:OUTPUT_MODEL:[2.2742135524749756, 2.707260847091675, 8.18465805053711, 19.089706420898438, 1.1853675842285156, 2.130765438079834, 1010, 0.00019967524363831608]\n",
            " 97% 71/73 [01:45<00:01,  1.15it/s]INFO:OUTPUT_MODEL:Train Epoch: 14 [97%]\n",
            "INFO:OUTPUT_MODEL:[2.5180039405822754, 2.340808391571045, 9.948895454406738, 19.531904220581055, 1.3685109615325928, 2.1974596977233887, 1020, 0.00019967524363831608]\n",
            "100% 73/73 [01:49<00:00,  1.50s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 14\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:16:07.192764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:16:07.225822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:16:07.235726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:16:08.868734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:16:17.250660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:16:17.270144: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:16:17.276016: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:16:18.367176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            " 11% 8/73 [00:29<01:37,  1.51s/it]INFO:OUTPUT_MODEL:Train Epoch: 15 [11%]\n",
            "INFO:OUTPUT_MODEL:[2.3524084091186523, 2.4936609268188477, 8.736371994018555, 20.96135139465332, 1.1819307804107666, 2.280622720718384, 1030, 0.0001996502842328613]\n",
            " 25% 18/73 [00:38<00:48,  1.12it/s]INFO:OUTPUT_MODEL:Train Epoch: 15 [25%]\n",
            "INFO:OUTPUT_MODEL:[2.316330909729004, 2.4737966060638428, 7.188093185424805, 23.313735961914062, 1.0856391191482544, 2.8052196502685547, 1040, 0.0001996502842328613]\n",
            " 38% 28/73 [00:48<00:39,  1.13it/s]INFO:OUTPUT_MODEL:Train Epoch: 15 [38%]\n",
            "INFO:OUTPUT_MODEL:[2.299795627593994, 2.619323968887329, 8.179582595825195, 20.816102981567383, 1.2646231651306152, 2.222010374069214, 1050, 0.0001996502842328613]\n",
            " 52% 38/73 [00:56<00:26,  1.30it/s]INFO:OUTPUT_MODEL:Train Epoch: 15 [52%]\n",
            "INFO:OUTPUT_MODEL:[2.3976268768310547, 2.4534919261932373, 9.35275650024414, 18.95109748840332, 1.3071928024291992, 2.3487789630889893, 1060, 0.0001996502842328613]\n",
            " 66% 48/73 [01:07<00:22,  1.12it/s]INFO:OUTPUT_MODEL:Train Epoch: 15 [66%]\n",
            "INFO:OUTPUT_MODEL:[2.3472466468811035, 2.3521015644073486, 7.171082019805908, 20.953536987304688, 1.400202751159668, 2.1235404014587402, 1070, 0.0001996502842328613]\n",
            " 79% 58/73 [01:15<00:12,  1.23it/s]INFO:OUTPUT_MODEL:Train Epoch: 15 [79%]\n",
            "INFO:OUTPUT_MODEL:[2.365750312805176, 2.457427978515625, 7.155242919921875, 20.69825553894043, 1.0468897819519043, 2.2765088081359863, 1080, 0.0001996502842328613]\n",
            " 93% 68/73 [01:26<00:05,  1.02s/it]INFO:OUTPUT_MODEL:Train Epoch: 15 [93%]\n",
            "INFO:OUTPUT_MODEL:[2.52467679977417, 2.0577805042266846, 6.811234951019287, 15.871480941772461, 1.4781322479248047, 2.117553234100342, 1090, 0.0001996502842328613]\n",
            "100% 73/73 [01:33<00:00,  1.28s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 15\n",
            "  0% 0/73 [00:00<?, ?it/s]2025-01-08 03:17:39.809414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:17:39.830869: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:17:39.837002: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:17:41.180468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "2025-01-08 03:17:52.931794: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-08 03:17:52.972614: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-08 03:17:52.983584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-08 03:17:54.603966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg6\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg6 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.58: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg5\n",
            "DEBUG:torio._extension.utils:Failed to load FFmpeg5 extension.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 116, in _find_ffmpeg_extension\n",
            "    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 108, in _find_versionsed_ffmpeg_extension\n",
            "    _load_lib(lib)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torio/_extension/utils.py\", line 94, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1350, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libavutil.so.57: cannot open shared object file: No such file or directory\n",
            "DEBUG:torio._extension.utils:Loading FFmpeg4\n",
            "DEBUG:torio._extension.utils:Successfully loaded FFmpeg4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "  7% 5/73 [00:28<03:23,  2.99s/it]INFO:OUTPUT_MODEL:Train Epoch: 16 [7%]\n",
            "INFO:OUTPUT_MODEL:[1.9130146503448486, 2.782989978790283, 9.030497550964355, 20.791486740112305, 0.9413079023361206, 2.8780903816223145, 1100, 0.00019962532794733217]\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to ././OUTPUT_MODEL/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to ././OUTPUT_MODEL/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to /content/drive/MyDrive/G_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to /content/drive/MyDrive/D_latest.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to ././OUTPUT_MODEL/G_1100.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to ././OUTPUT_MODEL/D_1100.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/G_1000.pth\n",
            "oldest_checkpoint_path:././OUTPUT_MODEL/D_1000.pth\n",
            "remove ././OUTPUT_MODEL/G_1000.pth\n",
            "remove ././OUTPUT_MODEL/D_1000.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to /content/drive/MyDrive/G_1100.pth\n",
            "INFO:OUTPUT_MODEL:Saving model and optimizer state at iteration 16 to /content/drive/MyDrive/D_1100.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/G_1000.pth\n",
            "oldest_checkpoint_path:/content/drive/MyDrive/D_1000.pth\n",
            "remove /content/drive/MyDrive/G_1000.pth\n",
            "remove /content/drive/MyDrive/D_1000.pth\n",
            " 21% 15/73 [00:58<01:27,  1.50s/it]INFO:OUTPUT_MODEL:Train Epoch: 16 [21%]\n",
            "INFO:OUTPUT_MODEL:[2.598086357116699, 2.257741928100586, 9.658634185791016, 20.465559005737305, 1.4713573455810547, 2.561508893966675, 1110, 0.00019962532794733217]\n",
            " 34% 25/73 [01:07<00:39,  1.21it/s]INFO:OUTPUT_MODEL:Train Epoch: 16 [34%]\n",
            "INFO:OUTPUT_MODEL:[2.369595527648926, 2.436445713043213, 8.452776908874512, 20.584976196289062, 1.4090068340301514, 2.234393358230591, 1120, 0.00019962532794733217]\n",
            " 48% 35/73 [01:17<00:35,  1.07it/s]INFO:OUTPUT_MODEL:Train Epoch: 16 [48%]\n",
            "INFO:OUTPUT_MODEL:[2.214341163635254, 2.5201034545898438, 6.605902194976807, 18.815074920654297, 1.311476230621338, 2.0037295818328857, 1130, 0.00019962532794733217]\n",
            " 62% 45/73 [01:25<00:23,  1.21it/s]INFO:OUTPUT_MODEL:Train Epoch: 16 [62%]\n",
            "INFO:OUTPUT_MODEL:[2.512712240219116, 2.3063673973083496, 5.515862941741943, 18.568803787231445, 1.526538610458374, 2.136293888092041, 1140, 0.00019962532794733217]\n",
            " 75% 55/73 [01:36<00:15,  1.13it/s]INFO:OUTPUT_MODEL:Train Epoch: 16 [75%]\n",
            "INFO:OUTPUT_MODEL:[2.340874671936035, 2.5703959465026855, 7.898113250732422, 20.794286727905273, 1.1627014875411987, 2.40165114402771, 1150, 0.00019962532794733217]\n",
            " 89% 65/73 [01:45<00:06,  1.19it/s]INFO:OUTPUT_MODEL:Train Epoch: 16 [89%]\n",
            "INFO:OUTPUT_MODEL:[2.158271551132202, 3.0143961906433105, 11.706182479858398, 20.172636032104492, 1.4206082820892334, 2.2877368927001953, 1160, 0.00019962532794733217]\n",
            "100% 73/73 [01:56<00:00,  1.59s/it]\n",
            "INFO:OUTPUT_MODEL:====> Epoch: 16\n",
            "  0% 0/73 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 微调完成后，在这里尝试效果。\n",
        "#@markdown ### 运行后会输出一个public URL, 点击进入网页版UI以使用模型\n",
        "#@markdown ### Try out TTS & VC quality here after fine-tuning is finished.\n",
        "!cp ./configs/modified_finetune_speaker.json ./finetune_speaker.json\n",
        "!python VC_inference.py --model_dir ./OUTPUT_MODEL/G_latest.pth --share True"
      ],
      "metadata": {
        "id": "SIK2XgD_ckgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e33728d-349d-4017-9158-624e02494d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:httpcore.connection:connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce9a083f6a0>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7ce9a066d5c0> server_hostname='api.gradio.app' timeout=3\n",
            "DEBUG:PIL.Image:Importing BlpImagePlugin\n",
            "DEBUG:PIL.Image:Importing BmpImagePlugin\n",
            "DEBUG:PIL.Image:Importing BufrStubImagePlugin\n",
            "DEBUG:PIL.Image:Importing CurImagePlugin\n",
            "DEBUG:PIL.Image:Importing DcxImagePlugin\n",
            "DEBUG:PIL.Image:Importing DdsImagePlugin\n",
            "DEBUG:PIL.Image:Importing EpsImagePlugin\n",
            "DEBUG:PIL.Image:Importing FitsImagePlugin\n",
            "DEBUG:PIL.Image:Importing FliImagePlugin\n",
            "DEBUG:PIL.Image:Importing FpxImagePlugin\n",
            "DEBUG:PIL.Image:Image: failed to import FpxImagePlugin: No module named 'olefile'\n",
            "DEBUG:PIL.Image:Importing FtexImagePlugin\n",
            "DEBUG:PIL.Image:Importing GbrImagePlugin\n",
            "DEBUG:PIL.Image:Importing GifImagePlugin\n",
            "DEBUG:PIL.Image:Importing GribStubImagePlugin\n",
            "DEBUG:PIL.Image:Importing Hdf5StubImagePlugin\n",
            "DEBUG:PIL.Image:Importing IcnsImagePlugin\n",
            "DEBUG:PIL.Image:Importing IcoImagePlugin\n",
            "DEBUG:PIL.Image:Importing ImImagePlugin\n",
            "DEBUG:PIL.Image:Importing ImtImagePlugin\n",
            "DEBUG:PIL.Image:Importing IptcImagePlugin\n",
            "DEBUG:PIL.Image:Importing JpegImagePlugin\n",
            "DEBUG:PIL.Image:Importing Jpeg2KImagePlugin\n",
            "DEBUG:PIL.Image:Importing McIdasImagePlugin\n",
            "DEBUG:PIL.Image:Importing MicImagePlugin\n",
            "DEBUG:PIL.Image:Image: failed to import MicImagePlugin: No module named 'olefile'\n",
            "DEBUG:PIL.Image:Importing MpegImagePlugin\n",
            "DEBUG:PIL.Image:Importing MpoImagePlugin\n",
            "DEBUG:PIL.Image:Importing MspImagePlugin\n",
            "DEBUG:PIL.Image:Importing PalmImagePlugin\n",
            "DEBUG:PIL.Image:Importing PcdImagePlugin\n",
            "DEBUG:PIL.Image:Importing PcxImagePlugin\n",
            "DEBUG:PIL.Image:Importing PdfImagePlugin\n",
            "DEBUG:PIL.Image:Importing PixarImagePlugin\n",
            "DEBUG:PIL.Image:Importing PngImagePlugin\n",
            "DEBUG:PIL.Image:Importing PpmImagePlugin\n",
            "DEBUG:PIL.Image:Importing PsdImagePlugin\n",
            "DEBUG:PIL.Image:Importing QoiImagePlugin\n",
            "DEBUG:PIL.Image:Importing SgiImagePlugin\n",
            "DEBUG:PIL.Image:Importing SpiderImagePlugin\n",
            "DEBUG:PIL.Image:Importing SunImagePlugin\n",
            "DEBUG:PIL.Image:Importing TgaImagePlugin\n",
            "DEBUG:PIL.Image:Importing TiffImagePlugin\n",
            "DEBUG:PIL.Image:Importing WebPImagePlugin\n",
            "DEBUG:PIL.Image:Importing WmfImagePlugin\n",
            "DEBUG:PIL.Image:Importing XbmImagePlugin\n",
            "DEBUG:PIL.Image:Importing XpmImagePlugin\n",
            "DEBUG:PIL.Image:Importing XVThumbImagePlugin\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce9a04e7a00>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 07 Jan 2025 18:02:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'3'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "/content/VITS-fast-fine-tuning/utils.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
            "INFO:root:Loaded checkpoint './OUTPUT_MODEL/G_latest.pth' (iteration 16)\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f7f4d30>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7ce98f69fec0> server_hostname='api.gradio.app' timeout=3\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f7f4ca0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 07 Jan 2025 18:02:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f474fd0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 07 Jan 2025 18:02:55 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=3 socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f4760e0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'HEAD']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'HEAD']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'HEAD']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 07 Jan 2025 18:02:55 GMT'), (b'server', b'uvicorn'), (b'content-length', b'41125'), (b'content-type', b'text/html; charset=utf-8')])\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'HEAD']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=30 socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f50dd50>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7ce98fa92ec0> server_hostname='api.gradio.app' timeout=30\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f50dd20>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 07 Jan 2025 18:02:55 GMT'), (b'Content-Type', b'text/html; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'ContentType', b'application/json'), (b'Access-Control-Allow-Origin', b'*'), (b'Content-Encoding', b'gzip')])\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='cdn-media.huggingface.co' port=443 local_address=None timeout=30 socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f50ece0>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7ce98fa931c0> server_hostname='cdn-media.huggingface.co' timeout=30\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ce98f50ecb0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'binary/octet-stream'), (b'Content-Length', b'11907224'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Fri, 30 Aug 2024 02:33:33 GMT'), (b'x-amz-server-side-encryption', b'AES256'), (b'Accept-Ranges', b'bytes'), (b'Server', b'AmazonS3'), (b'Date', b'Tue, 07 Jan 2025 10:31:41 GMT'), (b'ETag', b'\"d962df6d33741b8c7b2bbd350ab2c455\"'), (b'Vary', b'accept-encoding'), (b'X-Cache', b'Hit from cloudfront'), (b'Via', b'1.1 afe0dafbcc18d90a59b516e928485aaa.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LAX53-P2'), (b'X-Amz-Cf-Id', b'dD41dGllHbAGAwdnIun0pfTvlgxGmm5xiQy6AYgOBVmFORbPS35_EA=='), (b'Age', b'27194')])\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "* Running on public URL: https://c095211eda376d8833.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "DEBUG:matplotlib:(private) matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "DEBUG:matplotlib:matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "DEBUG:matplotlib:CONFIGDIR=/root/.config/matplotlib\n",
            "DEBUG:matplotlib:matplotlib version 3.3.1\n",
            "DEBUG:matplotlib:interactive is False\n",
            "DEBUG:matplotlib:platform is linux\n",
            "DEBUG:matplotlib:loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', '_io', 'marshal', 'posix', '_frozen_importlib_external', 'time', 'zipimport', '_codecs', 'codecs', 'encodings.aliases', 'encodings', 'encodings.utf_8', '_signal', '_abc', 'abc', 'io', '__main__', 'types', 'enum', '_sre', 'sre_constants', 'sre_parse', 'sre_compile', '_collections_abc', 'itertools', 'keyword', '_operator', 'operator', 'reprlib', '_collections', 'collections', '_functools', 'functools', '_locale', 'copyreg', 're', 'warnings', '_stat', 'stat', 'genericpath', 'posixpath', 'os.path', 'os', '_sitebuiltins', '_distutils_hack', 'importlib._bootstrap', 'importlib._bootstrap_external', 'importlib', 'importlib._abc', 'contextlib', 'importlib.util', 'importlib.machinery', 'google', 'google.cloud', 'mpl_toolkits', 'sphinxcontrib', 'sitecustomize', 'site', 'numpy._globals', 'numpy.__config__', 'numpy._distributor_init', '__future__', '_json', 'json.scanner', 'json.decoder', 'json.encoder', 'json', 'numpy._version', 'numpy.version', 'math', '_datetime', 'datetime', 'numpy.core._multiarray_umath', 'numpy.compat._inspect', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pathlib', '_struct', 'struct', '_compat_pickle', '_pickle', 'pickle', 'numpy.compat.py3k', 'numpy.compat', 'numpy.core.overrides', 'numpy.core.multiarray', 'numpy.core.umath', 'numbers', 'numpy.core._string_helpers', 'numpy.core._dtype', 'numpy.core._type_aliases', 'numpy.core.numerictypes', 'numpy.core._exceptions', 'collections.abc', '_contextvars', 'contextvars', 'numpy.core._ufunc_config', 'numpy.core._methods', 'numpy.core.fromnumeric', 'numpy.core.shape_base', 'numpy.core.arrayprint', 'numpy.core._asarray', 'numpy.core.numeric', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core._machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._multiarray_tests', 'numpy.core._add_newdocs', 'numpy.core._add_newdocs_scalars', 'numpy.core._dtype_ctypes', '_ast', 'ast', '_ctypes', 'ctypes._endian', 'ctypes', 'numpy.core._internal', 'numpy._pytesttester', 'numpy.core', 'numpy.lib.mixins', 'numpy.lib.ufunclike', 'numpy.lib.type_check', 'numpy.lib.scimath', 'numpy.lib.stride_tricks', 'numpy.lib.twodim_base', 'numpy.linalg._umath_linalg', 'numpy.linalg.linalg', 'numpy.linalg', 'numpy.matrixlib.defmatrix', 'numpy.matrixlib', 'numpy.lib.histograms', 'numpy.lib.function_base', 'numpy.lib.index_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'textwrap', 'numpy.lib.utils', 'numpy.lib.arraysetops', '_weakrefset', 'weakref', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.npyio', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.lib', 'numpy.fft._pocketfft_internal', 'numpy.fft._pocketfft', 'numpy.fft.helper', 'numpy.fft', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.polynomial', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.polynomial', 'cython_runtime', '_cython_0_29_35', 'numpy.random._common', 'binascii', 'base64', '_hashlib', '_blake2', 'hashlib', 'hmac', '_bisect', 'bisect', '_random', '_sha512', 'random', 'secrets', 'threading', 'numpy.random.bit_generator', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random.mtrand', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.random._pickle', 'numpy.random', 'numpy.ctypeslib', '_opcode', 'opcode', 'dis', 'token', 'tokenize', 'linecache', 'inspect', 'numpy.ma.core', 'numpy.ma.extras', 'numpy.ma', 'numpy', 'glob', 'signal', 'fcntl', '_posixsubprocess', 'select', 'selectors', 'subprocess', 'platform', 'typing.io', 'typing.re', 'typing', '_socket', 'typing_extensions', 'traceback', '_string', 'string', 'atexit', 'logging', 'torch._utils', 'zlib', '_compression', '_bz2', 'bz2', '_lzma', 'lzma', 'shutil', 'tempfile', 'torch._strobelight', 'array', 'socket', 'gc', 'timeit', 'torch._strobelight.cli_function_profiler', 'torch._strobelight.compile_time_profiler', 'torch._utils_internal', 'torch._vendor', 'torch._vendor.packaging', 'torch._vendor.packaging._structures', 'torch._vendor.packaging.version', 'torch.version', 'torch.torch_version', 'torch._C._onnx', 'torch._C._jit', 'torch._C._jit_tree_views', 'torch._C._te', 'torch._C._monitor', 'torch._C._functorch', 'torch._C._profiler', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C._lazy', 'torch._C._lazy_ts_backend', 'torch._C._aoti', 'torch._C._itt', 'torch._C._cudart', 'torch._C._nvtx', 'torch._C._cudnn', 'torch._C._cusparselt', 'torch._C._cpu', 'torch._C._instruction_counter', 'torch._C._verbose', 'torch._C', 'torch._C._dynamo', 'torch._C._dynamo.autograd_compiler', 'torch._C._dynamo.eval_frame', 'torch._C._dynamo.guards', 'torch._C._dynamo.utils', 'torch._C._fft', 'torch._C._linalg', 'torch._C._nested', 'torch._C._nn', 'torch._C._return_types', 'torch._C._sparse', 'torch._C._special', 'copy', 'torch._namedtensor_internals', 'torch.overrides', 'torch._tensor', 'torch.types', 'torch.storage', 'torch.amp.autocast_mode', 'torch.amp.grad_scaler', 'torch.amp', 'torch.random', '_heapq', 'heapq', 'difflib', 'pwd', 'grp', 'tarfile', 'torch._weights_only_unpickler', 'torch._sources', 'mmap', 'torch.serialization', 'dataclasses', 'torch._tensor_str', 'torch.cuda.gds', 'torch.cuda._utils', 'torch.cuda.graphs', 'torch._streambase', 'torch.cuda.streams', 'torch.cuda._memory_viz', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.amp.autocast_mode', 'torch.cuda.amp.common', 'torch.cuda.amp.grad_scaler', 'torch.cuda.amp', 'torch.cuda.jiterator', 'torch.cuda.nvtx', 'torch.cuda.profiler', 'torch.cuda.sparse', 'torch.cuda.tunable', 'torch.cuda', 'torch.sparse._semi_structured_conversions', 'torch.sparse._semi_structured_ops', 'torch.sparse.semi_structured', 'torch.sparse', 'torch._compile', 'torch._VF', 'torch.nn.parameter', 'torch._prims_common', 'torch.utils.backcompat', 'locale', 'torch.utils.collect_env', 'multiprocessing.process', 'multiprocessing.reduction', 'multiprocessing.context', '__mp_main__', 'multiprocessing', '_queue', 'queue', 'cmd', 'bdb', 'codeop', 'code', 'pprint', 'pdb', 'torch._C._distributed_c10d', 'torch.utils._typing_utils', 'torch.distributed.logging_handlers', 'torch.distributed.c10d_logger', 'torch.distributed.constants', 'torch.distributed.rendezvous', 'torch.distributed.distributed_c10d', 'torch.distributed.device_mesh', 'torch.distributed.remote_device', 'torch.distributed', 'torch.utils.data.datapipes._hook_iterator', 'torch.utils.data.datapipes._typing', 'torch.utils._import_utils', 'torch.utils.data.datapipes.utils', 'torch.utils.data.datapipes.utils.common', 'torch.utils.data.dataset', 'torch.utils.data.datapipes.datapipe', 'torch.utils.data.datapipes._decorator', 'torch.utils.data.datapipes.dataframe.dataframe_wrapper', 'torch.utils.data.datapipes.dataframe.structures', 'torch.utils.data.datapipes.dataframe.dataframes', 'torch.utils.data.datapipes.dataframe.datapipes', 'torch.utils.data.datapipes.dataframe', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.worker', 'torch.utils.data._utils', 'torch.utils.data.datapipes.iter.callable', 'torch.utils.data.sampler', 'torch.utils.data.datapipes.iter.combinatorics', 'torch.utils.data.datapipes.iter.combining', 'torch.utils.data.datapipes.iter.utils', 'torch.utils.data.datapipes.iter.filelister', 'torch.utils.data.datapipes.iter.fileopener', 'torch.utils.data.datapipes.iter.sharding', 'torch.utils.data.datapipes.iter.grouping', 'torch.utils.data.datapipes.utils.decoder', 'torch.utils.data.datapipes.iter.routeddecoder', 'torch.utils.data.datapipes.iter.selecting', 'torch.utils.data.datapipes.iter.streamreader', 'torch.utils.data.datapipes.iter', 'torch.utils.data.datapipes.map.callable', 'torch.utils.data.datapipes.map.combinatorics', 'torch.utils.data.datapipes.map.combining', 'torch.utils.data.datapipes.map.grouping', 'torch.utils.data.datapipes.map.utils', 'torch.utils.data.datapipes.map', 'torch.utils.data.datapipes', 'torch.utils.data.graph', 'torch.utils.data.graph_settings', 'torch.utils.data.dataloader', 'torch.utils.data.distributed', 'torch.utils.data', 'torch.utils.deterministic', 'torch.utils.hooks', 'torch.utils.backend_registration', 'torch.utils.cpp_backtrace', 'torch.utils.throughput_benchmark', 'torch.utils', 'torchgen', 'torchgen.code_template', 'torchgen.utils', 'torchgen.model', 'torch.utils._python_dispatch', 'torch.nn.modules.module', 'torch._C._distributed_rpc', 'torch._C._distributed_autograd', 'torch.distributed.autograd', 'torch.futures', 'torch.distributed.rpc._utils', 'torch.distributed.rpc.constants', 'torch.distributed.rpc.internal', 'torch.distributed.rpc.api', 'torch.distributed.rpc.backend_registry', 'torch.distributed.rpc.functions', 'torch.distributed.rpc.options', 'torch.utils._pytree', 'torch._vmap_internals', 'torch.utils._contextlib', 'torch.autograd.grad_mode', 'torch.autograd.forward_ad', 'torch.autograd.functional', 'torch.autograd.variable', 'torch.autograd.graph', 'torch.autograd.anomaly_mode', 'torch._functorch', 'torch.utils._exposed_in', 'torch._functorch.utils', 'torch._functorch.vmap', 'torch._functorch.apis', 'torch._functorch.pyfunctorch', 'torch._ops', 'torch._functorch.autograd_function', 'torch.autograd.function', 'torch.testing._utils', 'cmath', 'torch.testing._comparison', 'torch.testing._creation', 'torch.testing', 'torch.autograd.gradcheck', 'torch._C._autograd', 'torch.autograd.profiler_util', 'torch.autograd.profiler', 'torch.autograd', 'torch.autograd.profiler_legacy', 'torch.distributed.rpc.server_process_global_profiler', 'torch.distributed.rpc', 'pickletools', 'torch.package._digraph', 'torch.package._importlib', 'torch.package._mangling', 'torch.package.importer', 'torch.package._package_pickler', 'torch.package._stdlib', 'torch.package.find_file_dependencies', 'torch.package.glob_group', 'torch.package.package_exporter', 'torch.package.analyze.find_first_use_of_broken_modules', 'torch.package.analyze.trace_dependencies', 'torch.package.analyze', 'torch.package.analyze.is_from_package', 'torch.package.file_structure_representation', 'torch.package._directory_reader', 'torch.package._package_unpickler', 'torch.package.package_importer', 'torch.package', 'torch._awaits', 'torch._jit_internal', 'torch._torch_docs', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn.functional', 'torch.nn.init', 'torch.nn.modules.lazy', 'torch.nn.modules.linear', 'torch.nn.modules.activation', 'torch.nn.modules.container', 'torch.nn.modules.adaptive', 'torch.nn.modules._functions', 'torch.nn.modules.batchnorm', 'torch.nn.modules.channelshuffle', 'torch.nn.common_types', 'torch.nn.modules.conv', 'torch.nn.modules.distance', 'torch.nn.modules.dropout', 'torch.nn.modules.flatten', 'torch.nn.modules.fold', 'torch.nn.modules.instancenorm', 'torch.nn.modules.loss', 'torch.nn.modules.normalization', 'torch.nn.modules.padding', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.pooling', 'torch.__future__', 'torch.nn.utils.parametrize', 'torch.nn.utils.parametrizations', 'torch.nn.utils.rnn', 'torch.nn.utils._named_member_accessor', 'torch.nn.utils.stateless', 'torch.utils._foreach_utils', 'torch.nn.utils.clip_grad', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.fusion', 'torch.nn.utils.init', 'torch.nn.utils.memory_format', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.weight_norm', 'torch.nn.utils', 'torch.nn.modules.rnn', 'torch.nn.modules.sparse', 'torch.nn.modules.transformer', 'torch.nn.modules.upsampling', 'torch.nn.modules', 'torch.backends.cpu', 'torch.backends.cuda', 'torch.backends.cudnn', 'torch.backends.cusparselt', 'torch.backends.mha', 'torch.backends.mkl', 'torch.backends.mkldnn', 'torch._library.utils', 'torch._library.autograd', 'torch._library.fake_impl', 'torch._library.simple_registry', 'torch._library.fake_class_registry', 'torch._library.custom_ops', 'torch._library.infer_schema', 'torch._library.triton', 'torch._library', 'torch.library', 'torch.backends.mps', 'torch.backends.nnpack', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.backends', 'torch.nn.attention', 'torch.nn.parallel.parallel_apply', 'torch.cuda.nccl', 'torch.nn.parallel.comm', 'torch.nn.parallel.replicate', 'torch.nn.parallel._functions', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel.data_parallel', 'torch.distributed.algorithms.join', 'torch.distributed.algorithms', 'torch.distributed.utils', 'torch.nn.parallel.distributed', 'torch.nn.parallel', 'torch.nn', 'torch._linalg_utils', 'torch._lowrank', 'torch.functional', 'torch.__config__', 'torch.cpu.amp.autocast_mode', 'torch.cpu.amp.grad_scaler', 'torch.cpu.amp', 'torch.cpu', 'torch.distributions.constraints', 'torch.distributions.utils', 'torch.distributions.transforms', 'torch.distributions.distribution', 'torch.distributions.exp_family', 'torch.distributions.bernoulli', 'torch.distributions.dirichlet', 'torch.distributions.beta', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.gamma', 'torch.distributions.chi2', 'torch.distributions.constraint_registry', 'torch.distributions.continuous_bernoulli', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.independent', 'torch.distributions.transformed_distribution', 'torch.distributions.uniform', 'torch.distributions.gumbel', 'torch.distributions.half_cauchy', 'torch.distributions.normal', 'torch.distributions.half_normal', 'torch.distributions.inverse_gamma', 'torch.distributions.laplace', 'torch.distributions.multivariate_normal', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.kl', 'torch.distributions.kumaraswamy', 'torch.distributions.lkj_cholesky', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.mixture_same_family', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.jit._builtins', 'torch.jit._async', 'torch.jit._await', 'torch.jit._decomposition_utils', 'torch._classes', 'torch.jit._fuser', 'torch.jit._monkeytype_config', 'torch.jit._check', 'torch.jit._state', 'torch.jit.annotations', 'torch.jit._dataclass_impls', 'six', 'six.moves', 'astunparse.unparser', 'astunparse.printer', 'astunparse', 'torch.jit.frontend', 'torch.jit._recursive', 'torch.jit._serialization', 'torch.jit._script', 'torch.jit._freeze', 'torch.jit._ir_utils', 'torch.jit._trace', 'torch.jit', 'torch.distributions.von_mises', 'torch.distributions.weibull', 'torch.distributions.wishart', 'torch.distributions', 'torch.fft', '_uuid', 'uuid', 'zipfile', 'urllib.response', 'urllib.error', 'email', 'http', 'email.errors', 'email.quoprimime', 'email.base64mime', 'quopri', 'email.encoders', 'email.charset', 'email.header', 'calendar', 'email._parseaddr', 'email.utils', 'email._policybase', 'email.feedparser', 'email.parser', 'uu', 'email._encoded_words', 'email.iterators', 'email.message', '_ssl', 'ssl', 'http.client', 'urllib.request', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'unicodedata', 'tqdm.utils', 'tqdm.std', 'tqdm._dist_ver', 'tqdm.version', 'tqdm.cli', 'tqdm.gui', 'tqdm', 'torch.hub', 'torch.linalg', 'torch.mps.profiler', 'torch.mps.event', 'torch.mps', 'torch.mtia._utils', 'torch.mtia', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.reductions', '_multiprocessing', 'multiprocessing.connection', 'concurrent', 'concurrent.futures._base', 'concurrent.futures', 'concurrent.futures.thread', 'torch.multiprocessing.spawn', 'torch.multiprocessing', 'torch.nested', 'torch.optim.optimizer', 'torch.optim.lr_scheduler', 'torch.optim.swa_utils', 'torch.optim._adafactor', 'torch.optim.adadelta', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamax', 'torch.optim.adamw', 'torch.optim.asgd', 'torch.optim.lbfgs', 'torch.optim.nadam', 'torch.optim.radam', 'torch.optim.rmsprop', 'torch.optim.rprop', 'torch.optim.sgd', 'torch.optim._functional', 'torch.optim.sparse_adam', 'torch.optim', 'gzip', 'torch.profiler._utils', 'torch.profiler._memory_profiler', 'torch.profiler.profiler', 'torch.profiler.itt', 'torch.profiler', 'torch.special', 'torch.xpu._utils', 'torch.xpu.streams', 'torch.xpu.memory', 'torch.xpu.random', 'torch.xpu', 'torch.signal.windows.windows', 'torch.signal.windows', 'torch.signal', 'torch.ao', 'torch.ao.nn', 'torch.ao.nn.intrinsic.modules.fused', 'torch.ao.nn.intrinsic.modules', 'torch.ao.nn.intrinsic', 'torch.nn.intrinsic.modules.fused', 'torch.nn.intrinsic.modules', 'torch.ao.nn.qat.modules.conv', 'torch.ao.nn.qat.modules.embedding_ops', 'torch.ao.nn.qat.modules.linear', 'torch.ao.nn.qat.modules', 'torch.ao.nn.qat', 'torch.ao.nn.intrinsic.qat.modules.conv_fused', 'torch.ao.nn.intrinsic.qat.modules.linear_fused', 'torch.ao.nn.intrinsic.qat.modules.linear_relu', 'torch.ao.nn.intrinsic.qat.modules', 'torch.ao.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch.nn.intrinsic.qat.modules.linear_fused', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat', 'torch.ao.nn.quantizable.modules.activation', 'torch.ao.nn.quantizable.modules.rnn', 'torch.ao.nn.quantizable.modules', 'torch.ao.nn.quantizable', 'torch.ao.nn.quantized.modules.activation', 'torch.ao.nn.quantized.modules.batchnorm', 'torch.ao.nn.quantized.modules.utils', 'torch.ao.nn.quantized.modules.conv', 'torch.ao.nn.quantized.modules.dropout', 'torch.ao.nn.quantized.modules.embedding_ops', 'torch.ao.nn.quantized.modules.functional_modules', 'torch.ao.nn.quantized.modules.linear', 'torch.ao.nn.quantized.modules.normalization', 'torch.ao.nn.quantized.modules.rnn', 'torch.ao.nn.quantized.modules', 'torch.ao.nn.quantized.functional', 'torch.ao.nn.quantized', 'torch.ao.nn.intrinsic.quantized.modules.bn_relu', 'torch.ao.nn.intrinsic.quantized.modules.conv_add', 'torch.ao.nn.intrinsic.quantized.modules.conv_relu', 'torch.ao.nn.intrinsic.quantized.modules.linear_relu', 'torch.ao.nn.intrinsic.quantized.modules', 'torch.ao.nn.intrinsic.quantized', 'torch.ao.nn.quantized.dynamic.modules.conv', 'torch.ao.nn.quantized.dynamic.modules.linear', 'torch.ao.nn.quantized.dynamic.modules.rnn', 'torch.ao.nn.quantized.dynamic.modules', 'torch.ao.nn.quantized.dynamic', 'torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu', 'torch.ao.nn.intrinsic.quantized.dynamic.modules', 'torch.ao.nn.intrinsic.quantized.dynamic', 'torch.nn.intrinsic.quantized.dynamic.modules.linear_relu', 'torch.nn.intrinsic.quantized.dynamic.modules', 'torch.nn.intrinsic.quantized.dynamic', 'torch.nn.intrinsic.quantized.modules.bn_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic', 'torch.ao.nn.qat.dynamic.modules.linear', 'torch.ao.nn.qat.dynamic.modules', 'torch.ao.nn.qat.dynamic', 'torch.nn.qat.dynamic.modules.linear', 'torch.nn.qat.dynamic.modules', 'torch.nn.qat.dynamic', 'torch.nn.qat.modules.conv', 'torch.nn.qat.modules.embedding_ops', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules', 'torch.nn.qat', 'torch.nn.quantizable.modules', 'torch.nn.quantizable', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules', 'torch.nn.quantized', 'torch._size_docs', 'torch._storage_docs', 'torch._tensor_docs', 'torch.ops', 'torch.classes', 'torch.ao.quantization.quant_type', 'torch.fx._compatibility', 'torch.fx.immutable_collections', 'torch.fx.operator_schemas', 'torch.fx.node', 'torch.return_types', 'torch.fx._pytree', 'torch.fx.graph', 'torch.fx.graph_module', 'torch.fx._lazy_graph_module', 'torch.utils._traceback', 'torch.fx.traceback', 'torch.fx.proxy', 'torch.fx._symbolic_trace', 'torch.fx.config', 'torch.fx.interpreter', 'torch.fx.subgraph_rewriter', 'torch.fx', 'torch.ao.quantization.utils', 'torch.ao.quantization.observer', 'torch.ao.quantization.fake_quantize', 'torch.ao.quantization.fuser_method_mappings', 'torch.ao.quantization.fuse_modules', 'torch.ao.quantization.pt2e', 'torch.ao.ns', 'torch.ao.ns.fx', 'torch.ao.ns.fx.ns_types', 'torch.ao.ns.fx.utils', 'torch.ao.quantization.pt2e._numeric_debugger', 'torch.ao.quantization.pt2e.export_utils', 'torch.ao.quantization.qconfig', 'torch.ao.quantization.qconfig_mapping', 'torch.ao.nn.quantized.reference.modules.utils', 'torch.ao.nn.quantized.reference.modules.conv', 'torch.ao.nn.quantized.reference.modules.linear', 'torch.ao.nn.quantized.reference.modules.rnn', 'torch.ao.nn.quantized.reference.modules.sparse', 'torch.ao.nn.quantized.reference.modules', 'torch.ao.nn.quantized.reference', 'torch.ao.nn.sparse.quantized.linear', 'torch.ao.nn.sparse.quantized.utils', 'torch.ao.nn.sparse.quantized.dynamic.linear', 'torch.ao.nn.sparse.quantized.dynamic', 'torch.ao.nn.sparse.quantized', 'torch.ao.nn.sparse', 'torch.ao.quantization.stubs', 'torch.ao.quantization.quantization_mappings', 'torch.ao.quantization.quantize', 'torch.ao.quantization.quantize_jit', 'torch.ao.quantization', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.quantization.fuser_method_mappings', 'torch.quantization.observer', 'torch.quantization.qconfig', 'torch.quantization.quant_type', 'torch.quantization.quantization_mappings', 'torch.quantization.quantize', 'torch.quantization.quantize_jit', 'torch.quantization.stubs', 'torch.quantization', 'torch.quasirandom', 'torch.multiprocessing._atfork', 'torch._lobpcg', 'torch.masked._docs', 'torch.masked.maskedtensor.core', 'torch.masked.maskedtensor.binary', 'torch.masked.maskedtensor.passthrough', 'torch.masked.maskedtensor.creation', 'torch.masked.maskedtensor.reductions', 'torch.masked.maskedtensor.unary', 'torch.masked.maskedtensor', 'torch.masked._ops', 'torch.masked', 'torch.utils.dlpack', 'torch._dispatch', 'unittest.util', 'unittest.result', 'unittest.case', 'unittest.suite', 'unittest.loader', 'gettext', 'argparse', 'unittest.signals', 'unittest.runner', 'unittest.main', 'unittest', 'asyncio.constants', 'asyncio.format_helpers', 'asyncio.base_futures', 'asyncio.log', 'asyncio.coroutines', 'asyncio.exceptions', 'asyncio.base_tasks', '_asyncio', 'asyncio.events', 'asyncio.futures', 'asyncio.protocols', 'asyncio.transports', 'asyncio.sslproto', 'asyncio.mixins', 'asyncio.tasks', 'asyncio.locks', 'asyncio.staggered', 'asyncio.trsock', 'asyncio.base_events', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.threads', 'asyncio.base_subprocess', 'asyncio.selector_events', 'asyncio.unix_events', 'asyncio', 'unittest.mock', 'torch._dispatch.python', 'torch.utils.weak', 'torch._guards', 'torch._logging.structured', 'torch._logging._internal', 'torch._logging._registrations', 'torch._logging', 'torch.utils._mode_utils', 'torch._subclasses.meta_utils', 'torch.utils._backport_slots', 'torch.utils._stats', 'torch.fx.experimental', 'torch.fx.experimental.sym_node', 'torch._subclasses._fake_tensor_utils', 'torch._custom_op', 'torch._subclasses.fake_impls', 'torch._subclasses.fake_tensor', 'torch._subclasses.fake_utils', 'torch._subclasses', 'torch.fx.passes.shape_prop', 'pyparsing.util', 'pyparsing.unicode', 'pyparsing.exceptions', 'pyparsing.actions', 'pyparsing.results', 'pyparsing.core', 'html.entities', 'html', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'pyparsing', 'pydot.dot_parser', 'pydot._vendor', 'pydot._vendor.tempfile', 'pydot.core', 'pydot.exceptions', 'pydot', 'torch.fx.passes.graph_drawer', 'torch.fx.passes.graph_manipulation', 'torch.fx.passes.utils.matcher_utils', 'torch.fx.passes.utils.common', 'torch.fx.passes.utils', 'torch.fx.passes.tools_common', 'torch.fx.passes.split_utils', 'torch.fx.passes.net_min_base', 'torch.fx.passes.operator_support', 'torch.fx.passes.param_fetch', 'torch.fx.passes.reinplace', 'torch.fx._utils', 'torch.utils._thunk', 'torch.fx.experimental._backward_state', 'torch.fx.experimental.proxy_tensor', 'torch.fx.passes.runtime_assert', 'torch.fx.passes.split_module', 'torch.fx.passes.splitter_base', 'torch.fx.passes', 'torch.fx.passes.infra.pass_base', 'torch.fx.passes.infra.pass_manager', 'torch.fx.passes.infra', 'torch._inductor', 'torch.utils._config_module', 'torch._inductor.config', 'torch._subclasses.functional_tensor', 'torch._higher_order_ops.utils', 'torch._higher_order_ops.cond', 'torch._higher_order_ops.flex_attention', 'torch._higher_order_ops.hints_wrap', 'torch._higher_order_ops.while_loop', 'torch._higher_order_ops', 'torch.export._tree_utils', 'torch.export.graph_signature', 'torch._custom_op.autograd', 'torch._custom_op.impl', 'torch._custom_ops', 'torch._higher_order_ops.strict_mode', 'torch._export.wrappers', 'torch._export', 'torch._export.utils', 'torch._export.verifier', 'torch.export.exported_program', 'torch.export.dynamic_shapes', 'torch._functorch._aot_autograd', 'torch._functorch._aot_autograd.utils', 'torch._higher_order_ops.torchbind', 'torch._higher_order_ops.effects', 'torch.export._remove_effect_tokens_pass', 'torch.export.unflatten', 'torch.export', 'torch.fx.experimental.const_fold', 'torch._functorch.eager_transforms', 'torch._functorch.functional_call', 'torch._functorch.batch_norm_replacement', 'torch.func', 'torch.utils._content_store', 'torch._prims.debug_prims', 'torch._prims.rng_prims', 'torch._prims_common.wrappers', 'torch._prims', 'torch._higher_order_ops.out_dtype', 'torch._decomp.decompositions', 'torch._refs._conversions', 'torch._refs.fft', 'torch._refs.linalg', 'torch._refs.nn', 'torch._refs.nn.functional', 'torch._refs.special', 'torch._refs', 'torch._decomp', 'torch._meta_registrations', 'torch.compiler', '_csv', 'csv', 'importlib.metadata._functools', 'importlib.metadata._text', 'importlib.metadata._adapters', 'importlib.metadata._meta', 'importlib.metadata._collections', 'importlib.metadata._itertools', 'importlib.abc', 'importlib.metadata', 'torch', 'commons', 'librosa.version', 'pkgutil', 'sysconfig', '_sysconfigdata__x86_64-linux-gnu', 'pydoc', '_decimal', 'decimal', 'joblib.hashing', 'joblib.backports', 'joblib.disk', 'joblib.logger', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.numpy_pickle', 'joblib._store_backends', 'joblib.func_inspect', 'joblib.memory', 'joblib._multiprocessing_helpers', 'joblib.externals', 'joblib.externals.loky._base', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.process', 'multiprocessing.queues', 'concurrent.futures.process', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend.queues', 'psutil._common', 'psutil._compat', 'psutil._psposix', 'psutil._psutil_linux', 'psutil._psutil_posix', 'resource', 'psutil._pslinux', 'psutil', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky', 'joblib._utils', 'runpy', 'joblib.externals.loky.backend.spawn', 'joblib.externals.loky.backend.resource_tracker', 'joblib._memmapping_reducer', 'multiprocessing.pool', 'joblib.pool', 'joblib.executor', 'joblib._parallel_backends', 'joblib.parallel', 'joblib._cloudpickle_wrapper', 'joblib', 'decorator', 'librosa._cache', 'scipy._lib._testutils', 'scipy._lib', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback_c', 'scipy._lib._ccallback', 'scipy', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy._lib.doccer', 'scipy.ndimage._ni_docstrings', 'scipy.ndimage._filters', 'scipy.ndimage._fourier', 'scipy.special._sf_error', '_cython_0_29_36', 'scipy.special._ufuncs_cxx', 'scipy.special._ufuncs', 'scipy.special._specfun', 'scipy.special._comb', 'scipy.special._basic', 'scipy._lib._util', 'scipy.special._logsumexp', 'scipy.linalg._fblas', 'scipy.linalg.blas', 'scipy.linalg._flapack', 'scipy.linalg.lapack', 'scipy.linalg._misc', 'scipy.linalg.cython_lapack', 'scipy.linalg._cythonized_array_utils', 'scipy.linalg._decomp', 'scipy.linalg._decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg._basic', 'scipy.linalg._decomp_lu_cython', 'scipy.linalg._decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg._decomp_cholesky', 'scipy.linalg._decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg._decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg.cython_blas', 'scipy.linalg._matfuncs_expm', 'scipy.linalg._matfuncs', 'scipy.linalg._special_matrices', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.sparse._sputils', 'scipy.sparse._matrix', 'scipy.sparse._base', 'scipy.sparse._sparsetools', 'scipy.sparse._data', 'scipy.sparse._index', 'scipy.sparse._compressed', 'scipy.sparse._csr', 'scipy.sparse._csc', '_csparsetools', 'scipy.sparse._csparsetools', 'scipy.sparse._lil', 'scipy.sparse._dok', 'scipy.sparse._coo', 'scipy.sparse._dia', 'scipy.sparse._bsr', 'scipy.sparse._construct', 'scipy.sparse._extract', 'scipy.sparse._matrix_io', 'scipy.sparse.linalg._isolve._iterative', 'scipy.sparse.linalg._interface', 'scipy.sparse.linalg._isolve.utils', 'scipy._lib.decorator', 'scipy._lib._threadsafety', 'scipy.sparse.linalg._isolve.iterative', 'scipy.sparse.linalg._isolve.minres', 'scipy.sparse.linalg._isolve._gcrotmk', 'scipy.sparse.linalg._isolve.lgmres', 'scipy.sparse.linalg._isolve.lsqr', 'scipy.sparse.linalg._isolve.lsmr', 'scipy.sparse.linalg._isolve.tfqmr', 'scipy.sparse.linalg._isolve', 'scipy.sparse.linalg._dsolve._superlu', 'scipy.sparse.linalg._dsolve.linsolve', 'scipy.sparse.linalg._dsolve._add_newdocs', 'scipy.sparse.linalg._dsolve', 'scipy.sparse.linalg._eigen.arpack._arpack', 'scipy.sparse.linalg._eigen.arpack.arpack', 'scipy.sparse.linalg._eigen.arpack', 'scipy.sparse.linalg._eigen.lobpcg.lobpcg', 'scipy.sparse.linalg._eigen.lobpcg', 'scipy.sparse.linalg._eigen._svds', 'scipy.sparse.linalg._eigen', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._matfuncs', 'scipy.sparse.linalg._norm', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.sparse.csgraph', 'scipy.sparse.base', 'scipy.sparse.bsr', 'scipy.sparse.compressed', 'scipy.sparse.construct', 'scipy.sparse.coo', 'scipy.sparse.csc', 'scipy.sparse.csr', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse.dok', 'scipy.sparse.extract', 'scipy.sparse.lil', 'scipy.sparse.sparsetools', 'scipy.sparse.sputils', 'scipy.sparse', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.linalg.decomp', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_lu', 'scipy.linalg.decomp_qr', 'scipy.linalg.decomp_svd', 'scipy.linalg.decomp_schur', 'scipy.linalg.basic', 'scipy.linalg.misc', 'scipy.linalg.special_matrices', 'scipy.linalg._flinalg', 'scipy.linalg._flinalg_py', 'scipy.linalg.flinalg', 'scipy.linalg.matfuncs', 'scipy.linalg', 'scipy.special._orthogonal', 'scipy.special._spfun_stats', 'scipy.special._ellip_harm_2', 'scipy.special._ellip_harm', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.special._add_newdocs', 'scipy.special.add_newdocs', 'scipy.special.basic', 'scipy.special.orthogonal', 'scipy.special.specfun', 'scipy.special.sf_error', 'scipy.special.spfun_stats', 'scipy.special', 'scipy.ndimage._interpolation', '_ni_label', 'scipy.ndimage._ni_label', 'scipy.ndimage._morphology', 'scipy.ndimage._measurements', 'scipy.ndimage.filters', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage.morphology', 'scipy.ndimage', 'numba._version', 'numba.misc', 'numba.misc.init_utils', 'numba.core', 'yaml.error', 'yaml.tokens', 'yaml.events', 'yaml.nodes', 'yaml.reader', 'yaml.scanner', 'yaml.parser', 'yaml.composer', 'yaml.constructor', 'yaml.resolver', 'yaml.loader', 'yaml.emitter', 'yaml.serializer', 'yaml.representer', 'yaml.dumper', '_cython_3_0_11', 'yaml._yaml', 'yaml.cyaml', 'yaml', 'llvmlite._version', 'llvmlite', 'importlib._adapters', 'importlib._common', 'importlib.resources', 'llvmlite.binding.common', 'llvmlite.utils', 'llvmlite.binding.ffi', 'importlib.readers', 'llvmlite.binding.dylib', 'llvmlite.binding.targets', 'llvmlite.binding.object_file', 'llvmlite.binding.executionengine', 'llvmlite.binding.initfini', 'llvmlite.binding.linker', 'llvmlite.binding.typeref', 'llvmlite.binding.value', 'llvmlite.binding.context', 'llvmlite.binding.module', 'llvmlite.binding.options', 'llvmlite.binding.passmanagers', 'llvmlite.binding.transforms', 'llvmlite.binding.analysis', 'llvmlite.binding.orcjit', 'llvmlite.binding', 'numba.core.config', 'numba.core.utils', 'numba.core.types.abstract', 'numba.core.errors', 'numba.core.types.common', 'numba.core.typeconv.castgraph', 'numba.core.typeconv', 'numba.core.consts', 'numba.core.ir', 'numba.core.types.misc', 'numba.core.types.containers', 'numba.core.types.functions', 'numba.core.types.iterators', 'llvmlite.ir._utils', 'llvmlite.ir.types', 'llvmlite.ir.values', 'llvmlite.ir.context', 'llvmlite.ir.module', 'llvmlite.ir.instructions', 'llvmlite.ir.builder', 'llvmlite.ir.transforms', 'llvmlite.ir', 'numba.core.types.npytypes', 'numba.np', 'numba.np.npdatetime_helpers', 'numba.core.types.scalars', 'numba.core.types.function_type', 'numba.core.types', 'numba.core.typeconv._typeconv', 'numba.core.typeconv.typeconv', 'numba.core.typeconv.rules', 'numba.core.targetconfig', 'numba.core.cpu_options', 'numba.core.typing.templates', 'numba.core.datamodel.manager', 'numba.core.datamodel.packer', 'numba.core.datamodel.registry', 'numba.core.datamodel.models', 'numba.core.datamodel', 'numba.core.debuginfo', 'numba.core.cgutils', 'numba.np.numpy_support', 'numba.core.typing.typeof', 'numba.core.typing.context', 'numba.core.typing', 'numba.core.typing.asnumbatype', 'numba.misc.special', 'numba.stencils', 'numba.core.imputils', 'numba._helperlib', 'numba.core.itanium_mangler', 'numba.core.funcdesc', 'numba.core.generators', 'numba.core.removerefctpass', 'numba._dynfunc', 'numba.core.environment', 'numba.core.controlflow', 'numba.core.analysis', 'numba.misc.firstlinefinder', 'numba.core.lowering', 'numba.cloudpickle.cloudpickle', 'numba.cloudpickle', 'numba.core.serialize', 'numba.core.pythonapi', 'numba.core.extending', 'numba.core.transforms', 'numba.core.postproc', 'numba.core.rewrites.registry', 'numba.core.rewrites.static_getitem', 'numba.core.rewrites.static_raise', 'numba.core.rewrites.static_binop', 'numba.core.rewrites.ir_print', 'numba.core.rewrites', 'numba.core.ir_utils', 'numba.core.descriptors', 'numba._devicearray', 'numba._dispatcher', 'numba.core.tracing', 'numba.core.byteflow', 'numba.core.unsafe', 'numba.core.unsafe.eh', 'numba.cpython', 'numba.cpython.unsafe', 'numba.cpython.unsafe.tuple', 'numba.core.interpreter', 'numba.core.bytecode', 'numba.core.event', 'numba.core.compiler_lock', 'numba.core.typeinfer', 'numba.stencils.stencilparfor', 'numba.core.typing.npydecl', 'numba.parfors.array_analysis', 'numba.parfors.parfor', 'numba.core.sigutils', 'numba.parfors.parfor_lowering_utils', 'numba.parfors.parfor_lowering', 'numba.parfors', 'numba.core.typing.builtins', 'numba.extending', 'numba.cpython.builtins', 'numba.core.base', 'numba.core.callconv', 'numba.core.callwrapper', 'numba.core.llvm_bindings', 'numba.core.runtime.nrtdynmod', 'numba.core.runtime._nrt_python', 'numba.core.runtime.nrt', 'numba.core.runtime', 'numba.core.runtime.nrtopt', 'numba.misc.inspection', 'numba.misc.llvm_pass_timings', 'numba.core.codegen', 'numba.core.intrinsics', 'numba.core.externals', 'numba.core.fastmathpass', 'numba.core.options', 'numba.core.entrypoints', 'numba.np.ufunc_db', 'numba.core.cpu', 'numba.core.compiler_machinery', 'numba.core.ssa', 'numba.core.untyped_passes', 'numba.core.annotations', 'numba.core.annotations.type_annotations', 'numba.core.typed_passes', 'numba.core.pylowering', 'numba.core.object_mode_passes', 'numba.core.compiler', 'numba.misc.appdirs', 'numba.core.caching', 'numba.core.dispatcher', 'numba.core.registry', 'numba.stencils.stencil', 'numba.core.decorators', 'numba.np.ufunc._internal', 'numba.np.ufunc.wrappers', 'numba.core.target_extension', 'numba.np.ufunc.sigparse', 'numba.np.ufunc.ufuncbuilder', 'numba.np.ufunc.parallel', 'numba.np.ufunc.ufunc_base', 'numba.np.ufunc.dufunc', 'numba.np.ufunc.gufunc', 'numba.np.ufunc.decorators', 'numba.np.ufunc.array_exprs', 'numba.np.ufunc', 'numba.experimental.jitclass.decorators', 'numba.experimental.jitclass._box', 'numba.experimental.jitclass.boxing', 'numba.experimental.jitclass.overloads', 'numba.experimental.jitclass', 'numba.experimental', 'numba.core.withcontexts', 'numba.typed', 'numba', 'librosa.util.exceptions', 'librosa.util.deprecation', 'librosa.util.decorators', 'librosa.util.utils', 'xml', 'xml.parsers', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'xml.parsers.expat', 'plistlib', 'packaging', 'packaging._elffile', 'packaging._manylinux', 'packaging._musllinux', 'packaging.tags', 'packaging._structures', 'packaging.version', 'packaging.utils', 'packaging.specifiers', 'packaging._tokenizer', 'packaging._parser', 'packaging.markers', 'packaging.requirements', 'jaraco', 'more_itertools.recipes', 'more_itertools.more', 'more_itertools', 'jaraco.functools', 'backports.tarfile.compat', 'backports.tarfile.compat.py38', 'backports.tarfile', 'jaraco.context', 'jaraco.text', 'platformdirs.api', 'platformdirs.version', 'configparser', 'platformdirs.unix', 'platformdirs', 'pkg_resources', 'shlex', 'pooch.hashes', 'pooch.utils', 'ftplib', 'pooch.downloaders', 'pooch.core', 'pooch.processors', 'pooch._version', 'pooch', 'librosa.util.files', 'librosa.util.matching', 'scipy.optimize._minpack2', 'scipy.optimize._linesearch', 'scipy.optimize._group_columns', 'scipy.optimize._numdiff', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._differentiable_functions', 'scipy.optimize._optimize', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion_ncg', 'scipy._lib.messagestream', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trlib', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trustregion_exact', 'numpy.testing._private', 'numpy.linalg.lapack_lite', 'numpy.testing._private.utils', 'numpy.testing._private.extbuild', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'numpy.testing', 'scipy.optimize._constraints', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._trustregion_constr', 'scipy.optimize._lbfgsb', 'scipy.optimize._lbfgsb_py', '_moduleTNC', 'scipy.optimize._moduleTNC', 'scipy.optimize._tnc', 'scipy.optimize._cobyla', 'scipy.optimize._cobyla_py', 'scipy.optimize._slsqp', 'scipy.optimize._slsqp_py', 'scipy.optimize._minimize', 'scipy.optimize._minpack', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.bvls', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq', 'scipy.optimize._minpack_py', 'scipy.optimize._spectral', 'scipy.optimize._nonlin', 'scipy.optimize._root', 'scipy.optimize._zeros', 'scipy.optimize._zeros_py', 'scipy.optimize._root_scalar', 'scipy.optimize.__nnls', 'scipy.optimize._nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._highs', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._linprog_highs', 'scipy.linalg._interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg.interpolative', 'scipy.optimize._remove_redundancy', 'scipy.optimize._linprog_util', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_simplex', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_rs', 'scipy.optimize._linprog_doc', 'scipy.optimize._linprog', 'scipy.optimize._lsap', 'scipy.optimize._differentialevolution', 'scipy.spatial._ckdtree', 'scipy.spatial._kdtree', 'scipy.spatial._qhull', 'scipy.spatial._voronoi', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._plotutils', 'scipy.spatial._procrustes', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.spatial._distance_pybind', 'scipy.spatial.distance', 'scipy.spatial._geometric_slerp', 'scipy.spatial.ckdtree', 'scipy.spatial.kdtree', 'scipy.spatial.qhull', 'scipy.constants._codata', 'scipy.constants._constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.constants', 'scipy.spatial.transform._rotation_groups', 'scipy.spatial.transform._rotation', 'scipy.spatial.transform._rotation_spline', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform', 'scipy.spatial', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib._vertex', 'scipy.optimize._shgo_lib._complex', 'scipy.optimize._shgo', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.optimize._direct', 'scipy.optimize._direct_py', 'scipy.optimize._milp', 'scipy.optimize.cobyla', 'scipy.optimize.lbfgsb', 'scipy.optimize.linesearch', 'scipy.optimize.minpack', 'scipy.optimize.minpack2', 'scipy.optimize.moduleTNC', 'scipy.optimize.nonlin', 'scipy.optimize.optimize', 'scipy.optimize.slsqp', 'scipy.optimize.tnc', 'scipy.optimize.zeros', 'scipy.optimize', 'librosa.util._nnls', 'librosa.util', 'librosa.core.notation', 'librosa.core.convert', 'ctypes.util', '_cffi_backend', '_soundfile', '_soundfile_data', 'soundfile', 'audioread.exceptions', 'audioread.base', 'audioread.ffdec', 'audioread.version', 'audioread', 'scipy.signal._sigtools', 'scipy._lib._uarray._uarray', 'scipy._lib._uarray._backend', 'scipy._lib._uarray', 'scipy._lib.uarray', 'scipy.fft._basic', 'scipy.fft._realtransforms', 'scipy.fft._fftlog', 'scipy.fft._fftlog_multimethods', 'scipy.fft._pocketfft.pypocketfft', 'scipy.fft._pocketfft.helper', 'scipy.fft._pocketfft.basic', 'scipy.fft._pocketfft.realtransforms', 'scipy.fft._pocketfft', 'scipy.fft._helper', 'scipy.fft._backend', 'scipy.fft', 'scipy.signal.windows._windows', 'scipy.signal.windows.windows', 'scipy.signal.windows', 'scipy.signal._waveforms', 'scipy.signal._max_len_seq_inner', 'scipy.signal._max_len_seq', 'scipy.signal._upfirdn_apply', 'scipy.signal._upfirdn', 'scipy.signal._spline', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._bspl', 'scipy.interpolate._bsplines', 'scipy.interpolate._fitpack_py', 'scipy.interpolate._polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.interpnd', 'scipy.interpolate._interpolate', 'scipy.interpolate._fitpack2', 'scipy.interpolate._rbf', 'scipy.interpolate._rbfinterp_pythran', 'scipy.interpolate._rbfinterp', 'scipy.interpolate._cubic', 'scipy.interpolate._ndgriddata', 'scipy.interpolate._pade', 'scipy.interpolate._rgi_cython', 'scipy.interpolate._rgi', 'scipy.interpolate.fitpack', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpolate', 'scipy.interpolate.ndgriddata', 'scipy.interpolate.polyint', 'scipy.interpolate.rbf', 'scipy.interpolate', 'scipy.signal._bsplines', 'scipy.signal._filter_design', 'scipy.signal._fir_filter_design', 'scipy.integrate._quadrature', 'scipy.integrate._odepack', 'scipy.integrate._odepack_py', 'scipy.integrate._quadpack', 'scipy.integrate._quadpack_py', 'scipy.integrate._vode', 'scipy.integrate._dop', 'scipy.integrate._lsoda', 'scipy.integrate._ode', 'scipy.integrate._bvp', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp', 'scipy.integrate._quad_vec', 'scipy.integrate.dop', 'scipy.integrate.lsoda', 'scipy.integrate.vode', 'scipy.integrate.odepack', 'scipy.integrate.quadpack', 'scipy.integrate', 'scipy.signal._lti_conversion', 'scipy.signal._ltisys', 'scipy.signal._arraytools', 'scipy.signal._sosfilt', 'scipy.signal._signaltools', 'scipy.signal._savitzky_golay', 'scipy.signal._spectral', 'scipy.signal._spectral_py', 'scipy.signal._wavelets', 'scipy.stats._warnings_errors', 'scipy.stats._distr_params', 'scipy._lib._finite_differences', 'scipy.stats._constants', 'scipy.stats._censored_data', 'scipy.stats._distn_infrastructure', 'scipy.special.cython_special', 'scipy.stats._stats', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats.beta_ufunc', 'scipy.stats._boost.beta_ufunc', 'scipy.stats.binom_ufunc', 'scipy.stats._boost.binom_ufunc', 'scipy.stats.nbinom_ufunc', 'scipy.stats._boost.nbinom_ufunc', 'scipy.stats.hypergeom_ufunc', 'scipy.stats._boost.hypergeom_ufunc', 'scipy.stats.ncf_ufunc', 'scipy.stats._boost.ncf_ufunc', 'scipy.stats.ncx2_ufunc', 'scipy.stats._boost.ncx2_ufunc', 'scipy.stats.nct_ufunc', 'scipy.stats._boost.nct_ufunc', 'scipy.stats.skewnorm_ufunc', 'scipy.stats._boost.skewnorm_ufunc', 'scipy.stats.invgauss_ufunc', 'scipy.stats._boost.invgauss_ufunc', 'scipy.stats._boost', 'scipy.stats._continuous_distns', 'scipy.stats._biasedurn', 'scipy.stats._discrete_distns', 'scipy.stats._levy_stable.levyst', 'scipy.stats._levy_stable', 'scipy.stats._entropy', 'scipy.stats.distributions', 'scipy._lib._bunch', 'scipy.stats._stats_pythran', 'scipy.stats._stats_mstats_common', 'scipy.stats._mstats_basic', 'scipy.stats._common', 'scipy.stats._hypotests', 'scipy._lib._docscrape', 'scipy.stats._axis_nan_policy', 'scipy.stats._resampling', 'scipy.stats._binomtest', 'scipy.stats._stats_py', 'scipy.stats._variation', 'scipy.stats._statlib', 'scipy.stats._fit', 'scipy.stats._relative_risk', 'scipy.stats._crosstab', 'scipy.stats._odds_ratio', 'scipy.stats.contingency', 'scipy.stats._morestats', 'scipy.stats._sobol', 'scipy.stats._qmc_cy', 'scipy.stats._qmc', 'scipy.stats._multicomp', 'scipy.stats._binned_statistic', 'scipy.stats._mvn', 'scipy.stats._kde', 'scipy.stats._mstats_extras', 'scipy.stats.mstats', 'scipy.stats.qmc', 'scipy.stats._covariance', 'scipy.stats._rcont.rcont', 'scipy.stats._rcont', 'scipy.stats._qmvnt', 'scipy.stats._multivariate', 'scipy.stats._rvs_sampling', 'scipy.stats._page_trend_test', 'scipy.stats._mannwhitneyu', 'scipy.stats._sensitivity_analysis', 'scipy.stats._survival', 'scipy.stats.biasedurn', 'scipy.stats.kde', 'scipy.stats.morestats', 'scipy.stats.mstats_basic', 'scipy.stats.mstats_extras', 'scipy.stats.mvn', 'scipy.stats.statlib', 'scipy.stats.stats', 'scipy.stats', 'scipy.signal._peak_finding_utils', 'scipy.signal._peak_finding', 'scipy.signal._czt', 'scipy.signal.bsplines', 'scipy.signal.filter_design', 'scipy.signal.fir_filter_design', 'scipy.signal.lti_conversion', 'scipy.signal.ltisys', 'scipy.signal.spectral', 'scipy.signal.signaltools', 'scipy.signal.waveforms', 'scipy.signal.wavelets', 'scipy.signal.spline', 'scipy.signal', 'resampy.version', 'resampy.filters', 'numba.misc.quicksort', 'numba.misc.mergesort', 'numba.cpython.slicing', 'numba.np.arrayobj', 'numba.np.npdatetime', 'numba.np.math', 'numba.cpython.unsafe.numbers', 'numba.cpython.mathimpl', 'numba.np.math.cmathimpl', 'numba.np.math.mathimpl', 'numba.np.math.numbers', 'numba.np.npyfuncs', 'numba.np.npyimpl', 'resampy.interpn', 'resampy.core', 'resampy', 'librosa.core.fft', 'encodings.cp437', 'librosa.core.audio', 'librosa.filters', 'librosa.core.spectrum', 'librosa.sequence', 'librosa.core.pitch', 'librosa.core.constantq', 'librosa.core.harmonic', 'librosa.core', 'librosa.feature.utils', 'scipy.fftpack._helper', 'scipy.fftpack._basic', 'scipy.fftpack.convolve', 'scipy.fftpack._pseudo_diffs', 'scipy.fftpack._realtransforms', 'scipy.fftpack.basic', 'scipy.fftpack.helper', 'scipy.fftpack.pseudo_diffs', 'scipy.fftpack.realtransforms', 'scipy.fftpack', 'librosa.feature.spectral', 'librosa.feature.rhythm', 'librosa.feature.inverse', 'librosa.feature', 'librosa.onset', 'librosa.beat', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build._check_build', 'sklearn.__check_build', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.utils.deprecation', 'sklearn.exceptions', 'threadpoolctl', 'sklearn.externals', 'sklearn.externals._packaging', 'sklearn.externals._packaging._structures', 'sklearn.externals._packaging.version', 'sklearn.utils.fixes', 'sklearn.utils._estimator_html_repr', 'sklearn.utils.validation', 'sklearn.utils', 'sklearn.utils._tags', 'sklearn.base', 'sklearn.utils._openmp_helpers', 'sklearn.utils._show_versions', 'sklearn', '_cython_0_29_26', 'sklearn.decomposition._cdnmf_fast', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', 'sklearn.utils.extmath', 'sklearn.decomposition._nmf', 'sklearn.decomposition._base', 'sklearn.utils._arpack', 'sklearn.decomposition._pca', 'sklearn.decomposition._incremental_pca', 'sklearn.preprocessing._function_transformer', 'sklearn.utils.sparsefuncs', 'sklearn.utils._mask', 'sklearn.utils._encode', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._data', 'sklearn.utils.multiclass', 'sklearn.preprocessing._label', 'sklearn.preprocessing._discretization', 'sklearn.utils.stats', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._polynomial', 'sklearn.preprocessing', 'sklearn.metrics._base', 'sklearn.metrics._ranking', 'sklearn.metrics._classification', 'sklearn.utils._typedefs', 'sklearn.utils._readonly_array_wrapper', 'sklearn.metrics._dist_metrics', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.pairwise', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics.cluster', 'sklearn._loss', 'sklearn._loss.glm_distribution', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.det_curve', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.metrics', 'sklearn.decomposition._kernel_pca', 'sklearn.utils._random', 'sklearn.utils._seq_dataset', 'sklearn.linear_model._base', 'sklearn.linear_model._bayes', 'sklearn.utils._cython_blas', 'sklearn.utils.arrayfuncs', 'sklearn.model_selection._split', 'sklearn.utils.metaestimators', 'sklearn.model_selection._validation', 'sklearn.utils.random', 'sklearn.model_selection._search', 'sklearn.model_selection', 'sklearn.linear_model._least_angle', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._coordinate_descent', 'sklearn.utils.optimize', 'sklearn.linear_model._glm.link', 'sklearn.linear_model._glm.glm', 'sklearn.linear_model._glm', 'sklearn.linear_model._huber', 'sklearn.utils._weight_vector', 'sklearn.linear_model._sgd_fast', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._sag', 'sklearn.linear_model._ridge', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._base', 'sklearn.svm._classes', 'sklearn.svm._bounds', 'sklearn.svm', 'sklearn.linear_model._logistic', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._quantile', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.linear_model', 'sklearn.decomposition._dict_learning', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._online_lda_fast', 'sklearn.decomposition._lda', 'sklearn.decomposition', 'sklearn.neighbors._partition_nodes', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._distance_metric', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._graph', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.neighbors', 'sklearn.manifold._locally_linear', 'sklearn.utils.graph', 'sklearn.manifold._isomap', 'sklearn._isotonic', 'sklearn.isotonic', 'sklearn.manifold._mds', 'sklearn.manifold._spectral_embedding', 'sklearn.manifold._utils', 'sklearn.tree._utils', 'sklearn.tree._tree', 'sklearn.tree._splitter', 'sklearn.tree._criterion', 'sklearn.tree._classes', 'sklearn.tree._reingold_tilford', 'sklearn.tree._export', 'sklearn.tree', 'sklearn.neighbors._quad_tree', 'sklearn.manifold._barnes_hut_tsne', 'sklearn.manifold._t_sne', 'sklearn.manifold', 'sklearn.cluster._k_means_common', 'sklearn.cluster._k_means_minibatch', 'sklearn.cluster._k_means_lloyd', 'sklearn.cluster._k_means_elkan', 'sklearn.cluster._kmeans', 'sklearn.cluster._spectral', 'sklearn.cluster._mean_shift', 'sklearn.cluster._affinity_propagation', 'sklearn.utils._fast_dict', 'sklearn.cluster._hierarchical_fast', 'sklearn.cluster._feature_agglomeration', 'sklearn.cluster._agglomerative', 'sklearn.cluster._dbscan_inner', 'sklearn.cluster._dbscan', 'sklearn.cluster._optics', 'sklearn.cluster._bicluster', 'sklearn.cluster._birch', 'sklearn.cluster', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction._stop_words', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction', 'librosa.segment', 'librosa.decompose', 'librosa.effects', 'librosa', 'scipy.io.matlab._byteordercodes', 'scipy.io.matlab._miobase', 'scipy.io.matlab._mio_utils', 'scipy.io.matlab._mio4', 'scipy.io.matlab._streams', 'scipy.io.matlab._mio5_params', 'scipy.io.matlab._mio5_utils', 'scipy.io.matlab._mio5', 'scipy.io.matlab._mio', 'scipy.io.matlab.mio', 'scipy.io.matlab.mio5', 'scipy.io.matlab.mio5_params', 'scipy.io.matlab.mio4', 'scipy.io.matlab.byteordercodes', 'scipy.io.matlab.miobase', 'scipy.io.matlab.mio_utils', 'scipy.io.matlab.streams', 'scipy.io.matlab.mio5_utils', 'scipy.io.matlab', 'scipy.io._netcdf', 'scipy.io._fortran', 'scipy.io._mmio', 'scipy.io._idl', 'scipy.io._harwell_boeing._fortran_format_parser', 'scipy.io._harwell_boeing.hb', 'scipy.io._harwell_boeing', 'scipy.io.arff._arffread', 'scipy.io.arff.arffread', 'scipy.io.arff', 'scipy.io.harwell_boeing', 'scipy.io.idl', 'scipy.io.mmio', 'scipy.io.netcdf', 'scipy.io.wavfile', 'scipy.io', 'mel_processing', 'regex._regex', 'regex._regex_core', 'regex.regex', 'regex', 'utils', 'transforms', 'modules', 'attentions', 'monotonic_align.monotonic_align', 'monotonic_align.core', 'monotonic_align.monotonic_align.core', 'monotonic_align', 'models', 'httpx.__version__', 'httpx._exceptions', 'http.cookiejar', 'mimetypes', 'httpx._types', 'ipaddress', 'httpx._utils', 'httpx._multipart', 'httpx._content', 'httpx._decoders', 'httpx._status_codes', 'idna.idnadata', 'idna.intranges', 'idna.core', 'idna.package_data', 'idna', 'httpx._urlparse', 'httpx._urls', 'httpx._models', 'httpx._auth', 'httpx._config', 'httpx._transports.base', 'httpx._transports.asgi', 'httpx._transports.default', 'httpx._transports.mock', 'httpx._transports.wsgi', 'httpx._transports', 'httpx._client', 'httpx._api', 'click._compat', 'click.globals', 'click.utils', 'click.exceptions', 'click.types', 'click.parser', 'click.formatting', 'click.termui', 'click.core', 'click.decorators', 'click', 'pygments', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.plugin', 'pygments.util', 'pygments.lexers', 'rich._extension', 'rich', 'termios', 'getpass', 'rich._null_file', 'rich.errors', 'colorsys', 'rich.color_triplet', 'rich.palette', 'rich._palettes', 'rich.repr', 'rich.terminal_theme', 'rich.color', 'rich.style', 'rich.default_styles', 'rich.theme', 'rich.themes', 'rich._emoji_codes', 'rich._emoji_replace', 'rich._export_format', 'rich._fileno', 'rich._loop', 'rich._pick', 'rich._cell_widths', 'rich.cells', 'rich._wrap', 'rich.segment', 'rich.jupyter', 'rich.protocol', 'rich.measure', 'rich.constrain', 'rich.align', 'rich.containers', 'rich.control', 'rich.emoji', 'rich.text', 'rich._log_render', 'rich.highlighter', 'rich.markup', 'rich.pager', 'attr._compat', 'attr._config', 'attr.exceptions', 'attr.setters', 'attr._make', 'attr.converters', 'attr.filters', 'attr.validators', 'attr._cmp', 'attr._funcs', 'attr._next_gen', 'attr._version_info', 'attr', 'rich.abc', 'rich.pretty', 'rich.region', 'rich.box', 'rich.padding', 'rich.panel', 'fractions', 'rich._ratio', 'rich.table', 'rich.scope', 'rich.screen', 'rich.styled', 'rich.console', 'rich.filesize', 'rich.ansi', 'rich.file_proxy', 'rich.live_render', 'rich.live', 'rich.progress_bar', 'rich._spinners', 'rich.spinner', 'rich.progress', 'pygments.filter', 'pygments.token', 'pygments.filters', 'pygments.regexopt', 'pygments.lexer', 'pygments.style', 'pygments.styles._mapping', 'pygments.styles', 'rich.syntax', 'httpx._main', 'httpx', 'huggingface_hub', 'urllib3.exceptions', 'urllib3.util.timeout', 'urllib3.util.connection', 'urllib3.util.util', 'urllib3.util.request', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.ssl_', 'urllib3.util.wait', 'urllib3.util', 'urllib3._base_connection', 'urllib3._collections', 'urllib3._version', 'urllib3.fields', 'urllib3.filepost', 'urllib3.http2', 'urllib3.http2.probe', 'urllib3.util.ssl_match_hostname', 'urllib3.connection', 'urllib3.response', 'urllib3._request_methods', 'urllib3.util.proxy', 'urllib3.connectionpool', 'urllib3.poolmanager', 'urllib3', 'chardet.enums', 'chardet.charsetprober', 'chardet.charsetgroupprober', 'chardet.resultdict', 'chardet.codingstatemachinedict', 'chardet.codingstatemachine', 'chardet.escsm', 'chardet.escprober', 'chardet.latin1prober', 'chardet.macromanprober', 'chardet.big5freq', 'chardet.euckrfreq', 'chardet.euctwfreq', 'chardet.gb2312freq', 'chardet.jisfreq', 'chardet.johabfreq', 'chardet.chardistribution', 'chardet.mbcharsetprober', 'chardet.mbcssm', 'chardet.big5prober', 'chardet.cp949prober', 'chardet.jpcntx', 'chardet.eucjpprober', 'chardet.euckrprober', 'chardet.euctwprober', 'chardet.gb2312prober', 'chardet.johabprober', 'chardet.sjisprober', 'chardet.utf8prober', 'chardet.mbcsgroupprober', 'chardet.sbcharsetprober', 'chardet.hebrewprober', 'chardet.langbulgarianmodel', 'chardet.langgreekmodel', 'chardet.langhebrewmodel', 'chardet.langrussianmodel', 'chardet.langthaimodel', 'chardet.langturkishmodel', 'chardet.sbcsgroupprober', 'chardet.utf1632prober', 'chardet.universaldetector', 'chardet.version', 'chardet', 'http.cookies', 'requests.compat', 'requests.exceptions', 'charset_normalizer.constant', 'charset_normalizer.md__mypyc', '_multibytecodec', 'charset_normalizer.utils', 'charset_normalizer.md', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.api', 'charset_normalizer.legacy', 'charset_normalizer.version', 'charset_normalizer', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.util.util', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util', 'requests.packages.urllib3._base_connection', 'requests.packages.urllib3._collections', 'requests.packages.urllib3._version', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.http2', 'requests.packages.urllib3.http2.probe', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.response', 'requests.packages.urllib3._request_methods', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.idna.core', 'requests.packages.idna.package_data', 'requests.packages.idna', 'requests.packages.chardet.enums', 'requests.packages.chardet.charsetprober', 'requests.packages.chardet.charsetgroupprober', 'requests.packages.chardet.resultdict', 'requests.packages.chardet.codingstatemachinedict', 'requests.packages.chardet.codingstatemachine', 'requests.packages.chardet.escsm', 'requests.packages.chardet.escprober', 'requests.packages.chardet.latin1prober', 'requests.packages.chardet.macromanprober', 'requests.packages.chardet.big5freq', 'requests.packages.chardet.euckrfreq', 'requests.packages.chardet.euctwfreq', 'requests.packages.chardet.gb2312freq', 'requests.packages.chardet.jisfreq', 'requests.packages.chardet.johabfreq', 'requests.packages.chardet.chardistribution', 'requests.packages.chardet.mbcharsetprober', 'requests.packages.chardet.mbcssm', 'requests.packages.chardet.big5prober', 'requests.packages.chardet.cp949prober', 'requests.packages.chardet.jpcntx', 'requests.packages.chardet.eucjpprober', 'requests.packages.chardet.euckrprober', 'requests.packages.chardet.euctwprober', 'requests.packages.chardet.gb2312prober', 'requests.packages.chardet.johabprober', 'requests.packages.chardet.sjisprober', 'requests.packages.chardet.utf8prober', 'requests.packages.chardet.mbcsgroupprober', 'requests.packages.chardet.sbcharsetprober', 'requests.packages.chardet.hebrewprober', 'requests.packages.chardet.langbulgarianmodel', 'requests.packages.chardet.langgreekmodel', 'requests.packages.chardet.langhebrewmodel', 'requests.packages.chardet.langrussianmodel', 'requests.packages.chardet.langthaimodel', 'requests.packages.chardet.langturkishmodel', 'requests.packages.chardet.sbcsgroupprober', 'requests.packages.chardet.utf1632prober', 'requests.packages.chardet.universaldetector', 'requests.packages.chardet.version', 'requests.packages.chardet', 'requests.packages', 'certifi.core', 'certifi', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.utils', 'requests.auth', 'stringprep', 'encodings.idna', 'requests.hooks', 'requests.status_codes', 'requests.models', 'urllib3.contrib', 'socks', 'urllib3.contrib.socks', 'requests.adapters', 'requests.sessions', 'requests.api', 'requests', 'tqdm.autonotebook', 'tqdm.asyncio', 'tqdm.auto', 'tqdm.contrib', 'tqdm.contrib.concurrent', 'huggingface_hub.constants', 'huggingface_hub.errors', 'huggingface_hub.utils.tqdm', 'huggingface_hub.utils._runtime', 'huggingface_hub.utils._auth', 'huggingface_hub.utils._cache_assets', 'huggingface_hub.commands', 'huggingface_hub.commands._cli_utils', 'huggingface_hub.utils.logging', 'huggingface_hub.utils._cache_manager', 'huggingface_hub.utils._chunk_utils', 'huggingface_hub.utils._datetime', 'huggingface_hub.utils._experimental', 'filelock._error', 'filelock._api', 'filelock._util', 'filelock._soft', 'filelock._unix', 'filelock._windows', 'filelock.asyncio', 'filelock.version', 'filelock', 'huggingface_hub.utils._fixes', 'huggingface_hub.utils._subprocess', 'huggingface_hub.utils._git_credential', 'huggingface_hub.utils._deprecation', 'huggingface_hub.utils._typing', 'huggingface_hub.utils._validators', 'huggingface_hub.utils._headers', 'huggingface_hub.utils._hf_folder', 'huggingface_hub.utils._lfs', 'huggingface_hub.utils._http', 'huggingface_hub.utils._pagination', 'huggingface_hub.utils._paths', 'huggingface_hub.utils._safetensors', 'huggingface_hub.utils._telemetry', 'huggingface_hub.utils', 'huggingface_hub._local_folder', 'huggingface_hub.utils.insecure_hashlib', 'huggingface_hub.utils.sha', 'huggingface_hub.file_download', 'huggingface_hub.lfs', 'huggingface_hub._commit_api', 'huggingface_hub.inference', 'huggingface_hub.inference._generated', 'huggingface_hub.inference._generated.types.base', 'huggingface_hub.inference._generated.types.audio_classification', 'huggingface_hub.inference._generated.types.audio_to_audio', 'huggingface_hub.inference._generated.types.automatic_speech_recognition', 'huggingface_hub.inference._generated.types.chat_completion', 'huggingface_hub.inference._generated.types.depth_estimation', 'huggingface_hub.inference._generated.types.document_question_answering', 'huggingface_hub.inference._generated.types.feature_extraction', 'huggingface_hub.inference._generated.types.fill_mask', 'huggingface_hub.inference._generated.types.image_classification', 'huggingface_hub.inference._generated.types.image_segmentation', 'huggingface_hub.inference._generated.types.image_to_image', 'huggingface_hub.inference._generated.types.image_to_text', 'huggingface_hub.inference._generated.types.object_detection', 'huggingface_hub.inference._generated.types.question_answering', 'huggingface_hub.inference._generated.types.sentence_similarity', 'huggingface_hub.inference._generated.types.summarization', 'huggingface_hub.inference._generated.types.table_question_answering', 'huggingface_hub.inference._generated.types.text2text_generation', 'huggingface_hub.inference._generated.types.text_classification', 'huggingface_hub.inference._generated.types.text_generation', 'huggingface_hub.inference._generated.types.text_to_audio', 'huggingface_hub.inference._generated.types.text_to_image', 'huggingface_hub.inference._generated.types.text_to_speech', 'huggingface_hub.inference._generated.types.token_classification', 'huggingface_hub.inference._generated.types.translation', 'huggingface_hub.inference._generated.types.video_classification', 'huggingface_hub.inference._generated.types.visual_question_answering', 'huggingface_hub.inference._generated.types.zero_shot_classification', 'huggingface_hub.inference._generated.types.zero_shot_image_classification', 'huggingface_hub.inference._generated.types.zero_shot_object_detection', 'huggingface_hub.inference._generated.types', 'huggingface_hub.inference._common', 'huggingface_hub.inference._client', 'huggingface_hub.inference._generated._async_client', 'huggingface_hub._inference_endpoints', 'huggingface_hub._space_api', 'huggingface_hub._upload_large_folder', 'huggingface_hub.community', 'huggingface_hub.repocard_data', 'huggingface_hub.utils.endpoint_helpers', 'huggingface_hub.hf_api', 'fsspec.caching', 'fsspec._version', 'fsspec.callbacks', 'fsspec.utils', 'fsspec.config', 'fsspec.dircache', 'fsspec.transaction', 'fsspec.spec', 'fsspec.compression', 'fsspec.registry', 'fsspec.core', 'fsspec.exceptions', 'fsspec.mapping', 'fsspec', 'fsspec.implementations', 'fsspec.implementations.local', 'fsspec.asyn', 'websockets.imports', 'websockets.version', 'websockets', 'websockets.legacy', 'websockets.asyncio', 'websockets.asyncio.async_timeout', 'websockets.asyncio.compatibility', 'websockets.datastructures', 'websockets.speedups', 'websockets.typing', 'websockets.extensions.base', 'websockets.extensions', 'websockets.frames', 'websockets.http11', 'websockets.exceptions', 'websockets.streams', 'websockets.protocol', 'websockets.legacy.framing', 'websockets.legacy.protocol', 'gradio_client.utils', 'gradio_client.media_data', 'gradio_client.data_classes', 'gradio_client.serializing', 'gradio_client.exceptions', 'gradio_client.compatibility', 'gradio_client.documentation', 'gradio_client.client', 'gradio_client', 'PIL._version', 'PIL', 'PIL.ExifTags', 'PIL._deprecate', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._typing', 'PIL._util', 'defusedxml.common', 'defusedxml', 'xml.etree', 'xml.etree.ElementPath', '_elementtree', 'xml.etree.ElementTree', 'defusedxml.ElementTree', 'PIL._imaging', 'PIL.Image', 'aiofiles.base', 'aiofiles.threadpool.utils', 'aiofiles.threadpool.binary', 'aiofiles.threadpool.text', 'aiofiles.threadpool', 'aiofiles.tempfile.temptypes', 'aiofiles.tempfile', 'aiofiles', 'safehttpx', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImagePalette', 'PIL.ImageOps', 'PIL.ImageSequence', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.PngImagePlugin', 'anyio._core', 'sniffio._version', 'sniffio._impl', 'sniffio', 'anyio._core._eventloop', 'exceptiongroup._exceptions', 'exceptiongroup._catch', 'exceptiongroup._version', 'exceptiongroup._formatting', 'exceptiongroup._suppress', 'exceptiongroup', 'anyio._core._exceptions', 'anyio.abc._eventloop', 'anyio.abc._resources', 'anyio._core._typedattr', 'anyio.abc._tasks', 'anyio.abc._streams', 'anyio.abc._sockets', 'anyio.abc._subprocesses', 'anyio.abc._testing', 'anyio.lowlevel', 'anyio._core._tasks', 'anyio._core._testing', 'anyio._core._synchronization', 'anyio.from_thread', 'anyio.abc', 'anyio.to_thread', 'anyio._core._fileio', 'anyio._core._resources', 'anyio._core._signals', 'anyio.streams', 'anyio.streams.stapled', 'anyio.streams.tls', 'anyio._core._sockets', 'anyio.streams.memory', 'anyio._core._streams', 'anyio._core._subprocesses', 'anyio', 'zoneinfo._tzpath', 'zoneinfo._common', '_zoneinfo', 'zoneinfo', 'orjson.orjson', 'orjson', 'gradio.context', 'starlette', 'starlette.status', 'fastapi.openapi', 'pydantic.version', 'pydantic._migration', 'pydantic.errors', 'pydantic', 'pydantic_core._pydantic_core', 'pydantic_core.core_schema', 'pydantic_core', 'pydantic._internal', 'pydantic._internal._internal_dataclass', 'pydantic.aliases', 'pydantic.config', 'pydantic.warnings', 'pydantic._internal._config', 'pydantic._internal._namespace_utils', 'pydantic._internal._typing_extra', 'pydantic._internal._repr', 'pydantic._internal._core_metadata', 'pydantic._internal._core_utils', 'pydantic._internal._import_utils', 'pydantic._internal._utils', 'pydantic._internal._decorators', 'pydantic._internal._docs_extraction', 'pydantic._internal._fields', 'pydantic._internal._forward_ref', 'pydantic._internal._generics', 'pydantic.plugin', 'pydantic.plugin._schema_validator', 'pydantic._internal._mock_val_ser', 'pydantic.annotated_handlers', 'pydantic.functional_validators', 'pydantic._internal._schema_generation_shared', 'pydantic.json_schema', 'pydantic._internal._discriminated_union', 'pydantic._internal._known_annotated_metadata', 'pydantic._internal._generate_schema', 'pydantic._internal._signature', 'pydantic._internal._model_construction', 'pydantic.main', 'starlette.exceptions', 'annotated_types', 'pydantic._internal._validators', 'pydantic.types', 'pydantic.fields', 'pydantic.plugin._loader', 'fastapi.exceptions', 'fastapi.types', 'starlette.concurrency', 'starlette.types', 'starlette.datastructures', 'pydantic.type_adapter', 'fastapi._compat', 'fastapi.logger', 'pydantic.networks', 'pydantic._internal._serializers', 'pydantic._internal._std_types_schema', 'fastapi.openapi.models', 'fastapi.params', 'fastapi.datastructures', 'fastapi.dependencies', 'fastapi.security.base', 'starlette._utils', 'python_multipart.exceptions', 'python_multipart.decoders', 'python_multipart.multipart', 'python_multipart', 'starlette.formparsers', 'starlette.requests', 'fastapi.security.api_key', 'fastapi.security.utils', 'fastapi.security.http', 'fastapi.param_functions', 'fastapi.security.oauth2', 'fastapi.security.open_id_connect_url', 'fastapi.security', 'fastapi.dependencies.models', 'starlette.background', 'fastapi.background', 'fastapi.concurrency', 'fastapi.utils', 'starlette._compat', 'starlette.responses', 'starlette.websockets', 'fastapi.dependencies.utils', 'pydantic.color', 'fastapi.encoders', 'starlette._exception_handler', 'starlette.convertors', 'starlette.middleware', 'starlette.routing', 'fastapi.routing', 'fastapi.websockets', 'fastapi.exception_handlers', 'fastapi.openapi.docs', 'fastapi.openapi.constants', 'fastapi.responses', 'fastapi.openapi.utils', 'starlette.middleware.base', 'starlette.middleware.errors', 'starlette.middleware.exceptions', 'starlette.applications', 'fastapi.applications', 'fastapi.requests', 'fastapi', 'pydantic.root_model', 'gradio.data_classes', 'gradio.exceptions', 'gradio.utils', 'gradio.wasm_utils', 'gradio.state_holder', 'gradio.route_utils', 'chunk', 'audioop', 'wave', 'pydub.logging_utils', 'pydub.utils', 'pydub.exceptions', 'pydub.silence', 'pydub.effects', 'pydub.audio_segment', 'pydub', 'httpcore._models', 'httpcore._backends', 'httpcore._exceptions', 'httpcore._utils', 'httpcore._backends.base', 'httpcore._backends.sync', 'httpcore._ssl', 'httpcore._synchronization', 'httpcore._trace', 'h11._abnf', 'h11._util', 'h11._headers', 'h11._events', 'h11._receivebuffer', 'h11._state', 'h11._readers', 'h11._writers', 'h11._connection', 'h11._version', 'h11', 'httpcore._sync.interfaces', 'httpcore._sync.http11', 'httpcore._sync.connection', 'httpcore._sync.connection_pool', 'httpcore._sync.http_proxy', 'httpcore._sync', 'httpcore._api', 'httpcore._backends.auto', 'httpcore._async.interfaces', 'httpcore._async.http11', 'httpcore._async.connection', 'httpcore._async.connection_pool', 'httpcore._async.http_proxy', 'httpcore._async', 'httpcore._backends.mock', 'httpcore._backends.anyio', 'httpcore', 'gradio.processing_utils', 'webbrowser', 'gradio.analytics', 'markupsafe._speedups', 'markupsafe', 'jinja2.bccache', 'jinja2.utils', 'jinja2.nodes', 'jinja2.exceptions', 'jinja2.visitor', 'jinja2.idtracking', 'jinja2.optimizer', 'jinja2.compiler', 'jinja2.async_utils', 'jinja2.runtime', 'jinja2.filters', 'jinja2.tests', 'jinja2.defaults', 'jinja2._identifier', 'jinja2.lexer', 'jinja2.parser', 'jinja2.environment', 'jinja2.loaders', 'jinja2', 'starlette.templating', 'fastapi.templating', 'aiofiles.ospath', 'aiofiles.os', 'starlette.staticfiles', 'gradio.ranged_response', 'gradio.node_server', 'gradio.oauth', 'gradio.server_messages', 'gradio.routes', 'gradio.tunneling', 'gradio.networking', 'gradio.events', 'gradio.flagging', 'gradio.helpers', 'gradio.queueing', 'gradio.strings', 'semantic_version.base', 'semantic_version', 'gradio.themes.utils.semver_match', 'gradio.themes.utils', 'gradio.themes.utils.colors', 'gradio.themes.utils.fonts', 'gradio.themes.utils.sizes', 'gradio.themes.utils.readme_content', 'gradio.themes.base', 'gradio.themes.citrus', 'gradio.themes.default', 'gradio.themes.glass', 'gradio.themes.monochrome', 'gradio.themes.ocean', 'gradio.themes.origin', 'gradio.themes.soft', 'gradio.themes', 'gradio.component_meta', 'gradio.blocks_events', 'gradio.blocks', 'gradio.layouts.accordion', 'gradio.layouts.column', 'gradio.layouts.row', 'gradio.layouts.form', 'gradio.layouts.group', 'gradio.layouts.tabs', 'gradio.layouts', 'gradio.components.base', 'PIL.BlpImagePlugin', 'PIL.BmpImagePlugin', 'PIL.BufrStubImagePlugin', 'PIL.CurImagePlugin', 'PIL.PcxImagePlugin', 'PIL.DcxImagePlugin', 'PIL.DdsImagePlugin', 'PIL.EpsImagePlugin', 'PIL.FitsImagePlugin', 'PIL.FliImagePlugin', 'PIL.FtexImagePlugin', 'PIL.GbrImagePlugin', 'PIL._imagingmath', 'PIL.ImageMath', 'PIL.GifImagePlugin', 'PIL.GribStubImagePlugin', 'PIL.Hdf5StubImagePlugin', 'PIL.features', 'PIL.Jpeg2KImagePlugin', 'PIL.IcnsImagePlugin', 'PIL.IcoImagePlugin', 'PIL.ImImagePlugin', 'PIL.ImtImagePlugin', 'PIL.IptcImagePlugin', 'PIL.JpegPresets', 'PIL.JpegImagePlugin', 'PIL.McIdasImagePlugin', 'PIL.MpegImagePlugin', 'PIL.TiffImagePlugin', 'PIL.MpoImagePlugin', 'PIL.MspImagePlugin', 'PIL.PalmImagePlugin', 'PIL.PcdImagePlugin', 'PIL.PdfParser', 'PIL.PdfImagePlugin', 'PIL.PixarImagePlugin', 'PIL.PpmImagePlugin', 'PIL.PsdImagePlugin', 'PIL.QoiImagePlugin', 'PIL.SgiImagePlugin', 'PIL.SpiderImagePlugin', 'PIL.SunImagePlugin', 'PIL.TgaImagePlugin', 'PIL._webp', 'PIL.WebPImagePlugin', 'PIL.WmfImagePlugin', 'PIL.XbmImagePlugin', 'PIL.XpmImagePlugin', 'PIL.XVThumbImagePlugin', 'gradio.components.annotated_image', 'gradio.components.audio', 'gradio.components.browser_state', 'gradio.components.button', 'gradio.components.chatbot', 'gradio.components.checkbox', 'gradio.components.checkboxgroup', 'gradio.components.clear_button', 'gradio.components.code', 'gradio.components.color_picker', 'gradio.components.dataframe', 'gradio.components.dataset', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'pytz', 'gradio.components.datetime', 'gradio.components.download_button', 'gradio.components.dropdown', 'gradio.components.duplicate_button', 'gradio.components.fallback', 'gradio.components.file', 'gradio.components.file_explorer', 'gradio.image_utils', 'gradio.components.gallery', 'gradio.components.highlighted_text', 'gradio.components.html', 'gradio.components.image', 'gradio.components.image_editor', 'gradio.components.json_component', 'gradio.components.label', 'gradio.components.login_button', 'gradio.components.markdown', 'gradio.components.model3d', 'gradio.components.multimodal_textbox', 'dateutil._version', 'dateutil', 'pandas._typing', 'pandas.compat._constants', 'pandas.compat.compressors', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas.util._exceptions', 'pandas.util.version', 'pandas.compat._optional', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.tz.tz', 'dateutil.tz', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.ccalendar', '_strptime', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config', 'pandas._config.localization', 'pandas._libs.tslibs.fields', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil._common', 'dateutil.relativedelta', 'pandas._libs.properties', 'pandas._libs.tslibs.offsets', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'dateutil.parser', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.tslibs', 'pandas._libs.ops_dispatch', 'pandas._libs.missing', 'pandas._libs.hashtable', 'pandas._libs.algos', 'pandas._libs.interval', 'pandas._libs', 'pandas.util._decorators', 'pandas.core', 'pandas.core.util', 'pandas._libs.lib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.base', 'pandas.core.dtypes.inference', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.common', 'pandas.core.util.hashing', 'pandas.util', 'pandas.compat.numpy', 'pyarrow._generated_version', '_cython_3_0_10', 'cloudpickle.cloudpickle', 'cloudpickle', 'pyarrow.util', 'pyarrow.lib', 'pyarrow.ipc', 'pyarrow.types', 'pyarrow', 'pandas.compat.pyarrow', 'pandas.compat', 'pandas._libs.tslib', 'pandas.core.config_init', 'pandas.core.dtypes.missing', 'pandas.io', 'pandas.io._util', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.astype', 'pandas.core.dtypes.concat', 'pandas.core.array_algos', 'pandas.core.common', 'pandas.core.construction', 'pandas.core.array_algos.take', 'pandas.core.indexers.utils', 'pandas.core.indexers', 'pandas.core.algorithms', 'pandas.util._validators', 'pandas.core.roperator', 'pandas._libs.ops', 'pandas.core.computation', 'numexpr.interpreter', 'numexpr.expressions', 'numexpr.version', 'numexpr.utils', 'numexpr.necompiler', 'numexpr', 'pandas.core.computation.check', 'pandas.core.computation.expressions', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.array_ops', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.ops', 'pandas.core.arraylike', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.core.array_algos.quantile', 'pandas.core.sorting', 'pandas.core.arrays.base', 'pandas.core.strings', 'pandas.core.strings.base', 'pandas.tseries', 'pandas.tseries.frequencies', 'pyarrow._compute', 'pyarrow._compute_docstrings', 'pyarrow.vendored', 'pyarrow.vendored.docscrape', 'pyarrow.compute', 'pandas.core.arrays.arrow._arrow_utils', 'pandas.core.arrays.arrow.dtype', 'pandas.core.arrays.arrow.array', 'pandas.core.arrays.arrow', 'pandas.core.array_algos.masked_accumulations', 'bottleneck.benchmark', 'bottleneck.benchmark.autotimeit', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck.slow', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'bottleneck', 'pandas.core.nanops', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arrays.masked', 'pandas.core.arrays.boolean', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.array_algos.transforms', 'pandas.core.arrays._mixins', 'pandas.core.base', 'pandas.core.strings.object_array', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.categorical', 'pandas.core.array_algos.datetimelike_accumulations', 'pandas.core.arrays.numeric', 'pandas.core.arrays.integer', 'pandas.core.arrays.datetimelike', 'pandas.core.arrays._ranges', 'pandas.tseries.offsets', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.floating', 'pandas.core.arrays.timedeltas', 'pandas.core.arrays.interval', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.arrays.sparse.array', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays', 'pandas.core.flags', 'pandas._libs.reduction', 'pandas.core.apply', 'pandas._libs.indexing', 'pandas.core.indexes', 'pandas._libs.index', 'pandas._libs.internals', 'pandas._libs.join', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.strings.accessor', 'pandas.core.indexes.base', 'pandas.core.indexes.extension', 'pandas.core.indexes.category', 'pandas.core.indexes.range', 'pandas.core.tools', 'pandas.core.tools.timedeltas', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.times', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.interval', 'pandas.core.indexes.period', 'pandas.core.indexes.api', 'pandas.core.indexing', 'pandas.core.sample', 'pandas.core.array_algos.replace', 'pandas._libs.writers', 'pandas.core.internals.blocks', 'pandas.core.internals.api', 'pandas.core.internals.base', 'pandas.core.internals.array_manager', 'pandas.core.internals.ops', 'pandas.core.internals.managers', 'pandas.core.internals.concat', 'pandas.core.internals', 'pandas.core.internals.construction', 'pandas.core.methods', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.shared_docs', 'pandas.io.common', 'pandas.io.formats.format', 'pandas.core.methods.describe', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas._libs.window.indexers', 'pandas.core.indexers.objects', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core._numba', 'pandas.core._numba.executor', 'pandas.core.window.rolling', 'pandas.core.window.ewm', 'pandas.core.window.expanding', 'pandas.core.window', 'pandas.core.generic', 'pandas.core.methods.selectn', 'pandas.core.reshape.util', 'pandas.core.tools.numeric', 'pandas.core.reshape.melt', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.arrays', 'pandas.core.tools.datetimes', 'pandas.io.formats.info', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.plotting', 'pandas.core.series', 'pandas.core.frame', 'pandas.core.groupby.base', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.categorical', 'pandas.core.groupby.grouper', 'pandas.core.groupby.ops', 'pandas.core.groupby.indexing', 'pandas.core.groupby.groupby', 'pandas.core.groupby.generic', 'pandas.core.groupby', 'pandas.core.api', 'pandas.tseries.api', 'pandas.core.computation.common', 'pandas.core.computation.align', 'pandas.core.computation.scope', 'pandas.core.computation.ops', 'pandas.core.computation.engines', 'pandas.core.computation.parsing', 'pandas.core.computation.expr', 'pandas.core.computation.eval', 'pandas.core.computation.api', 'pandas.core.reshape.encoding', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.tile', 'pandas.core.reshape.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.core.interchange', 'pandas.core.interchange.dataframe_protocol', 'pandas.core.dtypes.api', 'pandas.api.types', 'pandas.core.interchange.utils', 'pandas.core.interchange.from_dataframe', 'pandas.api.interchange', 'pandas.api', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._io', 'pandas._testing._warnings', 'pandas._libs.testing', 'pandas._testing.asserters', 'pandas._testing.compat', 'pandas._testing', 'pandas.testing', 'pandas.util._print_versions', 'pandas.io.clipboards', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers.base_parser', 'pandas.io.parsers.arrow_parser_wrapper', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.parsers.readers', 'pandas.io.parsers', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._base', 'pandas._libs.json', 'pandas.io.excel._odswriter', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.json._json', 'pandas.io.json', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.compat.pickle_compat', 'pandas.io.pickle', 'pandas.core.computation.pytables', 'pandas.io.pytables', 'pandas.io.sas.sasreader', 'pandas.io.sas', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.io.api', 'pandas.util._tester', 'pandas._version', 'pandas', 'gradio.components.native_plot', 'gradio.components.number', 'gradio.components.paramviewer', 'gradio.components.plot', 'gradio.components.radio', 'gradio.components.slider', 'gradio.components.state', 'gradio.components.textbox', 'gradio.components.timer', 'gradio.components.upload_button', 'ffmpy.ffmpy', 'ffmpy', 'gradio.components.video', 'gradio.components', 'gradio._simple_templates.simpledropdown', 'gradio._simple_templates.simpleimage', 'gradio._simple_templates.simpletextbox', 'gradio._simple_templates', 'gradio.templates', 'gradio.chat_interface', 'gradio.external_utils', 'gradio.external', 'gradio.pipelines_utils', 'gradio.pipelines', 'gradio.interface', 'gradio.renderable', 'typer.colors', 'typer._typing', 'click.shell_completion', 'shellingham._core', 'shellingham', 'typer._completion_shared', 'typer._completion_classes', 'typer.models', 'typer.params', 'typer.utils', 'typer.completion', 'rich.columns', 'markdown_it.common', 'markdown_it.common.entities', 'markdown_it.common.utils', 'markdown_it.helpers.parse_link_destination', 'markdown_it._compat', 'markdown_it.utils', 'markdown_it.ruler', 'markdown_it.token', 'markdown_it.rules_inline.state_inline', 'markdown_it.rules_inline.emphasis', 'markdown_it.rules_inline.strikethrough', 'markdown_it.rules_inline.autolink', 'markdown_it.rules_inline.backticks', 'markdown_it.rules_inline.balance_pairs', 'markdown_it.rules_inline.entity', 'markdown_it.rules_inline.escape', 'markdown_it.rules_inline.fragments_join', 'markdown_it.common.html_re', 'markdown_it.rules_inline.html_inline', 'markdown_it.rules_inline.image', 'markdown_it.rules_inline.link', 'markdown_it.rules_inline.linkify', 'markdown_it.rules_inline.newline', 'markdown_it.rules_inline.text', 'markdown_it.rules_inline', 'markdown_it.helpers.parse_link_label', 'markdown_it.helpers.parse_link_title', 'markdown_it.helpers', 'markdown_it.presets.commonmark', 'markdown_it.presets.default', 'markdown_it.presets.zero', 'markdown_it.presets', 'mdurl._decode', 'mdurl._encode', 'mdurl._format', 'mdurl._url', 'mdurl._parse', 'mdurl', 'markdown_it._punycode', 'markdown_it.common.normalize_url', 'markdown_it.rules_block.state_block', 'markdown_it.rules_block.blockquote', 'markdown_it.rules_block.code', 'markdown_it.rules_block.fence', 'markdown_it.rules_block.heading', 'markdown_it.rules_block.hr', 'markdown_it.common.html_blocks', 'markdown_it.rules_block.html_block', 'markdown_it.rules_block.lheading', 'markdown_it.rules_block.list', 'markdown_it.rules_block.paragraph', 'markdown_it.rules_block.reference', 'markdown_it.rules_block.table', 'markdown_it.rules_block', 'markdown_it.parser_block', 'markdown_it.rules_core.state_core', 'markdown_it.rules_core.block', 'markdown_it.rules_core.inline', 'markdown_it.rules_core.linkify', 'markdown_it.rules_core.normalize', 'markdown_it.rules_core.replacements', 'markdown_it.rules_core.smartquotes', 'markdown_it.rules_core.text_join', 'markdown_it.rules_core', 'markdown_it.parser_core', 'markdown_it.parser_inline', 'markdown_it.renderer', 'uc_micro.categories.Cc.regex', 'uc_micro.categories.Cc', 'uc_micro.categories.Cf.regex', 'uc_micro.categories.Cf', 'uc_micro.categories.P.regex', 'uc_micro.categories.P', 'uc_micro.categories.Z.regex', 'uc_micro.categories.Z', 'uc_micro.categories', 'uc_micro.properties.Any.regex', 'uc_micro.properties.Any', 'uc_micro.properties', 'uc_micro', 'linkify_it.ucre', 'linkify_it.main', 'linkify_it', 'markdown_it.main', 'markdown_it', 'rich._stack', 'rich.rule', 'rich.markdown', 'typer.rich_utils', 'typer.core', 'rich.traceback', 'typer.main', 'typer', 'gradio_client.cli.deploy_discord', 'gradio_client.cli', 'gradio.cli.commands.cli_env_info', 'tomlkit._compat', 'tomlkit._utils', 'tomlkit._types', 'tomlkit.exceptions', 'tomlkit.items', 'tomlkit.container', 'tomlkit.toml_char', 'tomlkit.source', 'tomlkit.toml_document', 'tomlkit.parser', 'tomlkit.api', 'tomlkit', 'gradio.cli.commands.components._docs_utils', 'gradio.cli.commands.display', 'gradio.cli.commands.components._docs_assets', 'gradio.cli.commands.components.docs', 'gradio.cli.commands.components.install_component', 'gradio.cli.commands.components.build', 'rich.prompt', 'gradio.cli.commands.components._create_utils', 'gradio.cli.commands.components.create', 'gradio.cli.commands.components.dev', 'gradio.cli.commands.components.publish', 'gradio.cli.commands.components.show', 'gradio.cli.commands.components.app', 'gradio.cli.commands.components', 'gradio.cli.commands.deploy_space', 'gradio.cli.commands.reload', 'gradio.cli.commands', 'gradio.cli.cli', 'gradio.cli', 'IPython.core', 'IPython.core.getipython', 'IPython.core.release', 'traitlets.utils', 'traitlets.utils.bunch', 'traitlets.utils.descriptions', 'traitlets.utils.getargspec', 'traitlets.utils.importstring', 'traitlets.utils.sentinel', 'traitlets.traitlets', 'traitlets._version', 'traitlets.utils.decorators', 'traitlets', 'logging.handlers', 'socketserver', 'logging.config', 'traitlets.utils.text', 'traitlets.config.loader', 'traitlets.config.configurable', 'traitlets.utils.nested_update', 'traitlets.config.application', 'traitlets.config', 'IPython.utils', 'IPython.utils.ipstruct', 'IPython.utils.coloransi', 'IPython.utils.colorable', 'IPython.utils.PyColorize', 'IPython.utils.encoding', 'IPython.utils.py3compat', 'IPython.core.excolors', 'IPython.testing', 'IPython.testing.skipdoctest', 'IPython.core.debugger', 'IPython.core.display_trap', 'pexpect.exceptions', 'pexpect.utils', 'pexpect.expect', 'tty', 'pty', 'ptyprocess.util', 'ptyprocess.ptyprocess', 'ptyprocess', 'pexpect.spawnbase', 'pexpect.pty_spawn', 'pexpect.run', 'pexpect', 'IPython.utils._process_common', 'IPython.utils._process_posix', 'IPython.utils.process', 'IPython.utils.decorators', 'IPython.utils.path', 'IPython.utils.data', 'IPython.utils.terminal', 'IPython.core.ultratb', 'IPython.utils._sysinfo', 'IPython.utils.sysinfo', 'IPython.core.crashhandler', 'IPython.utils.importstring', 'IPython.paths', 'IPython.core.profiledir', 'IPython.core.application', 'IPython.terminal', 'IPython.core.compilerop', 'IPython.core.error', 'IPython.utils.text', 'IPython.core.magic_arguments', 'getopt', 'IPython.core.display', 'IPython.core.page', 'IPython.lib.security', 'IPython.lib', 'IPython.lib.pretty', 'IPython.utils.openpy', 'IPython.utils.dir2', 'IPython.utils.wildcard', 'pygments.unistring', 'pygments.lexers.python', 'pygments.formatters._mapping', 'pygments.formatters', 'pygments.formatter', 'pygments.formatters.html', 'IPython.core.oinspect', 'IPython.core.inputtransformer2', 'IPython.core.magic', 'pickleshare', 'IPython.core.autocall', 'IPython.core.macro', 'IPython.core.splitinput', 'IPython.core.prefilter', 'IPython.core.alias', 'IPython.core.builtin_trap', 'backcall.backcall', 'backcall', 'IPython.core.events', 'IPython.core.displayhook', 'IPython.core.displaypub', 'IPython.core.extensions', 'IPython.utils.sentinel', 'IPython.core.formatters', '_sqlite3', 'sqlite3.dbapi2', 'sqlite3', 'IPython.core.history', 'IPython.core.logger', 'IPython.core.payload', 'IPython.core.usage', 'IPython.lib.display', 'IPython.display', 'IPython.utils.capture', 'IPython.utils.io', 'IPython.core.hooks', 'IPython.utils.strdispatch', 'IPython.utils.syspathcontext', 'IPython.utils.tempdir', 'IPython.utils.contexts', 'IPython.core.async_helpers', 'IPython.core.interactiveshell', 'prompt_toolkit.application.current', 'prompt_toolkit.eventloop.utils', 'prompt_toolkit.eventloop.async_generator', 'prompt_toolkit.eventloop.inputhook', 'prompt_toolkit.eventloop', 'prompt_toolkit.application.run_in_terminal', 'prompt_toolkit.selection', 'prompt_toolkit.clipboard.base', 'prompt_toolkit.clipboard.in_memory', 'prompt_toolkit.clipboard', 'prompt_toolkit.cache', 'prompt_toolkit.enums', 'prompt_toolkit.filters.base', 'prompt_toolkit.filters.app', 'prompt_toolkit.filters.cli', 'prompt_toolkit.filters.utils', 'prompt_toolkit.filters', 'prompt_toolkit.document', 'prompt_toolkit.auto_suggest', 'prompt_toolkit.keys', 'prompt_toolkit.key_binding.key_bindings', 'wcwidth.table_vs16', 'wcwidth.table_wide', 'wcwidth.table_zero', 'wcwidth.unicode_versions', 'wcwidth.wcwidth', 'wcwidth', 'prompt_toolkit.utils', 'prompt_toolkit.key_binding.key_processor', 'prompt_toolkit.key_binding', 'prompt_toolkit.key_binding.vi_state', 'prompt_toolkit.cursor_shapes', 'prompt_toolkit.data_structures', 'prompt_toolkit.styles.base', 'prompt_toolkit.styles.named_colors', 'prompt_toolkit.styles.style', 'prompt_toolkit.styles.defaults', 'prompt_toolkit.styles.pygments', 'prompt_toolkit.styles.style_transformation', 'prompt_toolkit.styles', 'prompt_toolkit.output.color_depth', 'prompt_toolkit.output.base', 'prompt_toolkit.output.flush_stdout', 'prompt_toolkit.output.plain_text', 'prompt_toolkit.output.defaults', 'prompt_toolkit.output', 'prompt_toolkit.output.vt100', 'prompt_toolkit.mouse_events', 'prompt_toolkit.formatted_text.base', 'prompt_toolkit.formatted_text.ansi', 'xml.dom.domreg', 'xml.dom', 'xml.dom.minicompat', 'xml.dom.NodeFilter', 'xml.dom.xmlbuilder', 'xml.dom.minidom', 'prompt_toolkit.formatted_text.html', 'prompt_toolkit.formatted_text.pygments', 'prompt_toolkit.formatted_text.utils', 'prompt_toolkit.formatted_text', 'prompt_toolkit.completion.base', 'prompt_toolkit.completion.deduplicate', 'prompt_toolkit.completion.filesystem', 'prompt_toolkit.completion.word_completer', 'prompt_toolkit.completion.fuzzy_completer', 'prompt_toolkit.completion.nested', 'prompt_toolkit.completion', 'prompt_toolkit.history', 'prompt_toolkit.search', 'prompt_toolkit.validation', 'prompt_toolkit.buffer', 'prompt_toolkit.input.base', 'prompt_toolkit.input.defaults', 'prompt_toolkit.input', 'prompt_toolkit.input.typeahead', 'prompt_toolkit.key_binding.bindings', 'prompt_toolkit.key_binding.bindings.scroll', 'prompt_toolkit.key_binding.bindings.page_navigation', 'prompt_toolkit.lexers.base', 'prompt_toolkit.lexers.pygments', 'prompt_toolkit.lexers', 'prompt_toolkit.layout.utils', 'prompt_toolkit.layout.processors', 'prompt_toolkit.layout.controls', 'prompt_toolkit.layout.dimension', 'prompt_toolkit.layout.margins', 'prompt_toolkit.layout.mouse_handlers', 'prompt_toolkit.layout.screen', 'prompt_toolkit.layout.containers', 'prompt_toolkit.layout.layout', 'prompt_toolkit.layout.menus', 'prompt_toolkit.layout.scrollable_pane', 'prompt_toolkit.layout', 'prompt_toolkit.key_binding.bindings.completion', 'prompt_toolkit.key_binding.bindings.named_commands', 'prompt_toolkit.key_binding.bindings.basic', 'prompt_toolkit.key_binding.bindings.cpr', 'prompt_toolkit.key_binding.bindings.emacs', 'prompt_toolkit.key_binding.bindings.mouse', 'prompt_toolkit.input.ansi_escape_sequences', 'prompt_toolkit.input.vt100_parser', 'prompt_toolkit.key_binding.digraphs', 'prompt_toolkit.key_binding.bindings.vi', 'prompt_toolkit.key_binding.defaults', 'prompt_toolkit.key_binding.emacs_state', 'prompt_toolkit.layout.dummy', 'prompt_toolkit.renderer', 'prompt_toolkit.application.application', 'prompt_toolkit.application.dummy', 'prompt_toolkit.application', 'prompt_toolkit.key_binding.bindings.focus', 'prompt_toolkit.widgets.toolbars', 'prompt_toolkit.widgets.base', 'prompt_toolkit.widgets.dialogs', 'prompt_toolkit.widgets.menus', 'prompt_toolkit.widgets', 'prompt_toolkit.shortcuts.dialogs', 'xml.dom.expatbuilder', 'prompt_toolkit.shortcuts.progress_bar.formatters', 'prompt_toolkit.shortcuts.progress_bar.base', 'prompt_toolkit.shortcuts.progress_bar', 'prompt_toolkit.key_binding.bindings.auto_suggest', 'prompt_toolkit.key_binding.bindings.open_in_editor', 'prompt_toolkit.shortcuts.prompt', 'prompt_toolkit.shortcuts.utils', 'prompt_toolkit.shortcuts', 'prompt_toolkit', 'prompt_toolkit.patch_stdout', 'IPython.core.latex_symbols', 'IPython.utils.generics', 'IPython.core.completer', 'IPython.terminal.ptutils', 'IPython.terminal.shortcuts', 'IPython.terminal.debugger', 'IPython.lib.clipboard', 'IPython.terminal.magics', 'IPython.terminal.pt_inputhooks', 'IPython.terminal.prompts', 'IPython.terminal.interactiveshell', 'IPython.core.magics.auto', 'IPython.core.magics.basic', 'IPython.core.magics.code', 'IPython.core.magics.config', 'IPython.core.magics.display', '_lsprof', 'profile', 'cProfile', 'pstats', 'IPython.utils.module_paths', 'IPython.utils.timing', 'IPython.core.magics.execution', 'IPython.core.magics.extension', 'IPython.core.magics.history', 'IPython.core.magics.logging', 'IPython.core.magics.namespace', 'IPython.core.magics.osm', 'IPython.core.magics.packaging', 'IPython.core.pylabtools', 'IPython.core.magics.pylab', 'IPython.lib.backgroundjobs', 'IPython.core.magics.script', 'IPython.core.magics', 'IPython.core.shellapp', 'IPython.extensions', 'IPython.extensions.storemagic', 'IPython.terminal.ipapp', 'IPython.terminal.embed', 'IPython.utils.frame', 'IPython', 'gradio.ipython_ext', 'gradio', 'unidecode', 'pyopenjtalk.version', 'pyopenjtalk.htsengine', '_cython_0_29_34', 'pyopenjtalk.openjtalk', 'pyopenjtalk.utils', 'pyopenjtalk', 'text.japanese', 'jamo.jamo', 'jamo', 'ko_pron.data', 'ko_pron.ko_pron', 'ko_pron', 'text.korean', 'pypinyin.compat', 'pypinyin.pinyin_dict', 'pypinyin.phrases_dict', 'pypinyin.constants', 'pypinyin.contrib', 'pypinyin.contrib.uv', 'pypinyin.style', 'pypinyin.style._tone_rule', 'pypinyin.contrib._tone_rule', 'pypinyin.contrib.neutral_tone', 'pypinyin.phonetic_symbol', 'pypinyin.style._constants', 'pypinyin.standard', 'pypinyin.style._utils', 'pypinyin.style.tone', 'pypinyin.style._tone_convert', 'pypinyin.contrib.tone_convert', 'pypinyin.contrib.tone_sandhi', 'pypinyin.seg', 'pypinyin.seg.mmseg', 'pypinyin.seg.simpleseg', 'pypinyin.utils', 'pypinyin.style.initials', 'pypinyin.style.finals', 'pypinyin.style.bopomofo', 'pypinyin.style.cyrillic', 'pypinyin.style.wadegiles', 'pypinyin.style.others', 'pypinyin.converter', 'pypinyin.core', 'pypinyin', 'jieba._compat', 'jieba.finalseg.prob_start', 'jieba.finalseg.prob_trans', 'jieba.finalseg.prob_emit', 'jieba.finalseg', 'jieba', 'proces.conf', 'proces.preprocess', 'proces.util', 'proces.data', 'proces.data.province_city', 'proces.util.data', 'proces.masking', 'proces', 'cn2an.conf', 'cn2an.an2cn', 'cn2an.cn2an', 'cn2an.transform', 'cn2an', 'text.mandarin', 'indic_transliteration', 'toml.tz', 'toml.decoder', 'toml.encoder', 'toml', 'indic_transliteration.sanscript.schemes', 'indic_transliteration.sanscript.schemes.roman', 'indic_transliteration.sanscript.schemes.brahmic', 'indic_transliteration.sanscript', 'text.sanskrit', 'typeguard._config', 'typeguard._exceptions', 'typeguard._memo', 'typeguard._utils', 'typeguard._checkers', 'typeguard._suppression', 'typeguard._functions', 'typeguard._transformer', 'typeguard._decorators', 'typeguard._importhook', 'typeguard', 'inflect.compat', 'inflect.compat.py38', 'inflect', 'eng_to_ipa.syllables', 'eng_to_ipa.stress', 'eng_to_ipa.transcribe', 'eng_to_ipa.rhymes', 'eng_to_ipa.transcriber', 'eng_to_ipa', 'text.english', 'num_thai', 'num_thai.thainumbers', 'text.thai', 'text.cleaners', 'text.symbols', 'text', 'netrc', 'uvicorn._types', 'uvicorn.importer', 'uvicorn.logging', 'uvicorn.middleware', 'uvicorn.middleware.asgi2', 'uvicorn.middleware.message_logger', 'uvicorn.middleware.proxy_headers', 'uvicorn.middleware.wsgi', 'uvicorn.config', 'uvicorn.server', 'uvicorn._subprocess', 'uvicorn.supervisors.basereload', 'uvicorn.supervisors.multiprocess', 'uvicorn.supervisors.statreload', 'uvicorn.supervisors', 'uvicorn.main', 'uvicorn', 'gradio.http_server', 'uvicorn.loops', 'uvicorn.loops.auto', 'uvicorn.loops.asyncio', 'uvicorn.protocols', 'uvicorn.protocols.http', 'uvicorn.protocols.http.flow_control', 'uvicorn.protocols.utils', 'uvicorn.protocols.http.h11_impl', 'uvicorn.protocols.http.auto', 'uvicorn.protocols.websockets', 'websockets.headers', 'websockets.utils', 'websockets.legacy.handshake', 'websockets.extensions.permessage_deflate', 'websockets.legacy.exceptions', 'websockets.legacy.http', 'websockets.legacy.server', 'websockets.server', 'uvicorn.protocols.websockets.websockets_impl', 'uvicorn.protocols.websockets.auto', 'uvicorn.lifespan', 'uvicorn.lifespan.on', 'anyio._backends', 'anyio._backends._asyncio', 'encodings.unicode_escape', 'matplotlib', 'distutils.compat.py38', 'distutils.compat', 'distutils.compat.py39', 'distutils.errors', 'distutils._log', 'distutils._modified', 'distutils.debug', 'distutils.spawn', 'distutils.util', 'distutils.sysconfig', 'distutils.command', 'jaraco.collections', 'distutils.file_util', 'distutils.dir_util', 'distutils.archive_util', 'distutils.cmd', 'distutils.fancy_getopt', 'distutils.dist', 'distutils.extension', 'distutils.core', 'distutils.command._framework_compat', 'distutils.command.install', 'distutils.command.install_egg_info', '_distutils_system_mod', 'setuptools._distutils', '_distutils_hack.override', 'distutils.filelist', 'setuptools.monkey', 'distutils.log', 'setuptools.logging', 'setuptools._imp', 'setuptools.depends', 'setuptools._path', 'setuptools.discovery', 'setuptools._importlib', 'setuptools._itertools', 'setuptools.errors', 'setuptools._entry_points', 'setuptools._reqs', 'distutils.command.bdist', 'setuptools.command', 'setuptools.warnings', 'setuptools.config.expand', 'setuptools.config.setupcfg', 'setuptools.config', 'email._header_value_parser', 'email.headerregistry', 'setuptools.extension', 'setuptools.config._apply_pyprojecttoml', 'setuptools.config.pyprojecttoml', 'setuptools.dist', 'setuptools.version', 'setuptools._normalization', 'setuptools._core_metadata', 'setuptools', 'distutils', 'distutils.version', 'matplotlib.cbook.deprecation', 'matplotlib.cbook', 'matplotlib._animation_data', 'matplotlib.animation', 'matplotlib.fontconfig_pattern', 'matplotlib.docstring', 'matplotlib._color_data', 'matplotlib.colors', 'cycler', 'matplotlib.rcsetup', 'matplotlib._version', 'matplotlib.ft2font', 'kiwisolver.exceptions', 'kiwisolver._cext', 'kiwisolver']\n",
            "ko↑Nniʧiwa.\n",
            " length:11\n",
            " length:11\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:738: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.686 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.686 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "ni↓↑hau↓↑.\n",
            " length:10\n",
            " length:10\n",
            "ʦ`⁼ɹ`→ʧʰyeNN↑ yau↓ ʧʰɥ↓ s`ə↓kʰə↓ t⁼ə s`ɹ`↑hou↓, you↓↑saNN→k⁼ə↓ wai↓ʧ⁼i↑ s`əNg→ ʦ⁼ai↓ su↓s`ə↓ k⁼wei↓tʰai↑ wai↓myeNN↓.\n",
            " length:116\n",
            " length:116\n",
            "ʧ⁼ye↑s`u↓ ʦ`⁼ɹ`→ hou↓ tʰa→ yuNg↓ həNN↓↑ fu↑ kʰwa→ t⁼ə t⁼uNg↓ʦ⁼wo↓ hai↑you↓↑ ɥ↓↑ʧʰi↓ k⁼əNN→ wo↓↑ s`wo→ ʃye↓ʃye↓.\n",
            " length:111\n",
            " length:111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP13MQEe6gu-",
        "outputId": "ece8da26-c328-455b-ab86-d514ae278b49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.10.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.8.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.24.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (14.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g48xd_CrfOib",
        "outputId": "06be7666-d515-4fa6-b8a9-de9e7ab8ff4b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192\r                                                                                                    \rHit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5 下载模型\n",
        "## 本地部署方法请见[README](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_ZH.md)"
      ],
      "metadata": {
        "id": "MXYxSdt-m3YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 下载选项1：运行该单元格，浏览器会自动下载模型和配置文件\n",
        "#@markdown ### Download option 1: Running this codeblock will download model & config files by your browser.\n",
        "!python scripts/rearrange_speaker.py\n",
        "%run scripts/download_model.py"
      ],
      "metadata": {
        "id": "QcJQm6_ImD7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d8511036-21a4-48e7-9ec2-c47d38a98fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VITS-fast-fine-tuning/scripts/rearrange_speaker.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_sd = torch.load(args.model_dir, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cff78594-4f41-4376-a9c1-d72a623e3ba7\", \"G_latest.pth\", 158887836)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0e796ce5-2bec-441a-a2b8-e0aec08b74ab\", \"finetune_speaker.json\", 2170)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62be45d1-afed-4cf1-8bf8-42a79f0639c6\", \"moegoe_config.json\", 2161)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 下载选项2：运行该单元格会将模型和配置文件保存到Google云端硬盘\n",
        "#@markdown ### Download option 2: Running this codeblock will save the mode & config files to your Google drive.\n",
        "!python scripts/rearrange_speaker.py\n",
        "!cp ./G_latest.pth ../drive/MyDrive/G_latest.pth\n",
        "!cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n",
        "!cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json"
      ],
      "metadata": {
        "id": "k13JBTommkTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 运行该单元格会清空所有已上传的样本，需要时可使用\n",
        "#@markdown ### Running this codeblock will delete all voice samples you have uploaded. Use it if you need.\n",
        "!rm -rf ./custom_character_voice/*\n",
        "!rm -rf ./video_data/*\n",
        "!rm -rf ./raw_audio/*\n",
        "!rm -rf ./denoised_audio/*\n",
        "!rm -rf ./segmented_character_voice/*\n",
        "!rm -rf long_character_anno.txt\n",
        "!rm -rf short_character_anno.txt"
      ],
      "metadata": {
        "id": "hU8LmJlUcF1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 运行该单元格会将切片和标注复制到谷歌云端硬盘根目录下名为`voice_data`的文件夹下以用作其它用途\n",
        "#@markdown ### Running this codeblock will copy all processed voices & annotations to a folder named `voice_data` under the root of Google Drive for other purpose of usage\n",
        "!mkdir ../drive/MyDrive/voice_data/\n",
        "!cp -rf ./custom_character_voice/ ../drive/MyDrive/voice_data/custom_character_voice/\n",
        "!cp -rf ./segmented_character_voice/ ../drive/MyDrive/voice_data/segmented_character_voice/\n",
        "!cp long_character_anno.txt ../drive/MyDrive/voice_data/long_character_anno.txt\n",
        "!cp short_character_anno.txt ../drive/MyDrive/voice_data/short_character_anno.txt"
      ],
      "metadata": {
        "id": "ZHK6qw4wRF8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "rGGMy5m-pyaD",
        "outputId": "1c8df450-745e-40a9-9883-0b4de9f341b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.4 which is incompatible.\n",
            "arviz 0.20.0 requires matplotlib>=3.5, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.3.1 which is incompatible.\n",
            "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "gradio 5.10.0 requires pydantic>=2.0, but you have pydantic 1.10.4 which is incompatible.\n",
            "langchain 0.3.12 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.3.1 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "seaborn 0.13.2 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.3.1 which is incompatible.\n",
            "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "8a984bdd90c34cebbf44baf6368f8fda"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}